---
author: Matthew J. C. Crump
lang: es
abstract-title: Notas
abstract: Traducido al espa√±ol rioplatense por ChatGPT4-o bajo la supervisi√≥n de √Ålvaro Cabana.
aliases: [Correlation.html]
---

```{r, include = FALSE}
source("global_stuff.R")
```

# Correlaci√≥n

> La correlaci√≥n no implica causalidad\
> ‚ÄîTodo docente de Estad√≠stica y M√©todos de Investigaci√≥n, alguna vez

En el cap√≠tulo anterior ten√≠amos un conjunto de datos. Era demasiado para mirar y no ten√≠a mucho sentido. As√≠ que hablamos de c√≥mo visualizar los datos usando gr√°ficos e histogramas, y de c√≥mo resumir un mont√≥n de n√∫meros para determinar su tendencia central (lo com√∫n) y su variabilidad (lo diferente). Y todo estaba bien en el mundo.

Pero no olvidemos la gran raz√≥n por la que aprendimos sobre estad√≠sticas descriptivas. La gran raz√≥n es que estamos interesados en responder preguntas usando datos.

Si est√°s buscando un tema central para tener en mente durante este curso, es este: **¬øc√≥mo hacemos para formular y responder preguntas usando datos?**

En cada secci√≥n del libro, deber√≠as conectar ese di√°logo interno con esta pregunta, y pensar: *¬øc√≥mo lo que estoy aprendiendo me ayuda a responder preguntas con datos?*\
Advertencia anticipada: sabemos que es f√°cil olvidarse de esto cuando nos metemos en los detalles, as√≠ que vamos a intentar tirarte una cuerda cada tanto... record√°: estamos tratando de responder preguntas con datos.

En el cap√≠tulo dos empezamos con unos datos ficticios sobre la felicidad humana, ¬øte acord√°s? Imaginamos que le ped√≠amos a muchas personas que nos dijeran cu√°n felices se sent√≠an, y luego mir√°bamos los n√∫meros que nos daban. Sigamos con ese experimento mental imaginario.

¬øQu√© obten√©s cuando le ped√≠s a la gente que use un n√∫mero para describir cu√°n feliz est√°? Un mont√≥n de n√∫meros. ¬øQu√© tipo de preguntas pod√©s hacer con esos n√∫meros? Bueno, pod√©s mirar los valores y estimar sus propiedades generales, como ya hicimos. Esperamos que esos n√∫meros nos digan cosas que m√°s o menos ya sabemos. Que hay personas diferentes, y que cada persona tiene un nivel diferente de felicidad. Probablemente conociste a algunas personas realmente felices, y otras realmente infelices, y vos tambi√©n seguramente tengas alg√∫n nivel de felicidad. ‚ÄúBuen√≠simo, ¬°chocolate por la noticia!‚Äù.

Antes de seguir, tambi√©n deber√≠as tener una actitud cr√≠tica respecto a qu√© significan esos n√∫meros. Por ejemplo, si forz√°s a las personas a calificar su felicidad con un n√∫mero entre 0 y 100, ¬øese n√∫mero refleja realmente cu√°n felices son? ¬øPuede una persona saber cu√°n feliz est√°? ¬øEl formato de la pregunta influye en la respuesta? ¬øLa felicidad es siquiera algo real?. Estas son todas preguntas v√°lidas sobre la **validez** del constructo (la felicidad misma) y del instrumento de medida (los n√∫meros) que est√°s usando para cuantificarlo. Pero por ahora vamos a dejar esas preguntas importantes de lado, y vamos a asumir que la felicidad existe, y que nuestra medida de felicidad refleja algo sobre cu√°n feliz est√° la gente.

Bien. Una vez que medimos un poco de felicidad, seguro se te ocurren preguntas m√°s importantes. Por ejemplo, ¬øqu√© cosas hacen que la felicidad suba o baje? Si supieras qu√© la causa, ¬øqu√© podr√≠as hacer? ¬øQu√© tal aumentar tu propia felicidad?; o ayudar a personas que est√°n infelices; o entender mejor por qu√© √çgor, el burrito de *Winnie the Pooh*, est√° siempre bajoneado; o presentar argumentos cient√≠ficos v√°lidos contra afirmaciones err√≥neas sobre las causas de la felicidad. Una teor√≠a causal y un entendimiento de la felicidad servir√≠an para todo eso. Entonces, ¬øc√≥mo hacemos para llegamos ah√≠?

Imagin√° que sos una observadora alien√≠gena. Lleg√°s a la Tierra y escuch√°s hablar de esta cosa llamada ‚Äúfelicidad‚Äù que tienen las personas. Quer√©s saber qu√© la causa. Tambi√©n descubr√≠s que en el planeta Tierra hay muchas otras cosas. ¬øCu√°les de todas esas cosas ‚Äîte pregunt√°s‚Äî causan la felicidad? ¬øC√≥mo har√≠a, tu yo-alien√≠gena, para empezar a responder esa pregunta gigante?

Como persona que tiene felicidad, quiz√°s ya tengas algunas corazonadas sobre qu√© la hace cambiar. Por ejemplo: el clima, las amistades, la m√∫sica, el dinero, la educaci√≥n, las drogas, los libros, las pel√≠culas, las creencias, la personalidad, el color de tus zapatos, el largo de tus cejas, cu√°ntos gatos ves por d√≠a, cu√°ntas veces se demora el subte, una provisi√≥n de por vida de chocolate, etc√©tera, etc√©tera (como dir√≠a Willy Wonka), podr√≠an contribuir de alguna forma a la felicidad. Podr√≠a haber muchas causas distintas de la felicidad.

## Si algo causara que otra cosa cambie, ¬øc√≥mo se ver√≠a eso?

Antes de salir a buscar las causas de la felicidad, deber√≠amos prepararnos con algunas herramientas anal√≠ticas que nos permitan identificar c√≥mo se ve una relaci√≥n causal. Si no nos preparamos para lo que podr√≠amos encontrar, no vamos a saber c√≥mo interpretar nuestros propios datos. En cambio, necesitamos anticipar c√≥mo podr√≠an verse esos datos. En concreto, necesitamos saber c√≥mo lucen los datos cuando una cosa *no causa* a otra, y c√≥mo lucen cuando *s√≠* la causa. Este cap√≠tulo trata justamente de esa preparaci√≥n. Advertencia: vamos a descubrir cosas complejas. Por ejemplo, hay patrones que *parecen* mostrar que una cosa causa a otra, incluso cuando en realidad **no la causa**. Aguant√°, ya vamos a verlo.

### Charlie y la f√°brica de chocolate

Imaginemos que la cantidad de chocolate que tiene una persona tiene una influencia causal sobre su nivel de felicidad. Sigamos imaginando que, como Charlie, cuanto m√°s chocolate ten√©s, m√°s feliz sos; y cuanto menos chocolate, menos feliz. Por √∫ltimo, como sospechamos que la felicidad depende tambi√©n de muchas otras cosas en la vida de una persona, anticipamos que la relaci√≥n entre el suministro de chocolate y la felicidad no va a ser perfecta. ¬øQu√© significan estas suposiciones para c√≥mo deber√≠an verse los datos?

El primer paso es recolectar unos datos imaginarios de 100 personas. Caminamos por ah√≠ y le pedimos a las primeras 100 personas que respondan dos preguntas:

1.  ¬øCu√°nto chocolate ten√©s?\
2.  ¬øCu√°n feliz est√°s?

Para hacerlo m√°s sencillo, ambas escalas van de 0 a 100. En la escala de chocolate, 0 significa ‚Äúsin chocolate‚Äù y 100 significa ‚Äúsuministro vitalicio de chocolate‚Äù. Cualquier otro n√∫mero est√° en el medio. En la escala de felicidad, 0 es ‚Äúnada de felicidad‚Äù, 100 es ‚Äútoda la felicidad‚Äù, y los valores intermedios reflejan distintos grados de felicidad en el medio.

Ac√° ten√©s una muestra de datos de los primeros 10 sujetos imaginarios.

```{r 3chocHappy}
sujeto <- 1:100
chocolate <- round(1:100*runif(100,.5,1))
felicidad <- round(1:100*runif(100,.5,1))

the_df_CC <- data.frame(sujeto,chocolate,felicidad)


the_df_short <- the_df_CC[1:10,]

knitr::kable(the_df_short)
```

Le hicimos dos preguntas a cada persona, as√≠ que hay dos valores por persona: uno para su suministro de chocolate, y otro para su nivel de felicidad. Capaz ya not√°s cierta relaci√≥n entre la cantidad de chocolate y el nivel de felicidad en la tabla. Para que esas relaciones se vean a√∫n m√°s claras, vamos a graficar todos los datos.

### Diagramas de dispersi√≥n

Cuando ten√©s dos variables medidas, siempre pod√©s convertirlas en puntos y mostrarlas en un diagrama de dispersi√≥n (*scatter plot*). Un gr√°fico de dispersi√≥n tiene un eje horizontal (x) y un eje vertical (y). Vos eleg√≠s qu√© variable va en qu√© eje. Vamos a poner el suministro de chocolate en el eje x, y el nivel de felicidad en el eje y. La figura @fig-3scatter1 muestra 100 puntos, uno por cada persona.

```{r}
#| label: fig-3scatter1
#| fig-cap: "Datos imaginarios que muestran una correlaci√≥n positiva entre la cantidad de chocolate y el nivel de felicidad"
library(ggplot2)
ggplot(the_df_CC,aes(x=chocolate,y=felicidad))+
  geom_point()+
  theme_classic()


```

Capaz te est√©s preguntando: ¬øpor qu√© hay solo 100 puntos en el gr√°fico? ¬øNo recolectamos 100 medidas de chocolate y 100 de felicidad? ¬øNo deber√≠a haber 200 puntos?\
No. Cada punto representa a una persona. Hay 100 personas, por lo tanto hay 100 puntos.

¬øQu√© significa cada punto? Cada punto tiene dos coordenadas: una en x (chocolate) y una en y (felicidad). El primer punto, abajo a la izquierda, representa a la primera persona de la tabla, que ten√≠a casi 0 de chocolate y casi 0 de felicidad. Pod√©s mirar cualquier punto y trazar una l√≠nea recta hacia abajo hasta el eje x: eso te dice cu√°n ‚Äúchocolatada‚Äù est√° esa persona. Si traz√°s una l√≠nea recta hacia la izquierda hasta el eje y, eso te dice cu√°n feliz est√°.

Ahora que estamos mirando el gr√°fico de dispersi√≥n, podemos ver muchas cosas. Los puntos est√°n algo esparcidos, ¬øno? De ah√≠ viene el nombre ‚Äúdiagrama de dispersi√≥n‚Äù. Incluso cuando no est√°n tan dispersos, se les sigue llamando as√≠. Capaz porque en la vida real los puntos *siempre* se dispersan un poco.\
M√°s importante todav√≠a: los puntos muestran una relaci√≥n entre el suministro de chocolate y la felicidad. Las personas con menos chocolate tienden a tener menos felicidad, y las que tienen m√°s chocolate tienden a ser m√°s felices. Parece que cuanto m√°s chocolate ten√©s, m√°s feliz sos ‚Äîy viceversa. Este tipo de relaci√≥n se llama **correlaci√≥n positiva**.

### Correlaci√≥n positiva, negativa y nula

Ya que estamos en el negocio de imaginar datos, sigamos imaginando un poco m√°s. Ya imaginamos c√≥mo se ver√≠an los datos si tener m√°s chocolate aumentara la felicidad. Vamos a mostrar eso de nuevo en un momento. Pero, ¬øc√≥mo te imagin√°s que se ver√≠a un gr√°fico de dispersi√≥n si la relaci√≥n fuera al rev√©s, y tener m√°s chocolate *disminuyera* la felicidad? ¬øO c√≥mo se ver√≠a si *no hubiera ninguna relaci√≥n* entre la cantidad de chocolate y la felicidad?\
Te invitamos a imaginarlo mirando la figura @fig-3posnegrand:

```{r}
#| label: fig-3posnegrand
#| fig-cap: "Tres diagramas de dispersi√≥n mostrando una correlaci√≥n negativa, positiva, y ausencia de correlaci√≥n"

sujeto_x<-1:100
chocolate_x<-round(1:100*runif(100,.5,1))
happiness_x<-round(1:100*runif(100,.5,1))

df_positive<-data.frame(sujeto_x,chocolate_x,happiness_x)

sujeto_x<-1:100
chocolate_x<-round(1:100*runif(100,.5,1))
happiness_x<-round(100:1*runif(100,.5,1))

df_negative<-data.frame(sujeto_x,chocolate_x,happiness_x)

sujeto_x<-1:100
chocolate_x<-round(runif(100,0,100))
happiness_x<-round(runif(100,0,100))

df_random<-data.frame(sujeto_x,chocolate_x,happiness_x)

all_data<-rbind(df_positive,df_negative,df_random)
all_data<-cbind(all_data,correlation=rep(c("positiva","negativa","nula"),each=100))

ggplot(all_data,aes(x=chocolate_x,y=happiness_x))+
  geom_point()+
  theme_classic()+
  facet_wrap(~correlation)+
  xlab("suministro de chocolate")+
  ylab("felicidad")

```

El primer panel muestra una **correlaci√≥n negativa**. La felicidad disminuye a medida que aumenta el suministro de chocolate. La correlaci√≥n negativa ocurre cuando una variable sube y la otra baja; o sea, cuando tener m√°s de X implica tener menos de Y, y viceversa. El segundo panel muestra una **correlaci√≥n positiva**. La felicidad aumenta a medida que aumenta el suministro de chocolate. En una correlaci√≥n positiva, ambas cosas suben juntas, o bajan juntas: m√°s de X implica m√°s de Y, y viceversa. El tercer panel muestra **ausencia de correlaci√≥n**. En este caso, no parece haber ninguna relaci√≥n clara entre el suministro de chocolate y la felicidad. Los puntos est√°n totalmente dispersos ‚Äîel m√°s disperso de todos los gr√°ficos de dispersi√≥n.

::: callout-note
Nos estamos metiendo en la idea de que las mediciones de dos cosas pueden estar relacionadas, o correlacionadas entre s√≠. Las relaciones pueden ser m√°s complejas que simplemente ‚Äúsube‚Äù o ‚Äúbaja‚Äù. Por ejemplo, podr√≠amos tener una relaci√≥n en la que los puntos suben en la primera mitad del eje X, y bajan en la segunda.
:::

Una correlaci√≥n nula ocurre cuando una cosa no est√° relacionada de ninguna forma con la otra: los cambios en X no tienen ninguna relaci√≥n con los cambios en Y, y viceversa.

## El *r* de Pearson

Ya aprendimos a calcular estad√≠sticos descriptivos para una sola variable, como el chocolate o la felicidad (medias, varianzas, etc.). Pero, ¬øes posible crear un estad√≠stico descriptivo que resuma la relaci√≥n entre **dos** variables, todo en un solo n√∫mero? ¬øSe puede? Karl Pearson al rescate.

::: callout-note
Las historias sobre la invenci√≥n de distintas estad√≠sticas son muy interesantes. Pod√©s leer m√°s sobre eso en el libro *The Lady Tasting Tea* [@salsburg2001lady].
:::

Existe una estad√≠stica para eso, y Karl Pearson la invent√≥. Hoy en d√≠a todxs la llaman el **r de Pearson**. M√°s adelante veremos que Pearson fue editor de *Biometrika* en los a√±os 30. Le ten√≠a bastante bronca a otro estad√≠stico famoso, Sir Ronald Fisher (del que tambi√©n vamos a hablar), y se tiraban con estad√≠sticas... ¬øPor qu√© no podemos simplemente llevarnos bien en estad√≠stica?

¬øC√≥mo funciona el *r* de Pearson? Volvamos a mirar los datos de los primeros 10 sujetos de nuestro experimento ficticio:

```{r 3chocHappyB,echo=F}
library(dplyr)

the_df_short <- the_df_short %>%
  rbind(c("Sumas",colSums(the_df_short[1:10,2:3]))) %>%
  rbind(c("Medias",colMeans(the_df_short[1:10,2:3])))
knitr::kable(the_df_short)
```

¬øQu√© podr√≠amos hacer con estos n√∫meros para obtener un √∫nico valor que resuma la relaci√≥n entre el suministro de chocolate y la felicidad?

### La idea de la covarianza

‚ÄúPor favor no... otra vez no uses la palabra *varianza*‚Äù. S√≠, lo vamos a hacer. Vamos a usar la palabra *varianza* una y otra vez, hasta que tenga sentido.\
Record√° lo que significa la varianza respecto a un conjunto de n√∫meros: significa que los n√∫meros tienen cierta variaci√≥n, que no son todos iguales, que algunos son m√°s grandes y otros m√°s chicos. Podemos ver que hay varianza en el suministro de chocolate entre los 10 sujetos. Tambi√©n hay varianza en los niveles de felicidad. Y tambi√©n vimos, en el gr√°fico de dispersi√≥n, que la felicidad aumenta cuando aumenta el chocolate ‚Äîuna relaci√≥n positiva, una correlaci√≥n positiva. ¬øQu√© tiene que ver eso con la varianza? Bueno, quiere decir que hay una relaci√≥n entre la varianza en el suministro de chocolate y la varianza en los niveles de felicidad. ¬øNo te parece que ambas medidas var√≠an juntas? Cuando tenemos dos variables que var√≠an juntas, son como una pareja feliz que comparte su varianza. Eso es lo que significa **covarianza**: la idea de que el patr√≥n de variaci√≥n en una medida se comparte con el patr√≥n de variaci√≥n en otra.

La **covarianza** es **muy, muy, muy, muy** importante. Sabemos que al principio puede ser una palabra confusa, especialmente si todav√≠a no te sent√≠s del todo c√≥modo con lo que significa varianza en una sola variable. Sin embargo, tenemos que seguir adelante y usar la idea de covarianza una y otra vez, para que quede bien grabada en tu mente estad√≠stica (s√≠, ya lo dijimos, pero repetir ayuda, es una hecho).

> üß† Consejo pro: La carrera de tres piernas es una met√°fora de la covarianza. Dos personas se atan una pierna entre s√≠, y luego intentan caminar. Funciona cuando sus piernas se mueven juntas (relaci√≥n positiva). Tambi√©n pueden moverse juntas de forma torpe, por ejemplo cuando una intenta avanzar justo cuando la otra intenta retroceder. Eso tambi√©n es covarianza (pero negativa). Caminan de forma aleatoria cuando no hay covarianza: cada persona hace lo suyo, sin coordinaci√≥n. Hay mucha varianza, pero la varianza se comparte al azar. Es solo un mont√≥n de piernas movi√©ndose sin lograr nada.

> üß† Consejo pro #2: Jugar bien a las palmas requiere que dos personas coordinen sus acciones. Eso es una covarianza positiva bien compartida.

## Convertir los n√∫meros en una medida de covarianza

‚ÄúOK, si me dec√≠s que *covarianza* es otra forma de decir ‚Äòcorrelaci√≥n‚Äô o ‚Äòrelaci√≥n‚Äô entre dos variables, me sirve. Supongo que deber√≠amos tener alguna forma de medir eso.‚Äù Correcto. Volvamos a nuestra tabla... ¬ønot√°s algo nuevo?

```{r 3chochappyCOV,echo=F}
the_df_temp <- data.frame(sujeto,chocolate,felicidad,Chocolate_X_Felicidad=chocolate*felicidad)

the_df_short <- the_df_temp[1:10,]

the_df_short <- the_df_short %>%
  rbind(c("Sumas",colSums(the_df_short[1:10,2:4]))) %>%
  rbind(c("Medias",colMeans(the_df_short[1:10,2:4])))
knitr::kable(the_df_short)

```

Agregamos una columna nueva, que representa las puntuaciones de Chocolate multiplicadas por las de Felicidad. Cada fila en esa nueva columna es el producto ‚Äîla multiplicaci√≥n entre los puntajes de chocolate y felicidad para esa persona. S√≠, pero ¬øpor qu√© har√≠amos esto?

En el cap√≠tulo anterior te llevamos de vuelta a la escuela primaria para pensar en la divisi√≥n. Ahora vamos a hacer lo mismo con la multiplicaci√≥n. Suponemos que ya sab√©s c√≥mo funciona. Un n√∫mero multiplicado por otro quiere decir que sum√°s el primero tantas veces como indica el segundo:

$2*2= 2+2=4$

$2*6= 2+2+2+2+2+2 = 12$, o $6+6=12$, que es lo mismo.

Todo eso ya lo sab√©s. Pero, ¬øpod√©s usar la multiplicaci√≥n a tu favor y hacer que haga lo que necesit√°s cuando se trata de resumir una covarianza? La multiplicaci√≥n es el droide que est√°s buscando.

Sabemos c√≥mo multiplicar n√∫meros, y lo que tenemos que hacer ahora es pensar en las consecuencias de multiplicar dos conjuntos de n√∫meros. Por ejemplo: ¬øqu√© pasa cuando multiplic√°s dos n√∫meros chicos, en comparaci√≥n con dos n√∫meros grandes? El primer producto deber√≠a ser m√°s chico, ¬øno? ¬øY qu√© pasa si multiplic√°s un n√∫mero chico con uno grande? Los productos deber√≠an quedar en un punto intermedio, ¬øcierto?

El siguiente paso es pensar qu√© pasa cuando sumamos los productos de dos variables, dependiendo de c√≥mo se alinean. Veamos otra tabla:

```{r 3chocHappyCOVb}
the_df_short <- data.frame(puntajes=1:10,X=1:10, Y=1:10, A=1:10, B=10:1, XY = 1:10*1:10, AB=1:10*10:1)

the_df_short <- the_df_short %>%
  rbind(c("Sumas",colSums(the_df_short[1:10,2:7]))) %>%
  rbind(c("Medias",colMeans(the_df_short[1:10,2:7])))
knitr::kable(the_df_short)
```

Observ√° las columnas $X$ y $Y$. Los valores de $X$ y $Y$ covar√≠an perfectamente. Cuando $X$ es 1, $Y$ tambi√©n es 1; cuando $X$ es 2, $Y$ es 2, y as√≠. Est√°n perfectamente alineados.\
Los valores de $A$ y $B$ tambi√©n covar√≠an perfectamente, pero en sentido opuesto. Cuando $A$ es 1, $B$ es 10; cuando $A$ es 2, $B$ es 9, y as√≠. $B$ es una copia invertida de $A$.

Ahora mir√° la columna $XY$. Son los productos que obtenemos al multiplicar cada valor de $X$ con el correspondiente valor de $Y$. Y la columna $AB$ son los productos de $A$ por $B$ en cada fila. Hasta ac√° todo bien.

Ahora observ√° las sumas de las columnas $XY$ y $AB$. No son iguales. La suma de los productos $XY$ es 385, y la suma de los productos $AB$ es 220. En este conjunto de datos en particular los n√∫meros 385 y 220 son muy importantes. Representan la mayor suma posible de productos (385) y la menor suma posible de productos (220). No hay forma de reordenar los n√∫meros del 1 al 10, digamos para $X$ y para $Y$, que produzca una suma mayor o menor. ¬øNo me cre√©s? Mir√° esto:

```{r}
#| label: fig-3simsum
#| fig-cap: "Sumas de productos simuladas que muestran los tipos de valores que pueden producirse al ordenar aleatoriamente los n√∫meros en X e Y."


simulated_sums<-length(0)
for(sim in 1:1000){
X<-sample(1:10)
Y<-sample(1:10)
simulated_sums[sim]<-sum(X*Y)
}
sim_df<-data.frame(sims=1:1000,simulated_sums)
ggplot(sim_df,aes(x=sims,y=simulated_sums))+
  geom_point()+
  theme_classic()+
  geom_hline(yintercept = 385)+
  geom_hline(yintercept = 220)+
  labs(x="simulaciones",y="Sumas simuladas")

```

La @fig-3simsum muestra 1000 simulaciones por computadora. Convenc√≠ a mi computadora de que ordenara al azar los n√∫meros del 1 al 10 para X, y tambi√©n del 1 al 10 para Y. Luego, multiplic√≥ X por Y, y sum√≥ los productos. Hizo esto 1000 veces. Cada punto en el gr√°fico muestra la suma de los productos para una de esas simulaciones. Las dos l√≠neas negras marcan la suma m√°xima posible (385) y la m√≠nima posible (220) para este conjunto de n√∫meros. Not√° c√≥mo todos los puntos est√°n entre esos dos valores. Te lo dije.

‚ÄúOK, est√° bien, me lo advertiste‚Ä¶ ¬øy qu√©? ¬øa qui√©n le importa?‚Äù.\
Est√°bamos buscando una forma de resumir la covarianza entre dos variables, ¬øno? Bueno, para estos n√∫meros, encontramos una: **la suma de los productos**. Sabemos que cuando esa suma da 385, hay una correlaci√≥n perfecta y positiva. Sabemos que si da 220, hay una correlaci√≥n perfecta y negativa. ¬øY qu√© pasa con los n√∫meros que est√°n en el medio? ¬øQu√© podemos concluir sobre la correlaci√≥n si la suma de productos da, por ejemplo, 350?\
Bueno, va a ser positiva, porque est√° cerca de 385, que es correlaci√≥n perfectamente positiva.\
Si la suma de productos fuera 240, va a ser negativa, porque est√° cerca de 220, que es la correlaci√≥n perfectamente negativa.\
¬øY si no hay correlaci√≥n? Entonces la suma va a estar justo en el medio entre 220 y 385, ¬øno?

Lo que acabamos de hacer es inventar una medida de resumen espec√≠fica para estos datos: una forma de cuantificar la correlaci√≥n entre los n√∫meros del 1 al 10 en X, y del 1 al 10 en Y, usando la **suma de productos**. Y como sabemos cu√°l es el m√°ximo (385) y el m√≠nimo (220), ahora podemos interpretar cualquier suma de productos de este tipo de datos respecto a esa escala.

> üß† Consejo pro: Cuando la correlaci√≥n entre dos variables aumenta en direcci√≥n positiva, la suma de sus productos se acerca al valor m√°ximo posible. Esto ocurre porque los n√∫meros grandes en X tienden a alinearse con los n√∫meros grandes en Y, creando la mayor suma de productos. Cuando la correlaci√≥n es negativa, la suma de los productos se acerca al valor m√≠nimo posible, porque los n√∫meros grandes en X se alinean con los n√∫meros peque√±os en Y. Si no hay correlaci√≥n, los n√∫meros grandes de X se alinean aleatoriamente con los grandes y peque√±os de Y, haciendo que la suma quede en un valor intermedio.

### La covarianza como medida

Nos tomamos un tiempo para ver qu√© pasa cuando multiplicamos dos conjuntos de n√∫meros. Descubrimos que:

$$
\text{grande} \times \text{grande} = \text{m√°s grande}
$$

$$
\text{chico} \times \text{chico} = \text{sigue siendo chico}
$$

$$
\text{grande} \times \text{chico} = \text{algo intermedio}
$$

La idea era darte una intuici√≥n conceptual sobre c√≥mo se refleja la **covarianza** entre dos variables en la suma de sus productos. Hicimos algo bien simple: multiplicamos X por Y, y observamos c√≥mo var√≠a la suma de los productos cuando X e Y covar√≠an de diferentes maneras. Ahora podemos ponernos un poco m√°s formales. En estad√≠stica, la **covarianza** no es simplemente multiplicar los valores de X y Y. En realidad, se trata de multiplicar las **desviaciones** de X respecto de su media, por las **desviaciones** de Y respecto de su media. ¬øTe acord√°s de esas diferencias con respecto a la media que vimos en el cap√≠tulo anterior? Bueno, ahora vuelven... pero tranquilos, vuelven en son de paz, como Gaspar√≠n, el fantasma amigable.

Veamos c√≥mo se ve esto en una tabla:

```{r 3cov,echo=F}
the_df<-the_df_CC

the_df_short<-the_df[1:10,]

the_df_short<-cbind(the_df_short,
                    C_d = round((chocolate[1:10]-mean(chocolate[1:10])),digits=2),
                    F_d = round((felicidad[1:10]-mean(felicidad[1:10])),digits=2),
                    Cd_x_Fd = round(((chocolate[1:10]-mean(chocolate[1:10]))* (felicidad[1:10]-mean(felicidad[1:10]))),digits=2))

the_df_short <- the_df_short %>%
  rbind(c("Sumas",round(colSums(the_df_short[1:10,2:6])),digits=2)) %>%
  rbind(c("Medias",round(colMeans(the_df_short[1:10,2:6]),digits=2)))

knitr::kable(the_df_short)

```

Calculamos las desviaciones respecto de la media para las puntuaciones de chocolate (columna `C_d`), y tambi√©n para las de felicidad (columna `F_d`). Despu√©s las multiplicamos (√∫ltima columna). Finalmente, pod√©s ver el promedio de los productos listado en la esquina inferior derecha de la tabla, que muestra la **covarianza** oficial.

La f√≥rmula de la covarianza es:

$cov(X,Y) = \frac{\sum_{i}^{n}(x_{i}-\bar{X})(y_{i}-\bar{Y})}{N}$

OK, ahora tenemos un n√∫mero formal que resume la relaci√≥n entre dos variables. Esto est√° buen√≠simo, era lo que ven√≠amos buscando.\
Sin embargo, hay un problema. ¬øTe acord√°s cuando aprendimos a calcular la **varianza**? Obten√≠amos un n√∫mero y no sab√≠amos bien qu√© hacer con √©l. Estaba al cuadrado, no estaba en la misma escala que los datos originales. Entonces sac√°bamos la ra√≠z cuadrada de la varianza para obtener la **desviaci√≥n est√°ndar**, que era un n√∫mero m√°s interpretable, en la misma escala que los datos.\
Bueno, con la **covarianza** pasa algo parecido. Cuando la calcul√°s como acabamos de hacer, no sab√©s inmediatamente en qu√© escala est√°. ¬øUn valor de 3 es grande? ¬øY 6? ¬ø100? ¬øQu√© tan grande o chico es?

En la discusi√≥n previa sobre covarianza, aprendimos que la suma de productos entre dos variables puede ir de un valor m√≠nimo a un valor m√°ximo. Lo mismo vale para la covarianza. Para un conjunto de datos determinado, hay un valor m√°ximo posible de covarianza positiva (cuando la correlaci√≥n es perfectamente positiva), y un m√≠nimo posible para la negativa (cuando es perfectamente negativa). Y cuando no hay covariaci√≥n, adivin√° qu√© pasa: da cero.

As√≠ que al menos, cuando miramos una covarianza, podemos ver si apunta en direcci√≥n positiva o negativa. Pero **no sabemos cu√°n grande o chica es** en relaci√≥n con los valores m√°ximos o m√≠nimos posibles. Eso significa que **no podemos decir qu√© tan fuerte es la correlaci√≥n**.\
Entonces... ¬øqu√© hacemos?

### ¬øYa llegamos al *r* de Pearson?

S√≠, ya llegamos. ¬øNo estar√≠a bueno si pudi√©ramos forzar nuestra medida de covarianza a estar siempre entre ‚Äì1 y +1?

‚Äì1 ser√≠a el valor m√≠nimo para una correlaci√≥n negativa perfecta.\
+1 ser√≠a el m√°ximo posible para una correlaci√≥n positiva perfecta. 0 indicar√≠a que no hay correlaci√≥n.

Todo lo que est√© entre 0 y ‚Äì1 ser√≠an correlaciones negativas cada vez m√°s fuertes. Todo lo que est√© entre 0 y +1 ser√≠an correlaciones positivas cada vez m√°s fuertes.\
Ser√≠a un sistema fant√°stico, coherente, f√°cil de interpretar. Si tan solo pudi√©ramos forzar el n√∫mero de covarianza a estar entre ‚Äì1 y 1...

Por suerte, este episodio est√° auspiciado por el **r de Pearson**, que hace justamente eso tan maravilloso.

Veamos la f√≥rmula del *r* de Pearson:

$$
r = \frac{\mathrm{cov}(X,Y)}{\sigma_{X}\sigma_{Y}} = \frac{\mathrm{cov}(X,Y)}{\mathrm{SD}_{X}\mathrm{SD}_{Y}}
$$

Aparece el s√≠mbolo $\sigma$ (s√≠, m√°s griego para vos). $\sigma$ es el s√≠mbolo que se usa frecuentemente para la desviaci√≥n est√°ndar.\
Le√≠do en voz alta: *r* es la covarianza de X e Y dividida por el producto de las desviaciones est√°ndar de X y Y. ¬øY por qu√© hacemos esa divisi√≥n? Porque esta operaci√≥n tiene el efecto de **normalizar** la covarianza, forz√°ndola a caer dentro del rango ‚Äì1 a 1.

::: callout-note
M√°s adelante vamos a explicar esta magia matem√°tica... prometido. Pero te adelantamos que no es magia. La explicaci√≥n r√°pida es que dividir cada variable por su desviaci√≥n est√°ndar garantiza que todas las mediciones est√©n en el mismo rango de escala.
:::

Por ahora, pod√©s pensar que es magia matem√°tica. Funciona. Ya despu√©s veremos por qu√©.

Vale decir que existen muchas f√≥rmulas diferentes para calcular el *r* de Pearson. Pod√©s buscarlas en Google y vas a ver varias versiones. Algunas aparecer√°n m√°s adelante en este libro tambi√©n. Pero todas dan el mismo resultado. Algunas son m√°s elegantes que otras. Y algunas pueden parecer un poco intimidantes. En otros libros de estad√≠stica vas a encontrar f√≥rmulas pensadas para facilitar los c√°lculos a mano, por ejemplo si solo ten√©s papel y l√°piz. Para ser honestos, no estamos muy interesados en ense√±arte c√≥mo meter n√∫meros en f√≥rmulas. Damos una sola lecci√≥n sobre eso aqu√≠: pon los n√∫meros donde est√°n las letras y luego calcula el resultado. Perd√≥n por ser sarc√°sticos. Hoy en d√≠a ten√©s una computadora que deber√≠as usar para estas cosas. As√≠ que nuestro inter√©s est√° m√°s en ense√±arte **qu√© significan** los c√°lculos, m√°s que en c√≥mo hacerlos. Claro que igual, cada semana en el laboratorio te mostramos c√≥mo hacer los c√°lculos en la compu, porque eso tambi√©n es importante.

¬øEl *r* de Pearson **siempre** queda entre ‚Äì1 y 1, sin importar qu√© datos uses? S√≠. Mir√° la siguiente simulaci√≥n. Reordenamos al azar los n√∫meros del 1 al 10 para una variable X, y lo mismo para Y. Calculamos el *r* de Pearson y repetimos eso 1000 veces. Como pod√©s ver en la figura @fig-3onethousandr, **todos** los puntos caen entre ‚Äì1 y 1. Tremendo, ¬øno?

## Ejemplos con datos

En el laboratorio sobre correlaci√≥n, vas a aprender a calcular correlaciones con datos reales usando software. Para darte una vista previa, miremos algunos datos del [Informe Mundial de la Felicidad](http://worldhappiness.report) (2018).

Este informe mide diversas actitudes en personas de distintos pa√≠ses. Por ejemplo, una de las preguntas era sobre cu√°nta libertad sent√≠an que ten√≠an para tomar decisiones en la vida. Otra preguntaba cu√°nta confianza ten√≠an en su gobierno nacional. La figura @fig-3hsrdata muestra un gr√°fico de dispersi√≥n con la relaci√≥n entre estas dos variables. Cada punto representa promedios para un pa√≠s diferente.

```{r}
#| label: fig-3hsrdata
#| fig-cap: "Relaci√≥n entre la libertad para tomar decisiones en la vida y la confianza en el gobierno nacional. Datos del Informe Mundial de la Felicidad de 2018"

library(data.table)
library(dplyr)
whr_data <- fread('data/WHR2018.csv')

# seleccionar variables y filtrar valores faltantes

smaller_df <- whr_data %>%
               dplyr::select(country,
                      `Freedom to make life choices`,
                      `Confidence in national government`) %>%
               dplyr::filter(!is.na(`Freedom to make life choices`),
                      !is.na(`Confidence in national government`))

# graficar los datos con l√≠nea de mejor ajuste

ggplot(smaller_df, aes(x=`Freedom to make life choices`,
                     y=`Confidence in national government`))+
  geom_point(alpha=.5)+
  geom_smooth(method=lm, se=FALSE)+
  theme_classic()+
  labs(x="Libertad para tomar decisiones en la vida",y="Confianza en el gobierno nacional")
```

Agregamos una l√≠nea azul al gr√°fico para resumir la relaci√≥n positiva. Parece que, a medida que aumenta la ‚Äúlibertad para tomar decisiones en la vida‚Äù, tambi√©n aumenta la confianza en el gobierno nacional. Es una correlaci√≥n positiva.

La correlaci√≥n real, medida por el *r* de Pearson, es:

```{r}
# calculate correlation

cor(smaller_df$`Freedom to make life choices`,
    smaller_df$`Confidence in national government`)
```

En el laboratorio vas a hacer mucho an√°lisis como este. Al mirar el gr√°fico, podr√≠as empezar a preguntarte: ¬øacaso la libertad para tomar decisiones causa un cambio en la confianza en el gobierno nacional? ¬øO ser√° al rev√©s? ¬øTener confianza en el gobierno hace que uno se sienta m√°s libre para tomar decisiones? ¬øO tal vez esta relaci√≥n es solo una coincidencia sin sentido?\
Todas son buenas preguntas. Pero estos datos **no** nos dan la respuesta. Solo sugieren que *podr√≠a* haber una relaci√≥n.

## Regresi√≥n: una mini introducci√≥n

Ahora vamos a agregar una cosita m√°s a lo que venimos aprendiendo sobre correlaci√≥n. Se llama **regresi√≥n lineal**. Suena intimidante, y... en parte lo es. Mucho m√°s adelante, vas a descubrir que todo lo que estamos por aprender es en realidad un caso especial de la regresi√≥n.\
Pero no queremos que salgas corriendo todav√≠a, as√≠ que ahora solo te presentamos los conceptos b√°sicos.

Primero, miremos una regresi√≥n lineal. As√≠ vas a ver de qu√© estamos hablando. La figura @fig-3regression muestra los mismos diagramas de dispersi√≥n que antes, pero con algo nuevo: ¬°l√≠neas!

```{r}
#| label: fig-3regression
#| fig-cap: "Tres diagramas de dispersi√≥n que muestran una correlaci√≥n negativa, una positiva y una aleatoria (donde se espera que el valor de r sea 0), junto con la l√≠nea de regresi√≥n de mejor ajuste"

sujeto_x<-1:100
chocolate_x<-round(1:100*runif(100,.5,1))
felicidad_x<-round(1:100*runif(100,.5,1))

df_positive<-data.frame(sujeto_x,chocolate_x,felicidad_x)

sujeto_x<-1:100
chocolate_x<-round(1:100*runif(100,.5,1))
felicidad_x<-round(100:1*runif(100,.5,1))

df_negative<-data.frame(sujeto_x,chocolate_x,felicidad_x)

sujeto_x<-1:100
chocolate_x<-round(runif(100,0,100))
felicidad_x<-round(runif(100,0,100))

df_random<-data.frame(sujeto_x,chocolate_x,felicidad_x)

all_data<-rbind(df_positive,df_negative,df_random)
all_data<-cbind(all_data,correlation=rep(c("positiva","negativa","aleatoria"),each=100))

ggplot(all_data,aes(x=chocolate_x,y=felicidad_x))+
  geom_point()+
  theme_classic()+
  geom_smooth(method="lm",se=F)+
  facet_wrap(~correlation)+
  xlab("suministro de chocolate")+
  ylab("felicidad")

```

### La l√≠nea de mejor ajuste

¬øNot√°s algo particular en estas l√≠neas azules? Esperamos que, al menos en los dos primeros paneles, puedas ver que pasan directamente por el medio de los datos, como si fueran un palito de brochette. A estas l√≠neas las llamamos **l√≠neas de mejor ajuste**, porque seg√∫n la definici√≥n que vamos a ver (te prometemos que ya llega), **no hay ninguna otra l√≠nea recta que puedas dibujar que haga un mejor trabajo atravesando los datos**.

Una idea importante ac√° es que estamos usando la l√≠nea como una especie de ‚Äúmedia‚Äù para describir la relaci√≥n entre las dos variables. Cuando solo tenemos una variable, esa variable existe en una dimensi√≥n: es un dato 1D. En ese caso, tiene sentido usar un √∫nico n√∫mero ‚Äîcomo la media‚Äî para describir su tendencia central. Pero cuando tenemos dos variables, y las graficamos juntas, estamos en un espacio bidimensional. Entonces, para ese espacio 2D, podemos usar algo m√°s grande ‚Äîcomo una l√≠nea‚Äî para resumir la tendencia central en la relaci√≥n entre ambas variables.

¬øQu√© esperamos de esa l√≠nea? Bueno, si tuvieras un l√°piz y un gr√°fico impreso, podr√≠as dibujar un mont√≥n de l√≠neas rectas como se te ocurriera. Tus l√≠neas ni siquiera tendr√≠an que pasar por los datos: podr√≠an tener cualquier inclinaci√≥n o direcci√≥n. ¬øSer√≠an todas esas l√≠neas buenas para describir el patr√≥n general de los puntos? La mayor√≠a, no. Las mejores l√≠neas ser√≠an aquellas que siguen el patr√≥n general de los puntos. Pero de entre todas las l√≠neas buenas, ¬øcu√°l es la mejor? ¬øC√≥mo podemos saberlo? ¬øY qu√© significa ‚Äúmejor‚Äù? En resumen: **la l√≠nea de mejor ajuste es aquella que tiene el menor error**.

::: callout-note
C√≥digo R para graficar los residuos, cortes√≠a del blog de Simon Jackson: <https://drsimonj.svbtle.com/visualising-residuals>
:::

Mir√° este pr√≥ximo gr√°fico. Muestra una l√≠nea que atraviesa algunos puntos. Pero tambi√©n muestra unas l√≠neas peque√±as que bajan desde cada punto hasta la l√≠nea. Cada una de esas l√≠neas chiquitas se llama **residuo**. Los residuos te muestran cu√°n lejos est√° cada punto de la l√≠nea. Es una medida de error, y nos dice **qu√© tan equivocada est√°** la l√≠nea. Despu√©s de todo, no todos los puntos est√°n sobre la l√≠nea. Eso significa que **la l√≠nea no representa perfectamente a los datos**. Pero la l√≠nea de mejor ajuste es **la menos equivocada** de todas las posibles.

```{r}
#| label: fig-3regressionResiduals
#| fig-cap: "Los puntos negros representan los datos reales. La l√≠nea azul es la de mejor ajuste. Los puntos blancos indican los valores predichos por la l√≠nea azul. Las l√≠neas rojas muestran el error entre cada punto real y su predicci√≥n. La l√≠nea azul es la mejor porque minimiza ese error."

d <- mtcars
fit <- lm(mpg ~ hp, data = d)
d$predicted <- predict(fit)   # Guardar los valores predichos
d$residuals <- residuals(fit) # Guardar los residuos

ggplot(d, aes(x = hp, y = mpg)) +
  geom_smooth(method = "lm", se = FALSE, color = "lightblue") +  # L√≠nea de regresi√≥n
  geom_segment(aes(xend = hp, yend = predicted, color="red"), alpha = .5) +  # L√≠neas rojas de error
  geom_point() +
  geom_point(aes(y = predicted), shape = 1) +  # Puntos blancos
  theme_classic() +
  theme(legend.position = "none") +
  xlab("X") + ylab("Y")
```

Pasan muchas cosas en la figura @fig-3regressionResiduals. Primero, estamos mirando un diagrama de dispersi√≥n de dos variables, una variable X y una variable Y. Cada punto negro representa los valores reales de esas variables. Pod√©s ver que hay una correlaci√≥n negativa: a medida que X aumenta, Y tiende a disminuir. Trazamos una l√≠nea de regresi√≥n sobre los datos ‚Äîesa es la l√≠nea azul. Tambi√©n aparecen unos puntitos blancos. Esos muestran **d√≥nde la l√≠nea ‚Äúcree‚Äù que deber√≠an estar los puntos negros**. Y est√°n tambi√©n las l√≠neas rojas, que son los residuos de los que ven√≠amos hablando. Cada punto negro tiene una l√≠nea roja que baja (o sube) en l√≠nea recta desde su ubicaci√≥n hasta tocar la l√≠nea. Ya podemos ver que muchos de los puntos **no est√°n sobre la l√≠nea**, as√≠ que sabemos que la l√≠nea se equivoca un poco en cada punto. La l√≠nea roja simplemente hace que sea m√°s f√°cil ver **exactamente cu√°nto se equivoca**.

Lo importante que est√° ocurriendo ac√° es que la l√≠nea azul fue trazada de manera tal que **minimiza la suma total de las l√≠neas rojas**. Por ejemplo, si quisi√©ramos saber **cu√°n equivocada** est√° esta l√≠nea, podr√≠amos juntar todas las l√≠neas rojas, medir cu√°nto miden, y sumar todas esas equivocaciones. Eso nos dar√≠a el **error total**. De hecho, ya hablamos de esta idea cuando discutimos la desviaci√≥n est√°ndar. Lo que realmente vamos a hacer con estas l√≠neas rojas es **elevar al cuadrado su longitud** (para que los valores negativos no se cancelen), y luego **sumarlas**. Esa suma representa el **total de error**. Y esta l√≠nea azul **minimiza esa suma**. Cualquier otra l√≠nea tendr√≠a un error total mayor.

La figura @fig-3regressionGIF es una animaci√≥n que muestra esto en acci√≥n. La animaci√≥n compara la l√≠nea azul (la de mejor ajuste) con otras l√≠neas posibles (en negro). La l√≠nea negra se mueve hacia arriba y abajo. Las l√≠neas rojas muestran el error entre la l√≠nea negra y los puntos de datos. A medida que la l√≠nea negra se acerca a la l√≠nea azul, el error total ‚Äîrepresentado visualmente como un √°rea gris‚Äî **se achica hasta su valor m√≠nimo**. Ese error total se agranda a medida que la l√≠nea negra se aleja de la l√≠nea azul.

::: {.content-visible when-format="html"}
```{r}
#| label: fig-3regressionGIF
#| fig-cap: La l√≠nea azul es la l√≠nea de regresi√≥n que mejor explica la covariaci√≥n entre los puntos negros. La l√≠nea negra se mueve hacia arriba y abajo, mostrando l√≠neas alternativas que podr√≠an trazarse. Las l√≠neas rojas indican el error entre cada punto de datos y la l√≠nea negra. La cantidad total de error est√° representada por el √°rea gris sombreada. Esta √°rea se agranda a medida que la l√≠nea negra se aleja de la l√≠nea azul, y se achica al m√≠nimo cuando la l√≠nea negra se acerca a la l√≠nea de mejor ajuste."
#| out-width: "75%"

knitr::include_graphics(path="imgs/gifs/regression-1.gif")
```
:::

Siempre que la l√≠nea negra no coincida con la l√≠nea azul, es peor que la l√≠nea de mejor ajuste. La l√≠nea de regresi√≥n azul es como Ricitos de Oro: est√° justo en el medio, y es la adecuada.

La figura @fig-3minimizeSS muestra c√≥mo se comporta la suma de las desviaciones al cuadrado (la suma de las longitudes al cuadrado de las l√≠neas rojas) a medida que movemos la l√≠nea hacia arriba y hacia abajo. Lo que est√° ocurriendo aqu√≠ es que estamos calculando una medida del error total a medida que la l√≠nea negra pasa por la l√≠nea de mejor ajuste. Esto representa la suma de las desviaciones al cuadrado. Es decir, elevamos al cuadrado la longitud de cada l√≠nea roja de la animaci√≥n anterior, luego sumamos todas esas l√≠neas rojas al cuadrado y obtenemos el error total (la suma total de las desviaciones al cuadrado).

El gr√°fico de abajo muestra c√≥mo se ve el error total a medida que la l√≠nea negra se acerca y luego se aleja de la l√≠nea de mejor ajuste. Fijate que los puntos en este gr√°fico comienzan altos en el lado izquierdo, luego descienden hasta alcanzar un m√≠nimo en la parte inferior central del gr√°fico. Cuando alcanzan ese punto m√≠nimo, hemos encontrado una l√≠nea que minimiza el error total. Esa es la l√≠nea de regresi√≥n de mejor ajuste.

```{r}
#| label: fig-3minimizeSS
#| fig-cap: "Suma de los errores cuadrados para diferentes l√≠neas con distintas intersecciones. La suma m√≠nima ocurre con la l√≠nea de mejor ajuste."
#| out-width: "75%"

d <- mtcars
fit <- lm(mpg ~ hp, data = d)
d$predicted <- predict(fit)   # Guardar los valores predichos
d$residuals <- residuals(fit) # Guardar los residuos

coefs <- coef(fit)
x <- d$hp
move_line <- seq(-5, 5, 0.5)
total_error <- c(length(move_line))

cnt <- 0
for (i in move_line) {
  cnt <- cnt + 1
  predicted_y <- coefs[2] * x + coefs[1] + i
  error_y <- (predicted_y - d$mpg)^2
  total_error[cnt] <- sum(error_y)
}

df <- data.frame(move_line, total_error)

ggplot(df, aes(x = move_line, y = total_error)) +
  geom_point() +
  theme_classic() +
  ylab("Suma de los errores cuadrados") +
  xlab("Cambio en la intersecci√≥n con el eje y")

```

Todav√≠a no hablamos de la intersecci√≥n con el eje y. Pero este gr√°fico nos muestra c√≥mo se comporta el **error total** al mover la l√≠nea hacia arriba o hacia abajo. La intersecci√≥n con el eje y es lo que estamos cambiando cuando movemos la l√≠nea verticalmente. Como pod√©s ver, el error aumenta cuando bajamos la l√≠nea desde 0 hasta ‚Äì5, y tambi√©n aumenta cuando la subimos desde 0 hasta +5. La mejor l√≠nea ‚Äîla que **minimiza el error**‚Äî ocurre justo en el medio, cuando **no movemos en absoluto** la l√≠nea azul de regresi√≥n.

### L√≠neas

Bueno, dec√≠s. As√≠ que hay una l√≠nea m√°gica que atraviesa el centro del diagrama de dispersi√≥n y minimiza la suma de los errores al cuadrado. ¬øC√≥mo encuentro esa l√≠nea m√°gica? Te lo vamos a mostrar. Pero, para ser completamente honestos, casi nunca vas a hacerlo de la manera que vamos a explicar ac√°. En cambio, es mucho m√°s f√°cil usar software y hacer que la computadora lo calcule por vos. Vas a aprender a hacerlo as√≠ en los laboratorios.

Antes de mostrarte c√≥mo encontrar la l√≠nea de regresi√≥n, vale la pena refrescar la memoria sobre c√≥mo funcionan las l√≠neas, especialmente en 2 dimensiones. ¬øTe acord√°s de esto?

$y = ax + b$, o tambi√©n $y = mx + b$ (A veces se usa $a$ o $m$ para representar la pendiente)

Esta es la f√≥rmula de una l√≠nea recta. Otra forma de escribirla ser√≠a:

$y = \text{pendiente} * x + \text{intercepto}$

La **pendiente** indica la inclinaci√≥n de la l√≠nea, y el **intercepto** o la **intersecci√≥n con el eje y** es el punto donde la l√≠nea cruza el eje vertical. Miremos las l√≠neas de la figura @fig-3twolines.

```{r}
#| label: fig-3twolines
#| fig-cap: "Dos l√≠neas diferentes con distintas intersecciones en el eje y (donde la l√≠nea cruza el eje vertical) y distintas pendientes. Una pendiente positiva hace que la l√≠nea suba de izquierda a derecha. Una pendiente negativa hace que la l√≠nea baje de izquierda a derecha."
#| out-width: "50%"

ggplot()+
  geom_abline(slope=1,intercept=5,color="blue")+
  geom_abline(slope=-1, intercept=15, color="red")+
  lims(x = c(1,20), y = c(0,20))+
  theme_classic()

```

La f√≥rmula para la l√≠nea azul es: $y = 1*x + 5$. Hablemos de eso. Cuando $x=0$ , ¬ød√≥nde est√° la l√≠nea azul en el eje y? Est√° en 5.\
Eso pasa porque 1 multiplicado por 0 es 0, y entonces nos queda solo el 5. ¬øY qu√© pasa cuando $x = 5$? En ese caso:

$y = 1*x + 5y = 1*5 + 5 = 5 + 5 = 10$

La idea de la f√≥rmula es decirte d√≥nde est√° $y$, para cualquier valor de $x$. La pendiente de la l√≠nea te indica si la l√≠nea sube o baja cuando te mov√©s de izquierda a derecha. La l√≠nea azul tiene una pendiente positiva de uno, as√≠ que sube a medida que $x$ aumenta. ¬øCu√°nto sube? Sube uno por cada unidad de $x$. Si hici√©ramos que la pendiente fuera 2, la l√≠nea ser√≠a mucho m√°s empinada y subir√≠a m√°s r√°pido. La l√≠nea roja tiene pendiente negativa, as√≠ que se inclina hacia abajo. Eso significa que $y$ disminuye a medida que $x$ aumenta. Y si no hay pendiente ‚Äîes decir, queremos una l√≠nea completamente horizontal‚Äî, simplemente ponemos la pendiente en 0. Eso significa que $y$ **no cambia nada**, aunque $x$ aumente o disminuya.

Eso son las l√≠neas.

### Calcular la l√≠nea de mejor ajuste

Si ten√©s un diagrama de dispersi√≥n que muestra la ubicaci√≥n de puntajes de dos variables, la verdadera pregunta es: ¬øc√≥mo encontr√°s la pendiente y la intersecci√≥n con el eje y de la mejor l√≠nea de ajuste? ¬øQu√© vas a hacer? ¬øDibujar millones de l√≠neas, sumar los residuos y ver cu√°l es la mejor? Eso llevar√≠a una eternidad. Por suerte, existen las computadoras. Y si no ten√©s una a mano, tambi√©n hay algunas f√≥rmulas √∫tiles.

::: callout-note
Vale la pena mencionar cu√°nto cambiaron las cosas desde que existen las computadoras. Antes, todo el mundo ten√≠a que hacer estos c√°lculos a mano ‚Äî¬°un embole total! M√°s all√° de las ideas matem√°ticas profundas detr√°s de las f√≥rmulas, muchas fueron dise√±adas por conveniencia, para facilitar los c√°lculos a mano, porque no hab√≠a computadoras. Ahora que las tenemos, hacer las cuentas a mano suele ser solo un ejercicio de √°lgebra‚Ä¶ Tal vez sirve para forjar el car√°cter. Vos decid√≠s.
:::

Te vamos a mostrar las f√≥rmulas. Y vamos a resolver un ejemplo a mano. S√≠, lo sabemos: es un horror. Por cierto, deber√≠as sentir un poco de l√°stima por m√≠ mientras hago todo esto a mano por vos.

Ac√° est√°n las dos f√≥rmulas que pod√©s usar para calcular la pendiente y la intersecci√≥n directamente desde los datos.\
No vamos a explicar por qu√© hacen lo que hacen. Estas son solo f√≥rmulas ‚Äúpr√°cticas‚Äù para facilitar los c√°lculos:

$\text{intercepto} = b = \frac{\sum{y}\sum{x^2}-\sum{x}\sum{xy}}{n\sum{x^2}-(\sum{x})^2}$

$\text{pendiente}= m = \frac{n\sum{xy}-\sum{x}\sum{y}}{n\sum{x^2}-(\sum{x})^2}$

En estas f√≥rmulas, $x$ e $y$ se refieren a los puntajes individuales. Ac√° ten√©s una tabla que muestra c√≥mo encajan todas las partes.

```{r 3morcov}
scores<-c(1,2,3,4,5,6,7)
x<-c(1,4,3,6,5,7,8)
y<-c(2,5,1,8,6,8,9)
x_squared<-x^2
y_squared<-y^2
xy<-x*y

all_df<-data.frame(scores,x,y,x_squared,y_squared,xy)

all_df <- all_df %>%
  rbind(c("Sumas",colSums(all_df[1:7,2:6]))) 

slope=((sum(y)*sum(x_squared))-(sum(x)*sum(xy)))/((7*sum(x_squared))-sum(x)^2)
intercept=(7*sum(xy)-sum(x)*sum(y))/(7*sum(x_squared)-sum(x)^2)

knitr::kable(all_df)

```

Vemos 7 pares de valores para las variables $x$ e $y$. Calculamos $x^2$ elevando al cuadrado cada valor de $x$, y lo pusimos en una columna.\
Hicimos lo mismo con $y^2$. Despu√©s calculamos $xy$, multiplicando cada valor de $x$ con su correspondiente valor de $y$, y tambi√©n lo pusimos en una columna.\
Finalmente, sumamos todas las columnas y pusimos esos totales al final.\
Esos son los n√∫meros que necesitamos para usar las f√≥rmulas y encontrar la mejor l√≠nea de ajuste.

As√≠ se ven las f√≥rmulas con los n√∫meros incluidos:

$\text{intercepto} = b = \frac{\sum{y}\sum{x^2}-\sum{x}\sum{xy}}{n\sum{x^2}-(\sum{x})^2} = \frac{39 * 200 - 34*231}{7*200-34^2} = -.221$

$\text{pendiente} = m = \frac{n\sum{xy}-\sum{x}\sum{y}}{n\sum{x^2}-(\sum{x})^2} = \frac{7*231-34*39}{7*275-34^2} = 1.19$

Genial. Ahora podemos verificar si lo hicimos bien.\
Vamos a graficar los datos en un diagrama de dispersi√≥n y trazar una l√≠nea con pendiente = 1.19 y una intersecci√≥n en el eje y de ‚Äì0.221.\
Como se muestra en la figura @fig-3corwithLine, la l√≠nea deber√≠a atravesar el centro de los puntos.

```{r}
#| label: fig-3corwithLine
#| fig-cap: "Ejemplo de una l√≠nea de regresi√≥n con bandas de confianza que atraviesa algunos puntos en un diagrama de dispersi√≥n"
#| out-width: "75%"

plot_df<-data.frame(x,y)

ggplot(plot_df,aes(x=x,y=y))+
  geom_point()+
  geom_smooth(method="lm",se=FALSE)+
  theme_classic()

#coef(lm(y~x,plot_df))
```

## Interpretar correlaciones

¬øQu√© significa que haya ‚Äîo no haya‚Äî una correlaci√≥n entre dos medidas? ¬øC√≥mo deber√≠an interpretarse las correlaciones? ¬øQu√© tipo de inferencias se pueden hacer a partir de una correlaci√≥n? Todas estas son preguntas excelentes.\
El primer consejo es: **ten√© cuidado al interpretar correlaciones**. Y ahora te contamos por qu√©.

### Correlaci√≥n no implica causalidad

Probablemente ya escuchaste que ‚Äúcorrelaci√≥n no implica causalidad‚Äù. ¬øPero por qu√© no? Hay muchas razones. Sin embargo, antes de meternos con las razones, empecemos con un caso en el que **s√≠** esperar√≠amos una conexi√≥n causal entre dos medidas.

Supongamos que compr√°s una planta serpiente (Sansevieria) para tu casa. Estas plantas son conocidas por ser f√°ciles de cuidar, porque casi no requieren atenci√≥n.\
Como la mayor√≠a de las plantas, necesitan algo de agua para sobrevivir. Pero tambi√©n necesitan **la cantidad justa** de agua.

Imaginemos un experimento donde cultiv√°s 1000 plantas serpiente en tu casa. Cada planta recibe una cantidad diferente de agua por d√≠a, desde 0 cucharaditas hasta 1000 cucharaditas por d√≠a. Vamos a asumir que el agua forma parte del proceso causal que permite que las plantas crezcan.\
Entonces, la cantidad de agua por d√≠a ser√≠a una de nuestras medidas. Y cada semana, med√≠s cu√°nto crecieron las plantas. Esa ser√≠a la segunda medida.

¬øTe pod√©s imaginar c√≥mo se ver√≠a un gr√°fico de dispersi√≥n con estos datos? Eje X: cucharaditas de agua por d√≠a. Eje Y: crecimiento semanal de la planta.

#### Incluso cuando hay causalidad, puede que no haya correlaci√≥n clara

La primera planta, que no recibe nada de agua, seguramente lo va a pasar mal y eventualmente morir. Deber√≠a mostrar el menor crecimiento semanal.\
¬øY las plantas que reciben solo unas pocas cucharaditas al d√≠a? Quiz√°s reciban justo lo necesario para mantenerse vivas, pero no para crecer mucho.\
Si est√°s imaginando un gr√°fico de dispersi√≥n, cada punto ser√≠a una planta. Algunos puntos deber√≠an estar en la esquina inferior izquierda (nada de agua = nada de crecimiento). A medida que aumenta el agua, los puntos deber√≠an ir subiendo hacia la derecha: m√°s agua, m√°s crecimiento.

¬øPero qu√© pasa cuando le das **demasiada** agua a una planta serpiente? Por experiencia personal: se muere.\
As√≠ que en alg√∫n momento, los puntos del gr√°fico deber√≠an empezar a **bajar** otra vez. Las plantas que reciben **demasiada** agua no crecen bien.

Ese gr√°fico imaginario tendr√≠a una forma de U invertida. De izquierda a derecha, los puntos suben, llegan a un m√°ximo, y despu√©s vuelven a bajar.\
¬øY qu√© pasa si calcul√°s el *r* de Pearson con esos datos? Te puede dar un valor cercano a 0. El gr√°fico de dispersi√≥n se ver√≠a m√°s o menos como en la figura @fig-3snakeplant.

```{r}
#| label: fig-3snakeplant
#| fig-cap: "Ilustraci√≥n de una posible relaci√≥n entre la cantidad de agua y el crecimiento de la planta serpiente. El crecimiento aumenta con el agua, pero eventualmente vuelve a disminuir, porque demasiada agua hace que las plantas mueran."

water<-seq(0,999,1)
growth<-c(seq(0,10,(10/499)),seq(10,0,-(10/499)))
noise<-runif(1000,-2,2)
growth<-growth+noise
snake_df<-data.frame(growth,water)

ggplot(snake_df, aes(x=water,y=growth))+
  geom_point()+
  theme_classic()+
  xlab("Agua (cucharaditas)") +
  ggtitle("Crecimiento imaginario de una planta serpiente\n en funci√≥n del agua")

```

Es cierto que parece m√°s una V invertida que una U invertida, pero se entiende la idea, ¬øno? Hay claramente una relaci√≥n entre el riego y el crecimiento de la planta serpiente. Pero esa relaci√≥n **no es en una sola direcci√≥n**. Como resultado, cuando calculamos el *r* de Pearson, obtenemos un valor que sugiere **que no hay relaci√≥n**.

```{r}
cor(growth,water)
```

Lo que esto significa, en realidad, es que **no hay una relaci√≥n lineal** que se pueda describir con una sola l√≠nea recta. Cuando necesitamos l√≠neas o curvas que cambien de direcci√≥n, estamos ante una relaci√≥n **no lineal**.

Este ejemplo muestra algunas complicaciones al interpretar correlaciones. Ya sabemos que las plantas necesitan agua para crecer, as√≠ que esperamos que haya alguna relaci√≥n entre la cantidad de agua y el crecimiento.\
Si miramos solo la primera mitad de los datos, vemos una correlaci√≥n positiva.\
Si miramos solo la segunda mitad, vemos una correlaci√≥n negativa.\
Y si miramos todos los datos juntos, **no vemos ninguna correlaci√≥n**.\
Uf. Entonces, **incluso cuando hay una conexi√≥n causal entre dos variables**, eso no garantiza que obtengamos evidencia clara al calcular un coeficiente de correlaci√≥n.

> üß† Consejo pro: Esta es una de las razones por las que es tan importante graficar tus datos. Si ves un patr√≥n en forma de U invertida, entonces un an√°lisis de correlaci√≥n probablemente **no sea el mejor** para esos datos.

#### Variable confundida, o problema de la tercera variable

Cualquiera puede correlacionar dos cosas que se puedan medir. Por ejemplo, podr√≠amos tomar a 100 personas y preguntarles todo tipo de cosas, como:

1.  ¬øQu√© tan feliz sos?\
2.  ¬øQu√© edad ten√©s?\
3.  ¬øCu√°nto med√≠s?\
4.  ¬øCu√°nto gan√°s por a√±o?\
5.  ¬øQu√© tan largas son tus pesta√±as?\
6.  ¬øCu√°ntos libros le√≠ste en tu vida?\
7.  ¬øQu√© tan fuerte es tu voz interior?

Supongamos que encontramos una correlaci√≥n positiva entre el salario anual y la felicidad. Not√° que podr√≠amos haber hecho exactamente lo mismo correlacionando felicidad con salario.\
Si encontramos una correlaci√≥n, ¬øte animar√≠as a decir que el salario **causa** felicidad?\
Tal vez tiene algo que ver. Pero algo como la felicidad seguramente tiene **muchas causas**.\
La plata podr√≠a hacer feliz a algunas personas directamente.\
Pero, m√°s probablemente, la plata les permite acceder a otras cosas‚Ä¶ y quiz√°s algunas de esas cosas s√≠ generen felicidad.\
A esas ‚Äúotras cosas‚Äù les decimos **variables de tercer orden** o **terceras variables**.

Por ejemplo: quiz√°s las personas que viven en lugares m√°s lindos, con casas m√°s caras, son m√°s felices que quienes viven en lugares peores, con casas m√°s baratas.\
En ese escenario, no ser√≠a la plata la que causa felicidad, sino **los lugares y casas que la plata puede comprar**.\
Y aunque eso fuera cierto, las personas pueden ser m√°s o menos felices en un mont√≥n de situaciones diferentes.

La lecci√≥n ac√° es que una correlaci√≥n puede aparecer entre dos medidas debido a una **tercera variable no medida directamente**.\
Entonces, aunque encontremos una correlaci√≥n, **no significa que podamos concluir** nada firme sobre causalidad.

### Correlaci√≥n y el azar

Otro aspecto muy importante de las correlaciones es el hecho de que **pueden producirse por puro azar**. Esto significa que pod√©s encontrar una correlaci√≥n positiva o negativa entre dos medidas **aunque no tengan absolutamente nada que ver una con la otra**. Tal vez esperar√≠as que la correlaci√≥n fuera cero cuando dos medidas est√°n completamente desligadas. Aunque eso puede pasar, tambi√©n puede suceder que dos variables no relacionadas produzcan **correlaciones espurias** simplemente por azar.

Vamos a demostrar c√≥mo pueden aparecer correlaciones por azar incluso cuando no hay ninguna conexi√≥n causal entre las medidas. Imagin√° dos personas participantes. Una est√° en el Polo Norte con una m√°quina de loter√≠a llena de bolillas numeradas del 1 al 10. La otra est√° en el Polo Sur, con otra m√°quina diferente pero tambi√©n con bolillas del 1 al 10. Hay un suministro infinito de bolillas en cada m√°quina, as√≠ que cualquier n√∫mero puede salir en cualquier momento. Cada participante elige 10 bolillas al azar y anota los n√∫meros. En este caso vamos a asumir que no hay forma de que las bolillas elegidas por un participante puedan influir causalmente en las del otro. Est√°n en extremos opuestos del planeta. As√≠ que debemos asumir que los n√∫meros son elegidos **por azar puro**.

Esto es lo que podr√≠an mostrar los n√∫meros elegidos por cada participante:

```{r 3northsouth}

Bolilla<-1:10
Polo_norte<-round(round(runif(10,1,10)))
Polo_sur<-round(round(runif(10,1,10)))

the_df_balls<-data.frame(Bolilla,Polo_norte,Polo_sur)

#the_df_balls <- the_df_balls %>%
#  rbind(c("Sums",colSums(the_df_balls[1:10,2:3]))) %>%
#  rbind(c("Means",colMeans(the_df_balls[1:10,2:3])))
knitr::kable(the_df_balls)

```

En este caso puntual, si calculamos el *r* de Pearson, podr√≠amos obtener, por ejemplo, un valor como ( r = 0.51 ). Pero ya sabemos que **ese valor no nos dice nada** sobre la relaci√≥n entre las bolillas del Polo Norte y las del Polo Sur. Sabemos que esa relaci√≥n **deber√≠a ser completamente aleatoria**, porque as√≠ dise√±amos el experimento.

La mejor pregunta en este caso no es ‚Äú¬øcu√°l fue la correlaci√≥n?‚Äù, sino **¬øqu√© puede producir el azar?**\
Por ejemplo: si repiti√©ramos este juego una y otra vez miles de veces ‚Äîcada vez eligiendo bolillas nuevas y cada vez calculando la correlaci√≥n‚Äî, ¬øqu√© obtendr√≠amos?

Primero, notar√≠amos **variaci√≥n**. El valor de *r* a veces ser√≠a positivo, a veces negativo, a veces grande y a veces peque√±o.\
Segundo, podr√≠amos ver **c√≥mo se ve esa variaci√≥n**. Esto nos dar√≠a una ventana hacia los tipos de correlaciones que **el azar, por s√≠ solo, puede producir**.

Vamos a ver qu√© pasa.

#### Simulaci√≥n Monte Carlo de correlaciones aleatorias

Es posible usar una computadora para simular nuestro juego tantas veces como queramos. Este proceso se conoce como **simulaci√≥n Monte Carlo**.

Abajo hay un script escrito en el lenguaje de programaci√≥n R. No vamos a entrar en los detalles del c√≥digo ahora. Pero vamos a explicar brevemente qu√© est√° haciendo. Fijate en la parte que dice que se crea un bucle que repite nuestro juego 1000 veces. Dentro del bucle hay variables llamadas, por ejemplo, `x` e `y`. Durante cada simulaci√≥n, se generan al azar 10 n√∫meros (entre 1 y 10) para cada variable. Esos n√∫meros representan las bolillas que habr√≠an salido de la m√°quina de loter√≠a. Una vez que tenemos los 10 n√∫meros para cada una, calculamos la correlaci√≥n usando `cor(x, y)`. Luego, guardamos ese valor de correlaci√≥n y pasamos a la pr√≥xima simulaci√≥n. Al final, vamos a tener 1000 valores de correlaci√≥n de Pearson.

```{r}
#| label: fig-3anotherthousand
#| fig-cap: "Otra figura que muestra el rango de valores de r que pueden obtenerse por azar."
#| echo: true

correlaciones_simuladas <- length(0)
for(sim in 1:1000){
  Polo_norte <- runif(10,1,10)
  Polo_sur <- runif(10,1,10)
  correlaciones_simuladas[sim] <- cor(Polo_norte,Polo_sur)
}

sim_df <- data.frame(simulaciones=1:1000,correlaciones_simuladas)

ggplot(sim_df, aes(x = simulaciones, y = correlaciones_simuladas))+
  geom_point()+
  theme_classic()+
  geom_hline(yintercept = -1)+
  geom_hline(yintercept = 1)+
  ggtitle("Simulaci√≥n de 1000 valores de r")
```

La @fig-3anotherthousand muestra esos 1000 valores de $r$ obtenidos en la simulaci√≥n. ¬øTe resulta familiar el gr√°fico? Ya hicimos una simulaci√≥n parecida antes. Cada punto en el gr√°fico representa el valor de ( r ) de una de las 1000 simulaciones. Como ves, los puntos est√°n por todos lados, entre ‚Äì1 y 1. La lecci√≥n importante ac√° es que **el azar produjo todas estas correlaciones**. Eso quiere decir que podemos encontrar ‚Äúcorrelaciones‚Äù en los datos que son completamente **sin sentido**, y que no reflejan ninguna relaci√≥n causal entre una medida y otra.

Vamos a ilustrar esta idea de encontrar correlaciones ‚Äúal azar‚Äù una vez m√°s, con una peque√±a animaci√≥n. Esta vez, te vamos a mostrar un gr√°fico de dispersi√≥n con los valores aleatorios de las bolillas elegidas desde el Polo Norte y el Polo Sur. Si no hay relaci√≥n, deber√≠amos ver puntos por todos lados. Si llega a aparecer una relaci√≥n positiva (por pura casualidad), los puntos ir√°n de abajo a la izquierda hacia arriba a la derecha. Si aparece una relaci√≥n negativa (tambi√©n por azar), los puntos ir√°n de arriba a la izquierda hacia abajo a la derecha.

Una cosa m√°s para prepararte para la animaci√≥n: abajo, en la figura @fig-3reminder, hay tres diagramas de dispersi√≥n que muestran correlaciones negativa, positiva y nula entre dos variables. Ya viste ese gr√°fico antes. Solo te estamos recordando que las l√≠neas azules ayudan a ver la direcci√≥n de la correlaci√≥n.\
Las correlaciones negativas ocurren cuando la l√≠nea baja de izquierda a derecha.\
Las positivas, cuando la l√≠nea sube de izquierda a derecha.\
Y las correlaciones nulas, cuando la l√≠nea es plana (ni sube ni baja).

Ok, ahora estamos listos para la animaci√≥n. La figura @fig-3randcor10gif muestra el proceso de muestreo aleatorio de dos conjuntos de n√∫meros: uno para la variable X y otro para la variable Y. Cada vez tomamos 10 n√∫meros para cada variable, los graficamos, y trazamos una l√≠nea a trav√©s de los puntos. Record√°: estos n√∫meros son completamente aleatorios, as√≠ que deber√≠amos esperar, en promedio, **que no haya correlaci√≥n entre ellos**. Sin embargo, eso **no es lo que pasa**. Pod√©s ver c√≥mo la l√≠nea cambia todo el tiempo. A veces encontramos una correlaci√≥n negativa (la l√≠nea baja), otras veces una correlaci√≥n positiva (la l√≠nea sube), y otras veces parece que no hay ninguna correlaci√≥n (la l√≠nea es m√°s plana).

::: {.content-visible when-format="html"}
```{r}
#| label: fig-3randcor10gif
#| out.width: "75%"
#| fig-cap: "Puntos de datos completamente aleatorios tomados de una distribuci√≥n uniforme, con un tama√±o muestral peque√±o de 10. La l√≠nea azul gira a veces mostrando correlaciones grandes que se producen por azar"


knitr::include_graphics(path="imgs/gifs/corUnifn10-1_es.gif")
```
:::

```{r,echo=F, eval=FALSE}
library(gganimate)

all_df<-data.frame()
for(sim in 1:10){
  Polo_norte <- runif(10,1,10)
  Polo_sur <- runif(10,1,10)
  t_df<-data.frame(simulation=rep(sim,10),
                                  Polo_norte,
                                  Polo_sur)
  all_df<-rbind(all_df,t_df)
}


ggplot(all_df,aes(x=Polo_norte,y=Polo_sur))+
  geom_point()+
  geom_smooth(method=lm, se=FALSE)+
  theme_classic()+
  ggtitle("Pseudo correlaciones de dos variables aleatorias")+
  transition_states(
    simulation,
    transition_length = 2,
    state_length = 1
  )+enter_fade() + 
  exit_shrink() +
  ease_aes('sine-in-out')
  
```

Capaz est√°s pensando que esto es un poco inquietante. Si sabemos que no deber√≠a haber ninguna correlaci√≥n entre dos variables aleatorias, ¬øc√≥mo puede ser que estemos encontrando correlaciones? ¬øNo es un gran problema? O sea, si alguien me muestra una correlaci√≥n entre dos cosas y me dice que est√°n relacionadas, ¬øc√≥mo puedo saber si eso es verdad? Despu√©s de todo, ¬°podr√≠a ser pura suerte! El azar tambi√©n puede producir eso.

Por suerte, no todo est√° perdido. Podemos mirar nuestros datos simulados de otra manera, usando un histograma. ¬øTe acord√°s que antes de la animaci√≥n hicimos 1000 simulaciones con n√∫meros aleatorios y calculamos el valor de (r) para cada una? Si ponemos todos esos valores de (r) en un histograma, vamos a tener una mejor idea de c√≥mo se comporta el azar. Vamos a ver qu√© tipo de correlaciones es m√°s o menos probable que el azar produzca.

La figura @fig-3histrandcor muestra ese histograma de los valores simulados de $r$.

```{r}
#| label: fig-3histrandcor
#| fig-cap: "Histograma que muestra la distribuci√≥n de frecuencia de los valores de r obtenidos entre dos variables X e Y completamente aleatorias (tama√±o muestral = 10). Todo el rango de valores de r puede surgir solo por azar. Los valores grandes de r son menos comunes que los peque√±os."

hist(correlaciones_simuladas,breaks=seq(-1,1,.1))
```

Not√° que este histograma **no es plano**. La mayor√≠a de los valores de (r) simulados est√°n **cerca de cero**. Y tambi√©n pod√©s ver que las barras se achican a medida que te alej√°s de cero, ya sea en direcci√≥n positiva o negativa. El mensaje principal ac√° es que el azar puede producir un rango amplio de correlaciones. Sin embargo, **no todas ocurren con la misma frecuencia**. Por ejemplo, las barras cercanas a ‚Äì1 y 1 son muy bajas. El azar **casi nunca** produce correlaciones perfectas. Las barras alrededor de ‚Äì0.5 y 0.5 tambi√©n son m√°s chicas que las del centro: eso significa que correlaciones medianas **no son tan comunes** cuando los datos son puramente aleatorios.

Pod√©s pensar este histograma como una especie de ‚Äú**ventana del azar**‚Äù. Te muestra lo que el azar **suele hacer**, y lo que **suele no hacer**. Ahora imaginemos que est√°s trabajando con un conjunto real de datos, no con datos simulados. Y calcul√°s un valor de ( r = 0.7 ). ¬øQu√© significa eso? ¬øEs un valor de correlaci√≥n grande? ¬øO podr√≠a haber sido generado por azar?

Una forma de pensar esta pregunta es usar el histograma del azar como ‚Äúventana‚Äù. Si tu valor de ( r ) cae en el centro del histograma ‚Äîdigamos, cerca de 0‚Äî, entonces es muy probable que el azar haya podido generarlo. Pero si tu valor est√° lejos del centro ‚Äîdigamos, cerca de ‚Äì0.8 o +0.8‚Äî, entonces es poco probable que lo haya generado el azar. Eso te da m√°s confianza de que tu valor de ( r ) representa algo real.

Esta idea es muy parecida a la l√≥gica del **p-valor**, que vas a aprender m√°s adelante en el curso. La idea es que mir√°s tus datos, calcul√°s una estad√≠stica (como ( r )), y despu√©s te pregunt√°s: ‚Äú¬øqu√© tan probable es que este valor haya sido generado por azar?‚Äù. Si la respuesta es ‚Äúmuy poco probable‚Äù, entonces pod√©s tener m√°s confianza en que el patr√≥n que ves en tus datos **no se debe simplemente al azar**.

### El tama√±o de muestra reduce el poder del azar

En todo este cap√≠tulo estuvimos usando ejemplos con muestras peque√±as ‚Äîpor ejemplo, 10 valores por variable. Pero, ¬øqu√© pasa si us√°s muestras m√°s grandes?

Vamos a repetir la simulaci√≥n de Monte Carlo, pero esta vez con diferentes tama√±os muestrales. La figura @fig-3corrandN muestra cuatro histogramas diferentes, que muestran valores de ( r ) generados por azar para tama√±os de muestra de 10, 50, 100 y 1000.

Fijate en lo que pasa cuando aumentamos el tama√±o muestral. Con muestras peque√±as (como 10), el azar puede producir una gran variedad de valores de ( r ). Pero a medida que aument√°s el tama√±o de la muestra, el histograma se vuelve m√°s angosto. Eso significa que el azar tiene **menos poder** para producir valores extremos de ( r ).

Entonces, si trabaj√°s con una muestra grande y encontr√°s un valor de ( r ) bastante alejado de cero, es mucho m√°s probable que ese valor **represente una relaci√≥n real** y **no simplemente el azar**.

Gracias. A continuaci√≥n te traduzco fielmente esta secci√≥n del cap√≠tulo, incluyendo las leyendas, explicaciones y descripci√≥n de las animaciones, y recordando insertar los `chunks` de c√≥digo donde correspondan:

La figura @fig-3corrandN muestra cuatro histogramas diferentes con los valores de correlaci√≥n de Pearson ( r ) para cada uno de los escenarios. Cada escenario involucra un tama√±o muestral distinto: 10, 50, 100 y 1000.

```{r}
#| label: fig-3corrandN
#| fig-cap: "Histograma de 1000 valores simulados de r, generados al azar, con diferentes tama√±os muestrales. Cada panel muestra el histograma para N = 10, 50, 100 y 1000. Cuanto m√°s grande el tama√±o muestral, m√°s cerca de 0 tienden los valores de r generados por azar."


all_df<-data.frame()
for(s_size in  c(10,50,100,1000)){
  simulated_correlations <- length(0)
  for(sim in 1:1000){
    North_pole <- runif(s_size,1,10)
    South_pole <- runif(s_size,1,10)
    simulated_correlations[sim] <- cor(North_pole,South_pole)
  }
sim_df <- data.frame(sample_size=rep(s_size,1000),sims=1:1000,simulated_correlations)
all_df<-rbind(all_df,sim_df)
}


ggplot(all_df,aes(x=simulated_correlations))+
  geom_histogram()+
  facet_wrap(~sample_size)+
  theme_classic()+
  labs(x="Correlaci√≥n simulada",y="Frecuencia")

```

Si observ√°s los cuatro histogramas, deber√≠as notar un patr√≥n claro. El ancho o rango de cada histograma se achica a medida que aumenta el tama√±o muestral. ¬øQu√© est√° pasando ac√°? Bueno, ya sabemos que podemos pensar estos histogramas como ventanas del azar. Nos muestran qu√© valores de ( r ) ocurren con m√°s frecuencia, y cu√°les no.

Cuando el tama√±o muestral es 10, aparecen muchos valores diferentes de ( r ). Ese histograma es bastante plano y extendido. Pero a medida que el tama√±o muestral aumenta, vemos que la ventana del azar se vuelve m√°s angosta. Por ejemplo, cuando llegamos a N = 1000, casi todos los valores de ( r ) est√°n muy cerca de 0.

Una conclusi√≥n importante es que **aumentar el tama√±o muestral estrecha la ventana del azar**. Entonces, si hac√©s un estudio con 1000 observaciones por variable y encontr√°s una correlaci√≥n de 0.5, pod√©s mirar el histograma de abajo a la derecha y ver que ese valor **no ocurre muy seguido solo por azar**. De hecho, puede que no aparezca ni una sola vez en 1000 simulaciones.\
Como resultado, si ten√©s una muestra grande como N = 1000 y encontr√°s una correlaci√≥n observada de 0.5, pod√©s estar m√°s seguro de que **no es espuria**. Si no fue el azar el que la produjo, entonces **algo m√°s s√≠ lo hizo**.

Por √∫ltimo, not√° c√≥mo tu confianza respecto a si el azar est√° afectando tus resultados depende **del tama√±o de tu muestra**. Si solo ten√©s 10 observaciones por variable y encontr√°s ( r = 0.5 ), no deber√≠as estar tan seguro de que refleja una relaci√≥n real. Como ves, valores de ( r = 0.5 ) ocurren bastante seguido **solo por azar** cuando la muestra es peque√±a.

> üß† Consejo pro: cuando dise√±√°s un experimento, vos decid√≠s cu√°ntas muestras vas a recolectar. Eso significa que pod√©s elegir **estrechar la ventana del azar**. As√≠, si encontr√°s una relaci√≥n en los datos, pod√©s tener m√°s confianza en que es real, y no un simple capricho del azar.

### Algunas pel√≠culas m√°s

Vamos a reforzar estas ideas con algunas animaciones m√°s. Cuando el tama√±o muestral es peque√±o (N es chico), el error muestral puede causar todo tipo de ‚Äúpatrones‚Äù en los datos. Esto hace posible ‚Äîy de hecho com√∫n‚Äî que aparezcan ‚Äúcorrelaciones‚Äù entre dos conjuntos de n√∫meros. Cuando aumentamos el tama√±o muestral, el error muestral se reduce, lo que hace menos probable que aparezcan correlaciones **solo por azar**. Cuando N es grande, el azar tiene **menos oportunidades de operar**.

#### Ver c√≥mo se comporta la correlaci√≥n cuando no hay correlaci√≥n

Abajo se muestran n√∫meros generados aleatoriamente para dos variables, los graficamos, y mostramos la correlaci√≥n usando una l√≠nea. Hay cuatro paneles, y cada uno muestra un tama√±o muestral distinto: 10, 50, 100 y 1000 observaciones en cada muestra.

Record√°: como estamos muestreando n√∫meros aleatoriamente, no deber√≠a haber ninguna relaci√≥n entre las variables X e Y. Pero, como venimos discutiendo, a veces podemos observar una correlaci√≥n ‚Äîproducto del azar. Lo importante es mirar **c√≥mo se comporta la l√≠nea** en los cuatro paneles de la figura @fig-3corRandfour.\
Con tama√±o muestral de 10, la l√≠nea gira para cualquier lado. Tambi√©n se mueve bastante con tama√±os de 50 o 100. Incluso con 1000 se mueve un poco, pero mucho menos. En todos los casos esperamos que la l√≠nea sea plana, pero cada vez que tomamos nuevas muestras, a veces la l√≠nea nos muestra **patrones falsos**.

::: {.content-visible when-format="html"}

```{r}
#| label: fig-3corRandfour
#| fig-cap: "Animation of how correlation behaves for completely random X and Y variables as a function of sample size. The best fit line is not very stable for small sample-sizes, but becomes more reliably flat as sample-size increases."
#| out.width: "75%"

knitr::include_graphics(path="imgs/gifs/corUnifFourNs-1_es.gif")
```

:::

```{r, eval=FALSE}
#| label: fig-3corRandfourd
#| fig-cap: "Cuatro paneles muestran la l√≠nea de correlaci√≥n calculada a partir de dos variables generadas aleatoriamente. Cada panel tiene un tama√±o muestral diferente: N = 10, 50, 100 y 1000. Not√° c√≥mo la l√≠nea de correlaci√≥n var√≠a mucho con tama√±os peque√±os, y se estabiliza con tama√±os grandes."

all_df<-data.frame()
for(sim in 1:10){
  for(n in c(10,50,100,1000)){
  North_pole <- runif(n,1,10)
  South_pole <- runif(n,1,10)
  t_df<-data.frame(nsize=rep(n,n),
                   simulation=rep(sim,n),
                                  North_pole,
                                  South_pole)
  all_df<-rbind(all_df,t_df)
  }
}


ggplot(all_df,aes(x=North_pole,y=South_pole))+
  geom_point()+
  geom_smooth(method=lm, se=FALSE)+
  theme_classic()+
  facet_wrap(~nsize)+
  transition_states(
    simulation,
    transition_length = 2,
    state_length = 1
  )+enter_fade() + 
  exit_shrink() +
  ease_aes('sine-in-out')
```

¬øCu√°l de estas l√≠neas deber√≠as creer? Bueno, esperamos que veas que la l√≠nea correspondiente a N = 1000 es **la m√°s estable**. Tiende a ser muy plana cada vez, y **no depende tanto de la muestra en particular**. En cambio, la l√≠nea con solo 10 observaciones **va para cualquier lado**.

La conclusi√≥n ac√° es que si alguien te dice que encontr√≥ una correlaci√≥n, deber√≠as preguntar cu√°ntas observaciones ten√≠a en su muestra. Si solo ten√≠a 10 observaciones, ¬øc√≥mo podr√≠as confiar en esa afirmaci√≥n? ¬°No pod√©s! Ahora que sab√©s que muestras tan chicas pueden producir cualquier cosa **solo por azar**, deber√≠as desconfiar.\
En cambio, si descubr√≠s que la muestra era grande, pod√©s confiar un poco m√°s en el hallazgo.

En el ejemplo anterior, muestreamos n√∫meros de una distribuci√≥n **uniforme**. Muchos datos reales provienen de una distribuci√≥n normal (o aproximadamente normal). Podemos repetir lo anterior, pero muestreando de una misma distribuci√≥n normal. Igual habr√° **cero correlaci√≥n real** entre X e Y, porque todo fue generado al azar.\
La figura @fig-3normCorfour muestra el mismo comportamiento. Con tama√±os muestrales peque√±os, la correlaci√≥n calculada fluct√∫a mucho. Con muestras grandes, no.

### Ver c√≥mo se comporta la correlaci√≥n cuando realmente **hay** una correlaci√≥n

A veces s√≠ existen correlaciones entre dos variables que **no** son producto del azar. La figura @fig-3realcorFour muestra una animaci√≥n con cuatro gr√°ficos de dispersi√≥n. Cada uno muestra la correlaci√≥n entre dos variables. Nuevamente, variamos el tama√±o muestral: 10, 50, 100 y 1000 observaciones. Los datos fueron generados de forma que **contengan una correlaci√≥n positiva real**. As√≠ que deber√≠amos esperar que la l√≠nea suba desde la esquina inferior izquierda hacia la esquina superior derecha.\
Sin embargo, los datos todav√≠a tienen variabilidad. As√≠ que esta vez, el error muestral debido al azar va a ‚Äúdifuminar‚Äù un poco la correlaci√≥n. Sabemos que est√° ah√≠, pero a veces el azar puede hacer que desaparezca.

Not√° que en el panel superior izquierdo (tama√±o muestral = 10), la l√≠nea se mueve mucho m√°s que en los otros paneles. Cada nuevo conjunto de muestras produce correlaciones distintas. A veces, la l√≠nea incluso se aplana o baja.\
Pero a medida que aumentamos el tama√±o muestral, vemos que la l√≠nea **no cambia tanto**: siempre va hacia arriba, mostrando una correlaci√≥n positiva.

::: {.content-visible when-format="html"}
```{r}
#| label: fig-3realcorFour
#| fig-cap: "C√≥mo se comporta la correlaci√≥n en funci√≥n del tama√±o muestral cuando existe una correlaci√≥n real entre las variables X e Y."
#| out.width: "75%"

knitr::include_graphics(path="imgs/gifs/corRealgif-1_es.gif")
```
:::

La lecci√≥n principal ac√° es que **incluso cuando hay una correlaci√≥n positiva real entre dos variables, podr√≠as no verla si tu muestra es muy peque√±a**. Por ejemplo, podr√≠as tener mala suerte con la muestra que recolectaste. Esa muestra podr√≠a mostrar una correlaci√≥n negativa, ¬°aunque la verdadera correlaci√≥n sea positiva!\
Lamentablemente, en el mundo real casi siempre tenemos solo una muestra, la que logramos recolectar. As√≠ que siempre tenemos que preguntarnos si tuvimos suerte‚Ä¶ o no.

Por suerte, si quer√©s eliminar el factor suerte, **todo lo que necesit√°s es recolectar una muestra m√°s grande**. As√≠ vas a tener muchas m√°s chances de observar el patr√≥n real, y no uno que apareci√≥ por azar.

## Resumen

En esta secci√≥n hablamos sobre la correlaci√≥n, y empezamos a construir algunas intuiciones sobre **estad√≠stica inferencial**, que es el gran tema de los pr√≥ximos cap√≠tulos. Por ahora, las ideas clave son:

1.  Podemos medir relaciones en los datos usando herramientas como la correlaci√≥n.\
2.  Las correlaciones que encontramos pueden deberse a muchas causas distintas, por eso **son dif√≠ciles de interpretar**.\
3.  El azar puede producir correlaciones, as√≠ que existe la posibilidad de que sean completamente **sin sentido**.\
4.  Sin embargo, podemos crear un modelo que represente exactamente **lo que el azar puede hacer**. Ese modelo nos dice si es m√°s o menos probable que el azar genere correlaciones de cierto tama√±o.\
5.  Podemos usar ese modelo del azar para ayudarnos a decidir sobre nuestros propios datos. Podemos comparar la correlaci√≥n que encontramos con ese modelo, y preguntarnos si es probable que haya sido generada por azar.
