---
author:
  - Danielle J. Navarro
  - Matthew J. C. Crump
abstract-title: Chapter notes
abstract: Sections 4.1 & 4.9 - Adapted text by Danielle Navarro Section 4.10 - 4.11 & 4.13 - Mix of Matthew Crump & Danielle Navarro Section 4.12 - 4.13 - Adapted text by Danielle Navarro
aliases: [probability-sampling-and-estimation.html]
---

```{r, include = FALSE}
source("global_stuff.R")
```


# Probabilidad, muestreo y estimación

> He estudiado muchos idiomas —francés, español y un poco de italiano—, pero nadie me dijo que la estadística era una lengua extranjera.
> —Charmaine J. Forde

Hasta ahora en el libro, hablamos sobre algunas de las ideas clave en el diseño experimental, y comentamos un poco cómo podés resumir un conjunto de datos. Para muchas personas, eso es todo lo que hay en estadística: se trata de calcular promedios, juntar números, hacer gráficos y poner todo eso en un informe. Algo así como coleccionar estampillas, pero con números.
Sin embargo, la estadística abarca mucho más que eso. De hecho, la estadística descriptiva es una de las partes más chicas —y menos potentes— de la estadística.
La parte más grande y útil de la estadística es que nos da herramientas **para hacer inferencias a partir de los datos**.

Cuando empezás a pensar en la estadística en estos términos —que está ahí para ayudarnos a sacar conclusiones a partir de los datos—, empezás a ver ejemplos por todas partes. Por ejemplo, acá hay un pequeño extracto de un artículo del *Sydney Morning Herald* (30 de octubre de 2010):

> “Tengo un trabajo difícil”, dijo la Premier en respuesta a una encuesta que reveló que su gobierno es ahora la administración laborista más impopular de la historia de los sondeos, con una intención de voto primaria de apenas el 23 por ciento.

Este tipo de afirmación es totalmente común en los diarios y en la vida cotidiana, pero pensemos por un momento qué implica.
Una encuestadora hizo un sondeo —probablemente bastante grande porque pueden pagarlo—. No tengo ganas de buscar el informe original, así que imaginemos que llamaron a 1000 personas al azar, y que 230 (23%) dijeron que pensaban votar al partido.
Para las elecciones federales de 2010, la Comisión Electoral Australiana informó que había 4.610.795 votantes registrados en New South Wales; así que las opiniones de los 4.609.795 votantes restantes (aproximadamente el 99,98%) **no las conocemos**.
Incluso suponiendo que nadie le mintió a la encuestadora, lo único que podemos decir con 100% de certeza es que el voto real está entre 230/4.610.795 (aprox. 0,005%) y 4.610.025/4.610.795 (aprox. 99,83%).
Entonces, ¿en qué se basa la encuestadora, el diario y la opinión pública para concluir que el voto al ALP es aproximadamente del 23%?

La respuesta es bastante obvia: si llamo a 1000 personas al azar y 230 dicen que votarían al ALP, parece muy poco probable que **sean las únicas** 230 personas en toda la población que lo harían.
En otras palabras, asumimos que los datos recolectados por la encuestadora **representan bastante bien a toda la población**.
Pero, ¿cuán representativos son? ¿Nos sorprendería descubrir que el verdadero apoyo al ALP es en realidad del 24%? ¿Del 29%? ¿Del 37%?
Acá es donde la intuición cotidiana empieza a fallar.
A nadie le sorprendería un 24%, y a todo el mundo le sorprendería un 37%, pero no es tan fácil decidir si un 29% sería plausible.
Necesitamos herramientas más potentes que simplemente mirar los números y adivinar.

La **estadística inferencial** proporciona las herramientas necesarias para responder ese tipo de preguntas.
Y como ese tipo de preguntas están en el corazón del trabajo científico, ocupan la mayor parte de cualquier curso introductorio de estadística o métodos de investigación.
Sin embargo, nuestras herramientas para hacer inferencias estadísticas están:
1. construidas sobre la base de la **teoría de la probabilidad**, y
2. requieren entender cómo se comportan las muestras cuando se extraen de distribuciones (definidas por la teoría de la probabilidad…).

Así que este capítulo tiene dos partes principales:
una breve introducción a la teoría de la probabilidad,
y una introducción al muestreo a partir de distribuciones.

## ¿En qué se diferencian la probabilidad y la estadística?

Antes de empezar a hablar de teoría de la probabilidad, conviene dedicar un momento a pensar en la relación entre probabilidad y estadística. Las dos disciplinas están muy relacionadas, pero **no son lo mismo**.

La teoría de la probabilidad es “la doctrina del azar”.
Es una rama de las matemáticas que te dice **con qué frecuencia** ocurren distintos tipos de eventos.
Por ejemplo, todas estas preguntas pueden responderse usando teoría de la probabilidad:

- ¿Cuál es la probabilidad de que una moneda justa salga cara 10 veces seguidas?
- Si tiro dos dados de seis caras, ¿qué tan probable es que salgan dos seises?
- ¿Qué probabilidad hay de que cinco cartas extraídas al azar de un mazo bien mezclado sean todas corazones?
- ¿Qué chance tengo de ganar la lotería?

Fijate que todas estas preguntas tienen algo en común:
en cada caso, **conocemos cómo funciona el mundo**, y lo que queremos saber es **qué clase de eventos** pueden ocurrir.
En la primera pregunta, **sabemos** que la moneda es justa, así que hay un 50% de probabilidad de que cualquier lanzamiento individual salga cara.
En la segunda, **sabemos** que la chance de sacar un 6 con un dado es 1 en 6.
En la tercera, **sabemos** que el mazo está bien mezclado.
Y en la cuarta, **sabemos** que la lotería sigue reglas bien definidas.

Lo importante es que las preguntas de probabilidad **parten de un modelo conocido del mundo**, y usamos ese modelo para hacer cálculos.

El modelo puede ser muy simple.
Por ejemplo, en el caso de la moneda, podemos escribir el modelo así:

$P(\text{cara}) = 0.5$

que se lee: “la probabilidad de que salga cara es 0.5”.

Como veremos más adelante, así como los porcentajes van de 0% a 100%, las probabilidades son simplemente números que van de 0 a 1.
Cuando usamos este modelo para responder la primera pregunta, en realidad **no sabemos exactamente qué va a pasar**.
Tal vez salgan 10 caras, como plantea la pregunta.
Pero también podrían salir 3 caras.
Eso es lo importante: en la teoría de la probabilidad, el **modelo es conocido**, pero los **datos no lo son**.

Eso es la probabilidad. ¿Y la estadística? Las preguntas estadísticas **funcionan al revés**.
En estadística, **no sabemos cómo es el mundo en realidad**.
Lo único que tenemos son datos, y a partir de ellos queremos **aprender** cómo es el mundo.
Las preguntas estadísticas suelen ser más del tipo:

- Si mi amiga lanza una moneda 10 veces y sale cara todas las veces, ¿me está haciendo trampa?
- Si saco cinco cartas y todas son corazones, ¿qué tan probable es que el mazo estuviera mezclado?
- Si la pareja del comisario de la lotería gana la lotería, ¿qué tan probable es que esté arreglada?

Esta vez, lo único que tenemos son los datos. Lo que **sé** es que vi a mi amiga lanzar la moneda 10 veces y salió cara cada vez. Y lo que quiero *inferir* es si debería concluir que lo que acabo de ver fue realmente una moneda justa siendo lanzada 10 veces seguidas, o si debería sospechar que mi amiga me está haciendo una trampa.

Los datos que tengo se ven así:

```
H H H H H H H H H H
```

y lo que estoy intentando hacer es decidir en cuál “modelo del mundo” debería confiar.
Si la moneda es justa, entonces el modelo que debería adoptar es uno en el que la probabilidad de que salga cara es 0.5; es decir,

$P(\text{cara}) = 0.5$

Si la moneda **no** es justa, entonces debería concluir que la probabilidad de que salga cara **no** es 0.5, lo que escribiríamos como:
$P(\text{cara}) \neq 0.5$

En otras palabras, el problema de la inferencia estadística consiste en decidir **cuál de estos modelos de probabilidad es el correcto**.

Está claro que la pregunta estadística **no es la misma** que la pregunta de probabilidad, pero están profundamente relacionadas.
Por eso, una buena introducción a la teoría estadística tiene que comenzar con una discusión sobre qué es la probabilidad y cómo funciona.

Gracias. A continuación va la **traducción fiel y continua** desde la sección `## What does probability mean?`:

---

## ¿Qué significa “probabilidad”?

Empecemos con la primera de estas preguntas: ¿qué es la “probabilidad”?
Puede parecerte sorprendente, pero aunque lxs estadísticxs y matemáticxs (en general) están de acuerdo sobre cuáles son las **reglas** de la probabilidad, hay mucho menos consenso sobre qué significa **realmente** la palabra.

Suena raro, porque todes usamos palabras como “azar”, “posibilidad”, “probable” o “chance” sin problema, y no parece una pregunta difícil de responder.
Si tuvieras que explicarle a una niña de cinco años qué es la probabilidad, probablemente te las arreglarías bastante bien.
Pero si alguna vez viviste esa situación en la vida real, tal vez te fuiste con la sensación de que **no lo explicaste tan bien**, y que —como pasa con muchos conceptos cotidianos— en realidad **no sabés del todo bien de qué se trata**.

Así que voy a intentarlo. Supongamos que quiero apostar en un partido de fútbol entre dos equipos de robots, **Arduino Arsenal** y **C Milan**.
Después de pensarlo, decido que hay una probabilidad del 80% de que **Arduino Arsenal** gane. ¿Qué quiero decir con eso? Acá hay tres posibles interpretaciones:

- Son equipos robot, así que puedo hacerlos jugar muchas veces. Si lo hiciera, **Arduino Arsenal** ganaría 8 de cada 10 partidos, en promedio.

- Para cualquier partido en particular, yo solo aceptaría que apostar es “justo” si una apuesta de \$1 por **C Milan** paga \$5 (es decir, recupero el \$1 más \$4 de premio), o si una apuesta de \$4 por **Arduino Arsenal** también paga \$5 (mi apuesta más \$1 de ganancia).

- Mi creencia o confianza subjetiva en que gana **Arduino Arsenal** es cuatro veces más fuerte que la que tengo en que gane **C Milan**.

Todas estas opciones parecen razonables.
Sin embargo, **no son idénticas**, y no todes lxs estadísticxs estarían de acuerdo con todas.
La razón es que existen diferentes ideologías estadísticas (¡sí, en serio!), y dependiendo de cuál suscribas, podrías decir que algunas de esas afirmaciones **no tienen sentido** o son irrelevantes.

En esta sección, voy a presentar brevemente los dos enfoques principales que existen en la literatura.
No son los únicos, pero sí son los más importantes.


### La visión frecuentista

El primero de los dos enfoques principales —y el más dominante en estadística— se conoce como la **visión frecuentista**, que define la probabilidad como una **frecuencia a largo plazo**.

Supongamos que empezamos a lanzar una moneda justa, una y otra vez. Por definición, es una moneda en la que $P(H) = 0.5$.
¿Qué podríamos observar? Una posibilidad es que los primeros 20 lanzamientos se vean así:

```
T, H, H, H, H, T, T, H, H, H, H, T, H, H, T, T, T, T, T, H
```
En este caso, 11 de los 20 lanzamientos (55%) salieron cara.
Ahora supongamos que fui llevando la cuenta del número de caras (que voy a llamar $ N_H $) en los primeros $ N $ lanzamientos, y que cada vez calculo la proporción de caras $ N_H / N $.
Esto es lo que obtendría (¡sí, de verdad lancé monedas para obtener esto!):

| número de lanzamientos |  1 |  2 |  3 |  4 |  5 |  6 |  7 |  8 |  9 | 10 |
|------------------------|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|
| número de caras        |  0 |  1 |  2 |  3 |  4 |  4 |  4 |  5 |  6 |  7 |
| proporción             |.00 |.50 |.67 |.75 |.80 |.67 |.57 |.63 |.67 |.70 |

| número de lanzamientos | 11 | 12 | 13 | 14 | 15 | 16 | 17 | 18 | 19 | 20 |
|------------------------|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|
| número de caras        |  8 |  8 |  9 | 10 | 10 | 10 | 10 | 10 | 10 | 11 |
| proporción             |.73 |.67 |.69 |.71 |.67 |.63 |.59 |.56 |.53 |.55 |

Fijate que al principio de la secuencia, la **proporción** de caras fluctúa bastante, empezando en .00 y subiendo hasta .80. Más adelante, da la impresión de que se estabiliza, con valores que se acercan cada vez más al valor “correcto” de 0.50.
Esta es la definición frecuentista de probabilidad en pocas palabras: lanzá una moneda justa muchas veces, y a medida que $ N $ crece (se acerca al infinito, denotado $ N \rightarrow \infty $), la proporción de caras converge a 50%.

Hay algunas sutilezas técnicas que le importan a lxs matemáticxs, pero en términos cualitativos, así es como lxs frecuentistas definen la probabilidad.

Por supuesto, no tengo un número infinito de monedas, ni la paciencia infinita para lanzarlas eternamente.
Pero sí tengo una computadora, y las computadoras son excelentes para tareas repetitivas.
Así que le pedí a la computadora que simulara lanzar una moneda 1000 veces, y luego grafiqué lo que pasa con la proporción $ N_H / N $ a medida que $ N $ aumenta.
En realidad, lo hice cuatro veces, solo para asegurarme de que no fuera casualidad.
Los resultados se muestran en la figura @fig-4FreqProb.

Como podés ver, la **proporción de caras observadas** eventualmente deja de fluctuar, y se estabiliza.
Cuando eso ocurre, el número al que se estabiliza es la verdadera probabilidad de cara.

```{r echo=F}
#| label: fig-4FreqProb
#| fig-cap: "Ilustración de cómo funciona la probabilidad frecuentista. Si lanzás una moneda justa muchas veces, la proporción de caras observadas se estabiliza y converge hacia la probabilidad verdadera de 0.5. Cada panel muestra un experimento simulado distinto: en cada caso, se simula lanzar una moneda 1000 veces y se lleva un registro de la proporción de caras acumuladas. Aunque ninguna secuencia termina exactamente en 0.5, si el experimento se extendiera indefinidamente, lo haría."
knitr::include_graphics("imgs/navarro_img/probability/frequentistProb-eps-converted-to.png")
```

La definición frecuentista de probabilidad tiene algunas características deseables. Primero, es **objetiva**: la probabilidad de un evento está necesariamente anclada en el mundo. La única forma en que las afirmaciones probabilísticas tienen sentido es si se refieren a (una secuencia de) eventos que ocurren en el universo físico.
Segundo, es **no ambigua**: dos personas que observan la misma secuencia de eventos y tratan de calcular la probabilidad de un evento, necesariamente deben llegar a la misma respuesta.

Sin embargo, también tiene características indeseables. Las secuencias infinitas **no existen** en el mundo físico.
Supongamos que agarrás una moneda de tu bolsillo y empezás a lanzarla. Cada vez que cae, impacta contra el suelo. Cada impacto desgasta un poco la moneda; eventualmente, la moneda se va a destruir.
Entonces, uno podría preguntarse si realmente tiene sentido fingir que una “secuencia infinita” de lanzamientos de moneda es un concepto significativo, o incluso **objetivo**.
No podemos decir que una secuencia infinita de eventos sea algo real en el universo físico, porque **el universo físico no permite nada infinito**.

Más seriamente, la definición frecuentista tiene un **alcance muy limitado**.
Hay un montón de cosas a las que les asignamos probabilidades en el lenguaje cotidiano, pero que **no pueden** (ni siquiera en teoría) ser representadas como una secuencia hipotética de eventos.
Por ejemplo, si una meteoróloga aparece en la tele y dice: “la probabilidad de que llueva en Adelaida el 2 de noviembre de 2048 es del 60%”, las personas aceptamos esa afirmación sin problemas.
Pero no está claro cómo definir eso en términos frecuentistas.
Solo hay una ciudad de Adelaida, y solo hay un 2 de noviembre de 2048. No hay ninguna secuencia infinita de eventos acá: es algo que ocurre **una sola vez**.

Desde la perspectiva frecuentista, **está prohibido** hacer afirmaciones de probabilidad sobre un evento único.
Para un frecuentista, mañana **o va a llover o no va a llover**; no hay ninguna “probabilidad” asociada a un evento no repetible.

Ahora bien, hay que decir que lxs frecuentistas tienen algunos trucos muy ingeniosos para sortear esta limitación.
Una posibilidad es que lo que quiso decir la meteoróloga sea algo así como:
“Hay una categoría de días para los que yo predigo un 60% de chance de lluvia; si miramos sólo esos días en los que hice esa predicción, entonces en el 60% de ellos efectivamente llueve”.

Es una forma rara e **intuitivamente extraña** de pensarlo, pero sí: lxs frecuentistas hacen esto a veces.

### La visión bayesiana

La **visión bayesiana** de la probabilidad también se llama la visión subjetivista. Es una posición minoritaria entre lxs estadísticxs, pero que ha ido ganando terreno de forma sostenida en las últimas décadas.
Hay muchas variantes del bayesianismo, lo que dificulta definir exactamente cuál es “la” visión bayesiana.
La forma más común de pensar en la probabilidad subjetiva es definir la probabilidad de un evento como el **grado de creencia** que una persona (o agente racional e inteligente) asigna a la verdad de ese evento.

Desde esta perspectiva, las probabilidades **no existen en el mundo**, sino que viven en los pensamientos y suposiciones de las personas (o seres inteligentes).
Sin embargo, para que este enfoque funcione, necesitamos alguna forma de operacionalizar ese “grado de creencia”.
Una manera de hacerlo es formalizarlo en términos de **apuestas racionales**, aunque existen otras formas.

Supongamos que creo que hay un 60% de probabilidad de que mañana llueva.
Si alguien me ofrece una apuesta que dice: *si llueve, ganás \$5; si no llueve, perdés \$5*, desde mi perspectiva **es una buena apuesta**.
En cambio, si creo que hay solo un 40% de probabilidad de lluvia, entonces esa misma apuesta sería **una mala idea**.
Así, podemos operacionalizar el concepto de “probabilidad subjetiva” en función de qué apuestas estoy dispuestx a aceptar.

¿Cuáles son las ventajas y desventajas de este enfoque bayesiano? La principal **ventaja** es que permite asignar probabilidades a **cualquier evento que queramos**.
No es necesario que el evento sea repetible.
La principal **desventaja** (para muchxs) es que no se puede ser puramente objetivx:
asignar una probabilidad **requiere especificar quién cree en qué**.
Esa entidad puede ser una persona, un robot, un extraterrestre, o una estadística… pero **tiene que haber un agente racional que tenga creencias**.

Para muchxs esto resulta incómodo: hace que la probabilidad parezca arbitraria.
Aunque el enfoque bayesiano exige que ese agente cumpla las reglas de la probabilidad (es decir, que sea racional), **permite que cada quien tenga sus propias creencias**.
Yo puedo creer que una moneda es justa, y vos no tenés por qué estar de acuerdo —ambxs podemos ser racionales.

En cambio, desde la visión frecuentista, **dos observadorxs no pueden asignar probabilidades distintas al mismo evento**: si lo hacen, por lo menos unx de lxs dos está equivocado.
El enfoque bayesiano no impone esta restricción: dos personas con conocimientos previos distintos **pueden asignar probabilidades distintas al mismo evento**, y ambas ser coherentes y racionales.


### ¿Cuál es la diferencia? ¿Y quién tiene razón?

Ahora que viste cada una de estas dos perspectivas por separado, conviene asegurarse de que podés compararlas.
Volvé al partido hipotético de fútbol robot al comienzo de la sección.
¿Qué pensás que dirían un frecuentista y un bayesiano sobre estas tres afirmaciones?
¿Cuál de ellas consideraría un frecuentista como la definición correcta de probabilidad?
¿Y cuál aceptaría un bayesiano?
¿Algunas de estas afirmaciones serían sin sentido para un frecuentista o para un bayesiano?
Si entendiste bien las dos perspectivas, deberías tener una idea de cómo responder esas preguntas.

Bien, suponiendo que entendiste la diferencia, tal vez te estés preguntando cuál de ellas es la **correcta**.
Sinceramente, no sé si hay una respuesta correcta.
Hasta donde puedo decir, no hay nada matemáticamente incorrecto en la forma en que lxs frecuentistas piensan las secuencias de eventos, y tampoco hay nada matemáticamente incorrecto en la forma en que lxs bayesianos definen las creencias de un agente racional.
De hecho, cuando uno se mete en los detalles, lxs bayesianos y lxs frecuentistas en realidad están de acuerdo en muchas cosas.
Muchos métodos frecuentistas llevan a decisiones que lxs bayesianos aceptarían como consistentes con un agente racional.
Y muchos métodos bayesianos tienen muy buenas propiedades frecuentistas.

En general, yo soy pragmático, así que uso cualquier método estadístico en el que confíe.
Resulta que eso me hace preferir los métodos bayesianos, por razones que voy a explicar hacia el final del libro, pero no estoy fundamentalmente en contra de los métodos frecuentistas.
No todes son tan relajades.

Por ejemplo, pensemos en Sir Ronald Fisher, una de las figuras más importantes de la estadística del siglo XX y un ferviente opositor de todo lo bayesiano, cuyo artículo sobre los fundamentos matemáticos de la estadística se refiere a la probabilidad bayesiana como “una selva impenetrable [que] detiene el progreso hacia la precisión de los conceptos estadísticos” @Fisher1922b [p. 311].

O el psicólogo Paul Meehl, quien sugiere que confiar en métodos frecuentistas podría convertirte en “un brillante pero estéril libertino intelectual que deja en su alegre camino una larga estela de doncellas seducidas pero sin descendencia científica viable” @Meehl1967 [p. 114]. La historia de la estadística, como podés ver, no carece de entretenimiento.
erés que siga con la próxima sección del libro?

## Teoría básica de la probabilidad

Más allá de las discusiones ideológicas entre bayesianos y frecuentistas, resulta que en general hay bastante consenso sobre **las reglas que deben seguir las probabilidades**.
Hay muchas maneras de llegar a estas reglas. El enfoque más común se basa en el trabajo de Andrey Kolmogorov, uno de los grandes matemáticos soviéticos del siglo XX.
No voy a entrar en demasiados detalles, pero voy a intentar darte una idea general de cómo funciona.
Y para hacerlo, voy a tener que hablar de mis pantalones.



### Introducción a las distribuciones de probabilidad

Una de las verdades perturbadoras de mi vida es que solo tengo cinco pares de pantalones: tres jeans, la parte de abajo de un traje, y un pantalón deportivo.
Más triste aún: les puse nombre. Los llamo $ X_1 $, $ X_2 $, $ X_3 $, $ X_4 $ y $ X_5 $.
De verdad lo hago: por eso me dicen “Señor Imaginativo”.

Cada día, elijo exactamente **un** par de pantalones para usar. Ni yo soy tan tonto como para tratar de usar dos al mismo tiempo, y gracias a años de entrenamiento ya no salgo de casa sin pantalones.

Si quisiera describir esta situación usando el lenguaje de la teoría de la probabilidad, diría que cada par de pantalones (es decir, cada $ X $) es un **evento elemental**.
La característica clave de los eventos elementales es que **cada vez que hacemos una observación** (por ejemplo, cada vez que me pongo un par de pantalones), el resultado será uno y solo uno de esos eventos.
Como dije, hoy en día siempre uso exactamente un par, así que mis pantalones cumplen con esa condición.

De forma similar, al conjunto de todos los posibles eventos se lo llama **espacio muestral** (*sample space*).
Es verdad que algunas personas lo llamarían “guardarropa”, pero eso es porque se niegan a pensar en mis pantalones desde una perspectiva probabilística. Triste.

Bien, ahora que tenemos un espacio muestral (un guardarropa), formado por varios eventos elementales (pantalones), lo que queremos hacer es asignar una **probabilidad** a cada uno de esos eventos.

Para un evento $ X $, la probabilidad de ese evento $ P(X) $ es un número entre 0 y 1.
Cuanto mayor es $ P(X) $, más probable es que ocurra ese evento.

Por ejemplo:

- Si $ P(X) = 0 $, significa que el evento $ X $ es **imposible** (nunca uso ese pantalón).
- Si $ P(X) = 1 $, significa que el evento $ X $ es **seguro** (siempre uso ese pantalón).
- Si $ P(X) = 0.5 $, significa que uso ese pantalón **la mitad de las veces**.

A esta altura, ya casi terminamos.
Lo último que necesitamos reconocer es que “**algo siempre ocurre**”.
Cada vez que me pongo pantalones, efectivamente termino con un par puesto (una locura, ¿no?).
Esta afirmación algo trillada quiere decir, en términos probabilísticos, que **las probabilidades de todos los eventos elementales deben sumar 1**.

Esto se conoce como la **ley de probabilidad total**, aunque a nadie le importe demasiado.
Más importante aún, si se cumplen estos requisitos, lo que tenemos es una **distribución de probabilidad**.



Por ejemplo, esta es una distribución de probabilidad:

| ¿Qué pantalón?     | Etiqueta |  Probabilidad     |
|:-------------------|:--------:|:-----------------:|
| Jean azul          | $ X_1 $ | $ P(X_1) = 0.5 $ |
| Jean gris          | $ X_2 $ | $ P(X_2) = 0.3 $ |
| Jean negro         | $ X_3 $ | $ P(X_3) = 0.1 $ |
| Pantalón de traje  | $ X_4 $ | $ P(X_4) = 0 $   |
| Pantalón deportivo | $ X_5 $ | $ P(X_5) = 0.1 $ |

Cada uno de estos eventos tiene una probabilidad que está entre 0 y 1, y si sumamos todas las probabilidades, el total es 1. Genial.

Incluso podemos hacer un lindo gráfico de barras para visualizar esta distribución, como se muestra en la figura @fig-4pantsprob.
Y en este punto, todes logramos algo: vos aprendiste qué es una distribución de probabilidad, y yo por fin encontré la forma de hacer un gráfico que trata exclusivamente sobre mis pantalones. ¡Ganamos todes!

```{r echo=F}
#| label: fig-4pantsprob
#| fig-cap: "Representación visual de la distribución de probabilidad de los pantalones. Hay cinco eventos elementales, que corresponden a los cinco pares de pantalones que tengo. Cada evento tiene alguna probabilidad de ocurrir: ese valor es un número entre 0 y 1. La suma de estas probabilidades es igual a 1."

knitr::include_graphics("imgs/navarro_img/probability/pantsDistribution-eps-converted-to.png")
```

La única otra cosa que necesito señalar es que la teoría de la probabilidad también te permite hablar de **eventos no elementales**, además de los elementales.

La forma más fácil de ilustrar esto es con un ejemplo. En el caso de los pantalones, es perfectamente válido referirse a la probabilidad de que use jeans.
En este caso, decimos que el evento “Dan usa jeans” ocurre si el evento elemental que ocurrió fue uno de los apropiados; en este caso, “jean azul”, “jean negro” o “jean gris”.

En términos matemáticos, definimos el evento “jeans” $ E $ como el conjunto de eventos elementales $ (X_1, X_2, X_3) $.
Si ocurre cualquiera de esos eventos, entonces se dice que ocurrió $ E $.

Una vez definida así la variable $ E $, es muy fácil calcular la probabilidad $ P(E) $: simplemente sumamos los valores.
En este caso:

$$
P(E) = P(X_1) + P(X_2) + P(X_3)
$$

Y como las probabilidades de jean azul, gris y negro son 0.5, 0.3 y 0.1 respectivamente, la probabilidad de que use jeans es igual a 0.9.

A esta altura tal vez estés pensando que todo esto es increíblemente obvio y simple, y tenés razón.
Lo único que hicimos fue envolver algunas intuiciones de sentido común con un poco de matemática básica.

Sin embargo, a partir de estos comienzos simples se pueden construir herramientas matemáticas extremadamente poderosas.
Definitivamente **no** voy a entrar en esos detalles en este libro, pero lo que sí voy a hacer es listar algunas otras reglas que las probabilidades deben cumplir.
Estas reglas se pueden derivar de los supuestos básicos que acabamos de ver, pero como **no las vamos a usar directamente en este libro**, no me voy a detener en eso.

| Evento         | Notación         | =   | Regla                                            |
|----------------|------------------|-----|--------------------------------------------------|
| no $A$       | $P(\neg A)$     | =   | $1 - P(A)$                                      |
| $A$ o $B$  | $P(A \cup B)$   | =   | $P(A) + P(B) - P(A \cap B)$                     |
| $A$ y $B$  | $P(A \cap B)$   | =   | $P(A|B) \cdot P(B)$                             |

: Algunas reglas básicas que deben cumplir las probabilidades. No necesitás conocerlas para entender los análisis que vamos a ver más adelante en el libro, pero son importantes si querés entender la teoría de la probabilidad con más profundidad.

Ahora que tenemos la capacidad de “definir” eventos no elementales en términos de eventos elementales, en realidad podemos usar eso para construir (o, si querés sonar matemáticamente refinadx, “derivar”) algunas de las otras reglas de probabilidad.
Estas reglas están listadas arriba, y aunque estoy bastante seguro de que muy pocxs lectorxs realmente están interesadxs en **cómo** se construyen, te las voy a mostrar igual:
aunque sea aburrido y probablemente nunca les encuentres mucho uso práctico, si lo leés un par de veces y tratás de entender cómo funciona, vas a ver que la probabilidad deja de parecer tan misteriosa, y con suerte te va a intimidar menos.
Así que ahí vamos.

Primero, para construir las reglas voy a necesitar un espacio muestral $ X $ compuesto por un conjunto de eventos elementales $ x $, y dos eventos no elementales que voy a llamar $ A $ y $ B $.
Supongamos que:

$$
\begin{array}{rcl}
X &=& (x_1, x_2, x_3, x_4, x_5) \\
A &=& (x_1, x_2, x_3) \\
B &=& (x_3, x_4)
\end{array}
$$

Para hacerlo más concreto, supongamos que todavía estamos hablando de la distribución de pantalones.
Si es así, $ A $ correspondería al evento “jeans”, y $ B $ al evento “negro”:

$$
\begin{array}{rcl}
\text{“jeans”} &=& (\text{“jean azul”}, \text{“jean gris”}, \text{“jean negro”}) \\
\text{“negro”} &=& (\text{“jean negro”}, \text{“traje negro”})
\end{array}
$$

Ahora podemos empezar a comprobar las reglas que figuran en la tabla.


En la primera línea, la tabla dice que:$$ P(\neg A) = 1 - P(A)$$ y lo que **significa** esto es que la probabilidad de “no $ A $” es igual a 1 menos la probabilidad de $ A $.
Con un poco de reflexión (y un ejemplo tedioso) se vuelve evidente por qué esto tiene que ser así. Si $ A $ corresponde al evento de que me pongo jeans (es decir, que ocurre alguno de los eventos $ x_1 $, $ x_2 $ o $ x_3 $), entonces la única definición razonable de “no $ A $” (que se denota matemáticamente como $ \neg A $) es decir que $ \neg A $ consiste en **todos** los eventos elementales que **no** pertenecen a $ A $. En el caso de los pantalones, eso significa que: $$ \neg A = (x_4, x_5) $$ o, dicho en castellano: “no jeans” incluye todos los pantalones que **no** son jeans (es decir, el pantalón de traje negro y el pantalón deportivo azul).Por lo tanto, cada uno de los eventos elementales pertenece **o bien a $ A $, o bien a $ \neg A $**, pero no a ambos.
Bien, entonces reorganicemos lo anterior:$$P(\neg A) + P(A) = 1$$ que no es más que una forma matemática de decir: o uso jeans, o no uso jeans; la probabilidad de “no jeans” más la probabilidad de “jeans” es igual a 1.

Matemáticamente:

$$
\begin{array}{rcl}
P(\neg A) &=& P(x_4) + P(x_5) \\
P(A) &=& P(x_1) + P(x_2) + P(x_3)
\end{array}
$$

así que:

$$
\begin{array}{rcl}
P(\neg A) + P(A) &=& P(x_1) + P(x_2) + P(x_3) + P(x_4) + P(x_5) \\
&=& \sum_{x \in X} P(x) \\
&=& 1
\end{array}
$$
Excelente. Todo parece funcionar.

"Guau", te escucho decir. "Todo esto para decirme lo **obvio**".  Y tenés razón: esto **es** increíblemente obvio. El **propósito** de la teoría de la probabilidad es formalizar y matematizar unas pocas intuiciones de sentido común.  Así que sigamos un poco más con esta línea de razonamiento.

En la sección anterior definí un evento correspondiente a **no** $ A $, que denoté como $ \neg A $.
Ahora vamos a definir dos nuevos eventos que corresponden a conceptos cotidianos importantes:
**$ A $ y $ B $**, y **$ A $ o $ B $**.
Específicamente:

| Afirmación en español                   | Notación matemática     |
|:---------------------------------------|:------------------------:|
| “$ A $ y $ B $” ocurren ambos       | $ A \cap B $           |
| ocurre al menos uno: “$ A $ o $ B $”| $ A \cup B $           |

Ya que $ A $ y $ B $ están definidos en términos de nuestros eventos elementales (los $ x $), necesitamos describir también $ A \cap B $ y $ A \cup B $ en términos de esos mismos eventos. ¿Podemos hacerlo? ¡Sí que podemos! La única forma en que ocurran **ambos** eventos, $ A $ y $ B $, es que el evento elemental observado pertenezca tanto a $ A $ como a $ B $.
Así que:

$$
\begin{array}{rcl}
A &=& (x_1, x_2, x_3) \\
B &=& (x_3, x_4) \\
A \cap B &=& (x_3)
\end{array}
$$
Es decir, la única forma en que pueda estar usando “jeans” ($ x_1, x_2, x_3 $) y “pantalón negro” ($ x_3, x_4 $) al mismo tiempo, es que esté usando los “jeans negros” ($ x_3 $). Otro triunfo para lo absolutamente obvio.

A esta altura, no te va a sorprender para nada la definición de $ A \cup B $, aunque probablemente te parezca increíblemente aburrida.
La única forma en que puedo estar usando “jeans” o “pantalón negro” es si el evento elemental que ocurre pertenece a $ A $, o a $ B $, o a ambos. Así que:

$$
\begin{array}{rcl}
A &=& (x_1, x_2, x_3) \\
B &=& (x_3, x_4) \\
A \cup B &=& (x_1, x_2, x_3, x_4)
\end{array}
$$

Vaaamooooooooo!!!!. Matemáticas, sabelo!.

Entonces, ya definimos qué queremos decir con $ A \cap B $ y $ A \cup B $. Ahora asignemos probabilidades a esos eventos. Más específicamente, vamos a verificar la regla que dice que:
$$
P(A \cup B) = P(A) + P(B) - P(A \cap B)
$$

Usando las definiciones anteriores, sabemos que:
$$
P(A \cup B) = P(x_1) + P(x_2) + P(x_3) + P(x_4)
$$

y usando el hecho de que sabemos qué eventos elementales pertenecen a $ A $, $ B $, y $ A \cap B $, tenemos:
$$
\begin{array}{rcl}
P(A) &=& P(x_1) + P(x_2) + P(x_3) \\
P(B) &=& P(x_3) + P(x_4) \\
P(A \cap B) &=& P(x_3)
\end{array}
$$
y por lo tanto:
$$
\begin{array}{rcl}
P(A) + P(B) - P(A \cap B)
&=& P(x_1) + P(x_2) + P(x_3) + P(x_3) + P(x_4) - P(x_3) \\
&=& P(x_1) + P(x_2) + P(x_3) + P(x_4) \\
&=& P(A \cup B)
\end{array}
$$

Listo.

El próximo concepto que necesitamos definir es el de “$ B $ dado $ A $”, que se escribe típicamente como $ B \mid A $.
Esto es lo que quiero decir: supongamos que me levanto una mañana y me pongo un pantalón. Ocurre un evento elemental $ x $.
Supongamos que le grito a mi esposa (que está en la otra habitación, y no puede ver qué pantalón me puse): “¡Hoy estoy usando jeans!”.
Asumiendo que ella me cree, entonces sabe que $ A $ es verdadero.
**Dado** que sabe que ocurrió $ A $, ¿cuál es la **probabilidad condicional** de que también sea cierto $ B $?

Bueno, pensemos qué información tiene. Estas son las cosas que sabe:

- **Los eventos que no son jeans son imposibles**. Si $ A $ es verdadero, entonces sabemos que los únicos eventos elementales que pueden haber ocurrido son $ x_1 $, $ x_2 $ y $ x_3 $ (o sea, los jeans).
  Los eventos que no son jeans, $ x_4 $ y $ x_5 $, ahora son imposibles y deben tener probabilidad cero.
  En otras palabras, nuestro **espacio muestral** se ha restringido a los eventos jeans.
  Pero sigue siendo cierto que la suma de las probabilidades de estos eventos **debe** ser 1: sabemos con certeza que estoy usando jeans.

- **Ella no aprendió nada sobre qué jeans estoy usando**.
  Antes de que yo anunciara que estoy usando jeans, ella ya sabía que era cinco veces más probable que estuviera usando jeans azules ($ P(x_1) = 0.5 $) que jeans negros ($ P(x_3) = 0.1 $).
  Mi anuncio no cambia eso... no dije **nada** sobre el color, así que la proporción $ P(x_1) / P(x_3) $ se mantiene igual, con un valor de 5.


Dado que \( P(A) = 0{,}9 \), dividimos por 0.9. Esto da:

| ¿Qué pantalón?     | Evento elemental | Prob. original \( P(x) \) | Nueva prob. \( P(x \mid A) \) |
|:-------------------|:----------------:|:--------------------------:|:------------------------------:|
| Jean azul          | \( x_1 \)         |           0.5              |            0.556               |
| Jean gris          | \( x_2 \)         |           0.3              |            0.333               |
| Jean negro         | \( x_3 \)         |           0.1              |            0.111               |
| Traje negro        | \( x_4 \)         |            0               |             0                  |
| Pantalón deportivo | \( x_5 \)         |           0.1              |             0                  |

En términos matemáticos, decimos que:
\[
P(x \mid A) = \frac{P(x)}{P(A)} \quad \text{si } x \in A, \quad \text{y } P(x \mid A) = 0 \text{ si } x \notin A
\]

Por lo tanto:
\[
\begin{array}{rcl}
P(B \mid A) &=& P(x_3 \mid A) + P(x_4 \mid A) \\\\
&=& \displaystyle \frac{P(x_3)}{P(A)} + 0 \\\\
&=& \displaystyle \frac{P(x_3)}{P(A)}
\end{array}
\]

Y recordando que \( A \cap B = (x_3) \), podemos escribir esto como:
\[
P(B \mid A) = \frac{P(A \cap B)}{P(A)}
\]

Y si multiplicamos ambos lados por \( P(A) \), obtenemos:

\[
P(A \cap B) = P(B \mid A) \cdot P(A)
\]
que es la **tercera regla** que habíamos listado en la tabla anterior.


## La distribución binomial

Como te podés imaginar, las distribuciones de probabilidad varían muchísimo, y hay una enorme cantidad de distribuciones ahí afuera.
Sin embargo, **no todas son igual de importantes**.
De hecho, la gran mayoría del contenido de este libro se basa en una de **cinco distribuciones**: la distribución binomial, la distribución normal, la distribución \( t \), la distribución \( \chi^2 \) (“ji-cuadrado”) y la distribución \( F \).

Dicho esto, lo que voy a hacer en las próximas secciones es darte una breve introducción a esas cinco, prestando especial atención a la binomial y a la normal.
Voy a empezar con la distribución binomial, porque es la más sencilla de las cinco.



### Introducción a la binomial

La teoría de la probabilidad se originó como un intento de describir cómo funcionan los juegos de azar, así que parece apropiado que nuestra discusión sobre la *distribución binomial* empiece con tirar dados y lanzar monedas.
Imaginá un experimento simple: en mi mano tengo 20 dados idénticos de seis caras. En una de las caras de cada dado hay una calavera; las otras cinco están en blanco.
Si lanzo los 20 dados, ¿cuál es la probabilidad de que salgan exactamente 4 calaveras?

Asumiendo que los dados son justos, sabemos que la chance de que cualquier dado salga calavera es 1 en 6; dicho de otra forma, la probabilidad de calavera para un solo dado es aproximadamente \( 0{,}167 \).
Con eso ya tenemos suficiente información para responder la pregunta, así que veamos cómo se hace.

Como siempre, vamos a introducir algunos nombres y notación.
Vamos a usar \( N \) para referirnos al número de lanzamientos en nuestro experimento; esto es lo que se conoce como el **parámetro de tamaño** de la distribución binomial.
También vamos a usar \( \theta \) para referirnos a la **probabilidad de éxito** de un solo lanzamiento, es decir, la probabilidad de que salga calavera.

Finalmente, usaremos \( X \) para referirnos al resultado de nuestro experimento, es decir, la cantidad de calaveras que obtengo al lanzar los dados.
Como el valor concreto de \( X \) depende del azar, nos referimos a él como una **variable aleatoria**.

Con toda esta terminología y notación, podemos expresar el problema de forma un poco más precisa:
la cantidad que queremos calcular es la probabilidad de que \( X = 4 \), dado que sabemos que \( \theta = 0{,}167 \) y \( N = 20 \).
La forma general de lo que queremos calcular se puede escribir como:

\[
P(X \mid \theta, N)
\]

y nos interesa el caso particular en el que \( X = 4 \), \( \theta = 0{,}167 \) y \( N = 20 \).

Hay una última notación que quiero mencionar antes de pasar a cómo resolver el problema.
Si quiero decir que \( X \) fue generado aleatoriamente a partir de una distribución binomial con parámetros \( \theta \) y \( N \), lo escribo así:

\[
X \sim \mbox{Binomial}(\theta, N)
\]

Sí, sí, ya sé lo que estás pensando: notación, notación, notación. ¿A quién le importa?
Muy pocxs lectorxs están acá por la notación, así que mejor sigo y explico **cómo usar** la distribución binomial.

Para eso, la figura @fig-4binomial1 muestra las probabilidades binomiales para todos los valores posibles de \( X \) en nuestro experimento con los dados, desde \( X = 0 \) (ninguna calavera) hasta \( X = 20 \) (todas calaveras).

Notá que básicamente es un gráfico de barras, y no es distinto del gráfico de “probabilidad de pantalones” que hicimos en @fig-4pantsprob.
En el eje horizontal están todos los eventos posibles, y en el eje vertical podemos ver la probabilidad de cada uno de esos eventos.

Por ejemplo, la probabilidad de obtener 4 calaveras al lanzar 20 dados es de aproximadamente 0.20 (la respuesta exacta es 0.2022036, como veremos enseguida).
En otras palabras, esperarías que eso ocurra alrededor del 20% de las veces que repitas este experimento.

```{r echo=F}
#| label: fig-4binomial1
#| fig-cap: "La distribución binomial con parámetro de tamaño $N = 20$ y una probabilidad de éxito de 1/6. Cada barra vertical representa la probabilidad de un resultado específico (es decir, un valor posible de $X$). Como se trata de una distribución de probabilidad, cada probabilidad debe ser un número entre 0 y 1, y la suma de las alturas de las barras también debe ser 1."

knitr::include_graphics("imgs/navarro_img/probability/binomSkulls20-eps-converted-to.png")
```




### Trabajando con la distribución binomial en R

R tiene una función llamada `dbinom` que calcula probabilidades binomiales por nosotros.
Los argumentos principales de la función son:

- `x`: Un número (o vector de números) que especifica los valores para los que querés calcular la probabilidad.
- `size`: Un número que le indica a R el tamaño del experimento.
- `prob`: La probabilidad de éxito en un solo intento del experimento.

Entonces, para calcular la probabilidad de obtener 4 calaveras en un experimento de 20 lanzamientos, donde la probabilidad de calavera en cada lanzamiento es 1/6, el comando sería simplemente:

```{r}
dbinom(x = 4, size = 20, prob = 1/6)
```

Para que veas cómo cambia la distribución binomial cuando alteramos los valores de \( \theta \) y \( N \), supongamos ahora que, en lugar de tirar dados, estoy lanzando monedas.
En este caso, el experimento consiste en lanzar una moneda justa repetidamente, y el resultado que me interesa es cuántas veces sale cara.
En este escenario, la probabilidad de éxito es ahora \( \theta = 1/2 \).
Supongamos que lanzo la moneda \( N = 20 \) veces.

En este ejemplo, cambié la probabilidad de éxito, pero mantuve igual el tamaño del experimento. ¿Qué le pasa a la distribución binomial?

```{r echo=F}
#| label: fig-4binomial2
#| fig-cap: "Dos distribuciones binomiales, en un escenario donde lanzo una moneda justa, con probabilidad de éxito $1/2$. En el panel (a), se supone que lanzo la moneda $N = 20$ veces. En el panel (b), que la lanzo $N = 100$ veces."

knitr::include_graphics("imgs/navarro_img/probability/Binomial2.png")
```

Bueno, como se ve en @fig-4binomial2 (a), el efecto principal es que la distribución se desplaza hacia el centro, como cabría esperar.
Ahora, ¿qué pasa si lanzo la moneda \( N = 100 \) veces? En ese caso, obtenemos la figura @fig-4binomial2 (b).
La distribución se mantiene más o menos centrada, pero hay más variabilidad en los posibles resultados.R incluye **cuatro funciones** para trabajar con la distribución binomial. Estas funciones son `dbinom`, `pbinom`, `rbinom` y `qbinom`, y cada una calcula una cantidad distinta de interés. No solo eso: **R hace lo mismo para todas las distribuciones de probabilidad** que implementa. No importa de qué distribución se trate, siempre vas a encontrar una función `d`, una función `p`, una función `r` y una función `q`.

Veamos qué hace cada una de estas funciones. Primero, las cuatro versiones de la función requieren que le indiques los argumentos `size` y `prob`: no importa qué querés que R calcule, siempre necesita saber cuáles son los parámetros de la distribución. Pero lo que cambia entre funciones es **cuál es el argumento principal** y **qué devuelve como resultado**. Así que veámoslas una por una:

- La versión `d` ya la vimos: le pasás un valor específico `x`, y la salida es la probabilidad de obtener **exactamente** ese valor. (La “d” viene de *density*, aunque por ahora podés ignorarlo).

- La versión `p` calcula la **probabilidad acumulada**. Le pasás un valor cuantil `q`, y te devuelve la probabilidad de obtener un resultado **menor o igual que** `q`.

- La versión `q` calcula los **cuantiles** de la distribución. Le pasás un valor de probabilidad `p`, y te devuelve el valor correspondiente de la variable aleatoria. Es decir, el valor tal que la probabilidad de obtener un número menor que él es igual a `p`.

- La versión `r` es un **generador de números aleatorios**: genera `n` resultados aleatorios tomados de la distribución.

Esto puede sonar algo abstracto, así que veamos algunos ejemplos concretos. Como ya vimos `dbinom`, vamos a concentrarnos en las otras tres.
Empecemos con `pbinom`, y volvamos al ejemplo de los dados con calaveras.
Recordá: lanzo 20 dados, cada uno tiene una chance de 1 en 6 de mostrar una calavera.
Supongamos ahora que quiero saber la probabilidad de obtener **4 o menos** calaveras.

Podría usar `dbinom` para calcular la probabilidad exacta de obtener 0, 1, 2, 3 y 4 calaveras, y luego sumar esos valores.
Pero hay una forma más rápida: usar la función `pbinom`. El comando sería:

```{r}
pbinom(q = 4, size = 20, prob = 1/6)
```

En otras palabras, hay un 76.9% de probabilidad de que al lanzar los 20 dados obtenga 4 calaveras **o menos**.
O, dicho de otra manera, R nos está diciendo que 4 es el **percentil 76.9** de esta distribución binomial.

Ahora consideremos la función `qbinom`.
Supongamos que quiero calcular el percentil 75 de la distribución binomial.
Siguiendo con el ejemplo de las calaveras, el comando sería:

```{r }
qbinom(p = 0.75, size = 20, prob = 1/6)
```
Mmm. Hay algo raro acá. Pensemos bien esto.
Lo que parece decir la función `qbinom` es que el percentil 75 de la distribución binomial es 4, aunque vimos recién que 4 es **en realidad** el percentil 76.9. Y la función `pbinom` es la correcta, te lo prometo.

Lo raro acá surge del hecho de que nuestra distribución binomial en realidad **no tiene** un percentil 75. No del todo.
¿Por qué no? Bueno, hay un 56.7% de chance de obtener 3 o menos calaveras (podés escribir `pbinom(3, 20, 1/6)` para comprobarlo), y un 76.9% de chance de obtener 4 o menos calaveras.
Entonces, en cierto sentido, el percentil 75 “debería estar entre medio” de 3 y 4 calaveras.
Pero eso no tiene sentido. ¡No podés tirar 20 dados y que salgan 3.9 calaveras!

Este problema se puede manejar de distintas formas:
podrías reportar un valor intermedio (o **interpolado**, como se dice técnicamente), como 3.9;
podrías redondear hacia abajo (a 3);
o podrías redondear hacia arriba (a 4).

La función `qbinom` **redondea hacia arriba**: si pedís un percentil que no existe literalmente (como el 75 en este ejemplo), R encuentra el valor más pequeño cuyo percentil acumulado sea **al menos** el que pediste.
En este caso, como el “verdadero” percentil 75 (sea lo que sea que eso signifique) está entre 3 y 4 calaveras, R redondea hacia arriba y te da 4.

Esta sutileza puede ser molesta, lo admito, pero por suerte **solo es un problema en distribuciones discretas** como la binomial.
Las otras distribuciones de las que voy a hablar (normal, \( t \), \( \chi^2 \) y \( F \)) son todas **continuas**, así que R siempre puede devolver un cuantil exacto cuando se lo pedís.

Finalmente, tenemos el generador de números aleatorios.
Para usar la función `rbinom`, tenés que especificar cuántas veces querés que R “simule” el experimento usando el argumento `n`, y te va a generar resultados aleatorios tomados de la distribución binomial.

Por ejemplo, si quisiera repetir el experimento de tirar dados 100 veces, puedo hacer que R simule esos resultados así:

```{r}
rbinom(n = 100, size = 20, prob = 1/6)
```
Como podés ver, los números que aparecen son bastante lo que uno esperaría, dados los resultados en @fig-4binomial1.
La mayoría de las veces saco entre 1 y 5 calaveras.

Hay muchas sutilezas sobre cómo se generan números aleatorios en una computadora, pero para los fines de este libro no necesitamos preocuparnos demasiado.

## La distribución normal

Aunque la distribución binomial es conceptualmente la más fácil de entender, **no es la más importante**.
Ese honor particular le corresponde a la *distribución normal*, también conocida como “la campana de Gauss” o simplemente “la curva de campana”.

```{r
#| label: fig-4normal
#| fig-cap: "La distribución normal con media = 0 y desviación estándar = 1. El eje x representa los valores posibles de una variable, y el eje y nos dice qué tan probable es observar ese valor. Sin embargo, notá que el eje y está etiquetado como Densidad de Probabilidad y no como Probabilidad. Esto se debe a una característica sutil —y algo frustrante— de las distribuciones continuas, que hace que el eje y se comporte de manera un poco extraña: la altura de la curva no representa literalmente la probabilidad de observar un valor x en particular. Sin embargo, sí es cierto que los valores de x más probables corresponden a las alturas mayores de la curva."

knitr::include_graphics("imgs/navarro_img/probability/standardNormal-eps-converted-to.png")
```

Una distribución normal se describe usando dos parámetros: la **media** de la distribución (\( \mu \)) y la **desviación estándar** (\( \sigma \)).
La notación que usamos a veces para indicar que una variable \( X \) tiene distribución normal es:

\[
X \sim \text{Normal}(\mu, \sigma)
\]

Claro que eso es solo notación. No nos dice nada especialmente interesante sobre la distribución normal en sí.

La fórmula matemática de la distribución normal es:

```{r echo=F}
#| label: 4normalformula
#| fig-cap: "Fórmula de la distribución normal"
knitr::include_graphics("imgs/navarro_img/probability/Normal_formula.png")
```

La fórmula es lo suficientemente importante como para que cualquiera que aprenda estadística la mire al menos una vez,
pero como este es un texto introductorio, no quiero enfocarme demasiado en eso.

En cambio, vamos a ver cómo se puede trabajar con distribuciones normales en R.
Las funciones en R para la distribución normal son `dnorm()`, `pnorm()`, `qnorm()` y `rnorm()`.
Sin embargo, **se comportan exactamente igual que sus equivalentes para la distribución binomial**, así que no hay mucho que necesites aprender nuevo.
Lo único que vale la pena señalar es que los argumentos para los parámetros se llaman `mean` y `sd`.
En casi todo lo demás, no hay diferencia.

En lugar de enfocarnos en las matemáticas, tratemos de entender **qué significa que una variable tenga distribución normal**.
Para eso, mirá la figura @fig-4normal, que muestra una distribución normal con media \( \mu = 0 \) y desviación estándar \( \sigma = 1 \).
Podés ver de dónde viene el nombre “curva de campana”: se parece un poco a una campana.

Notá que, a diferencia de los gráficos que dibujé para ilustrar la distribución binomial, la figura @fig-4normal muestra una **curva suave**, no un gráfico tipo histograma.
Esto **no es una elección arbitraria**: la distribución normal es **continua**, mientras que la binomial es **discreta**.

En el ejemplo anterior, era posible obtener 3 calaveras o 4 calaveras, pero **era imposible obtener 3.9 calaveras**. Teniendo eso en cuenta, veamos si podemos desarrollar una intuición de cómo funciona la distribución normal.
Primero, vamos a ver qué pasa cuando jugamos con los parámetros de la distribución.
Uno de los parámetros que podemos modificar es la media.
Esto desplaza la distribución hacia la derecha o hacia la izquierda.

La animación en @fig-4normalMeanShift muestra una distribución normal con media = 0, que se va moviendo desde media = 0 hasta media = 5.
Notá que, cuando cambiás la media, **la forma de la distribución no cambia**: simplemente se traslada de izquierda a derecha.
En la animación, la curva normal sube y baja un poco, pero eso es solo una característica visual de la animación (además queda lindo así).

::: {.content-visible when-format="html"}
```{r echo=F}
#| label: fig-4normalMeanShift
#| fig-cap: "Una distribución normal con media variable"
#| out.width: "50%"

knitr::include_graphics(path="imgs/gifs/normalMovingMean-1.gif")
```
:::

En cambio, si aumentamos la desviación estándar manteniendo constante la media, la cima de la distribución se queda en el mismo lugar, **pero la distribución se ensancha**.
La animación en @fig-4normalSDShift muestra lo que pasa cuando empezamos con una desviación estándar pequeña (sd = 0.5), y la aumentamos gradualmente hasta sd = 5.
Como podés ver, la distribución se expande y se vuelve más ancha a medida que aumenta la desviación estándar.

::: {.content-visible when-format="html"}
```{r echo=F}
#| label: fig-4normalSDShift
#| fig-cap: "Una distribución normal con desviación estándar variable."
#| out.width: "50%"

knitr::include_graphics(path="imgs/gifs/normalMovingSD-1.gif")
```
:::

Fijate que cuando ensanchamos la distribución, **la altura del pico disminuye**.
Eso **tiene que ocurrir**: al igual que las alturas de las barras en la distribución binomial debían **sumar 1**, el área **bajo la curva** de la distribución normal también debe ser igual a 1.

Antes de continuar, quiero señalar una característica importante de la distribución normal.
Sin importar cuál sea la media o la desviación estándar específica, el **68.3% del área** cae dentro de 1 desviación estándar de la media.
De forma similar, **el 95.4%** cae dentro de 2 desviaciones estándar, y **el 99.7%** está dentro de 3 desviaciones estándar.


### Densidad de probabilidad

Hay algo que estuve intentando ocultar durante toda mi discusión sobre la distribución normal.
Algo que algunos libros introductorios directamente omiten por completo.
Tal vez tengan razón en hacerlo: esta “cosa” que estoy ocultando es rara y contraintuitiva, incluso según los estándares algo retorcidos que rigen en estadística.
Afortunadamente, **no es algo que necesites entender a fondo** para hacer estadística básica: es algo que empieza a volverse importante más adelante, cuando salís de lo introductorio.
Así que si no te queda completamente claro, no te preocupes: tratá de captar la idea general.

A lo largo de esta discusión sobre la distribución normal, hay una o dos cosas que **no cierran del todo**.
Quizás notaste que el eje \( y \) en esas figuras está etiquetado como “Densidad de probabilidad” y no como “Probabilidad”.
Tal vez notaste que usé \( p(X) \) en lugar de \( P(X) \) al dar la fórmula de la normal.
Quizás te preguntás por qué R usa el prefijo `"d"` para funciones como `dnorm()`.
Y tal vez, solo tal vez, estuviste jugando con la función `dnorm()` y escribiste un comando como este:

```{r}
dnorm(x = 1, mean = 1, sd = 0.1)
```

Y si hiciste eso, seguramente quedaste muy confundidx.
Le pedí a R que calcule la **probabilidad de que \( x = 1 \)** para una variable normalmente distribuida con media = 1 y desviación estándar = 0.1; y R me responde que la “probabilidad” es 3.99.

Pero, como discutimos antes, las probabilidades **no pueden** ser mayores que 1.
Entonces, o me equivoqué, o eso que R me dio **no es una probabilidad**.

Resulta que la segunda opción es la correcta.
Lo que calculamos ahí no es una probabilidad: **es otra cosa**.
Para entender qué es esa otra cosa, tenemos que dedicar un momento a pensar qué significa realmente decir que \( X \) es una variable continua.

Supongamos que estamos hablando de la temperatura exterior. El termómetro me dice que hace 23 grados, pero yo sé que eso no es del todo cierto.
No son *exactamente* 23 grados. Quizás sean 23.1, me digo.
Pero tampoco es del todo cierto, porque podrían ser 23.09. Pero, claro, también podrían ser 23.091.
Bueno... ya entendés la idea.

El problema con las cantidades verdaderamente continuas es que **nunca sabés exactamente cuál es su valor**. Ahora pensá qué implica esto cuando hablamos de probabilidades.
Supongamos que la temperatura máxima de mañana se extrae de una distribución normal con media 23 y desviación estándar 1. ¿Cuál es la probabilidad de que la temperatura sea *exactamente* 23 grados?
La respuesta es “cero”, o si querés, “un número tan cercano a cero que es indistinguible de cero”.  ¿Por qué?

Porque hay una cantidad **infinita** de números reales entre 22.9999999 y 23.0000001.
La probabilidad de que cualquier número en particular sea el valor exacto que obtengamos es prácticamente cero.  No importa cuán precisa sea tu medición, **siempre** hay infinitos valores más que podrían haber sido el resultado “real”.

Esto hace que tenga **mucho menos sentido** hablar de la probabilidad de que la temperatura sea *exactamente* 23 grados.
Sin embargo, en el lenguaje cotidiano, si te digo que hace 23 grados afuera y en realidad son 22.9998, probablemente no me digas que te mentí.
Porque en la vida real, cuando decimos “23 grados”, en realidad queremos decir algo así como “entre 22.5 y 23.5 grados”.

Y aunque no parezca muy útil preguntar por la probabilidad de que la temperatura sea **exactamente** 23 grados, sí parece razonable preguntar por la probabilidad de que esté **entre 22.5 y 23.5**, o entre 20 y 30, o cualquier otro rango de valores.El punto de toda esta discusión es dejar en claro que, cuando hablamos de **distribuciones continuas**, no tiene sentido hablar de la probabilidad de un valor específico.
Sin embargo, **sí podemos** hablar de la **probabilidad de que el valor esté dentro de un cierto rango**. Y para calcular esa probabilidad, lo que necesitamos hacer es calcular el **área bajo la curva**.

Ok, eso explica parte del asunto.
Hablamos un poco sobre cómo deberían interpretarse las distribuciones continuas (es decir, el área bajo la curva es la clave),
pero todavía no expliqué realmente **qué calcula la función `dnorm()`**.
O, equivalente, ¿qué significa la fórmula de \( p(x) \) que presentamos antes?

Evidentemente, \( p(x) \) **no describe una probabilidad**. Entonces, ¿qué es?

El nombre técnico de esa cantidad \( p(x) \) es **densidad de probabilidad**,
y en los gráficos que venimos dibujando, corresponde a la **altura** de la curva.
Las densidades en sí **no tienen sentido por sí solas**; pero están “diseñadas” de manera que el **área** bajo la curva sea **una probabilidad verdadera**.

Para ser sincerx, eso es más o menos **todo lo que necesitás saber por ahora**.


## Otras distribuciones útiles

Hay muchas otras distribuciones útiles, entre ellas la distribución `t`, la distribución `F` y la distribución chi cuadrado (`χ²`).
Pronto vamos a aprender más sobre las distribuciones `t` y `F` cuando discutamos los t-tests y los ANOVA en capítulos posteriores.

Perfecto. Gracias por compartir el texto original completo. A continuación te doy la **traducción fiel** de esta sección final, que no habíamos incluido antes:

---

## Resumen sobre la probabilidad

Hablamos sobre qué significa la probabilidad, y por qué lxs estadísticxs no logran ponerse de acuerdo sobre su significado.
Hablamos de las reglas que deben cumplir las probabilidades.
Y presentamos la idea de una **distribución de probabilidad**, dedicando una buena parte del capítulo a algunas de las distribuciones más importantes con las que trabajan lxs estadísticxs.
Discutimos cosas como:

- Teoría de la probabilidad versus estadística
- Visiones frecuentista y bayesiana de la probabilidad
- Fundamentos básicos de la teoría de la probabilidad
- Distribuciones binomial y normal

Como era de esperarse, esta cobertura **está lejos de ser exhaustiva**.
La teoría de la probabilidad es una rama amplia de las matemáticas, con entidad propia, separada de su aplicación a la estadística y al análisis de datos.
Hay miles de libros escritos sobre el tema, y en general las universidades ofrecen varias materias dedicadas exclusivamente a la teoría de la probabilidad.
Incluso la tarea “más sencilla” de documentar las distribuciones de probabilidad estándar es un tema extenso.

Por suerte para vos, **muy poco de todo eso es necesario**.
Es poco probable que necesites conocer decenas de distribuciones estadísticas para hacer análisis de datos en el mundo real,
y definitivamente no las vas a necesitar para este libro.
Pero nunca está de más saber que existen otras posibilidades.

Retomando ese último punto, en cierto sentido **todo este capítulo es una especie de digresión**.
Muchas materias de estadística en psicología a nivel de grado pasan muy por arriba este contenido (sé que así fue en mi caso),
e incluso las materias más avanzadas suelen “olvidarse” de volver sobre los fundamentos básicos del campo.
La mayoría de lxs psicólogxs académicxs no sabría explicar la diferencia entre probabilidad y densidad,
y hasta hace poco, muy pocxs sabían que había una diferencia entre la probabilidad bayesiana y la frecuentista.

Sin embargo, creo que **es importante entender estas cosas antes de pasar a las aplicaciones**.
Por ejemplo, hay muchas reglas sobre lo que se puede o no se puede decir cuando hacés inferencia estadística,
y muchas de esas reglas pueden parecer arbitrarias o extrañas.
Pero empiezan a tener sentido cuando entendés que existe esta distinción entre lo bayesiano y lo frecuentista.

## Muestras, poblaciones y muestreo

Recordá que el rol de la estadística descriptiva es resumir de forma concisa lo que **sí** sabemos.
En cambio, el propósito de la estadística inferencial es “aprender lo que no sabemos a partir de lo que sí sabemos”.
¿Qué tipo de cosas nos gustaría aprender? ¿Y cómo las aprendemos?

Estas son las preguntas que están en el corazón de la estadística inferencial, y que tradicionalmente se dividen en dos grandes ideas: **estimación** y **pruebas de hipótesis**.
El objetivo de este capítulo es presentar la primera de estas ideas, la teoría de la estimación,
pero antes vamos a hablar sobre teoría del muestreo, porque **la estimación no tiene sentido si no entendés cómo funciona el muestreo**.

Así que este capítulo se divide en dos partes: teoría del muestreo, y cómo usar esa teoría para hablar sobre cómo piensan lxs estadísticxs el problema de la estimación.
Ya hicimos bastante muestreo, así que ya estás familiarizadx con algunas de las ideas principales.

La **teoría del muestreo** cumple un rol enorme a la hora de definir los supuestos sobre los que se apoyan tus inferencias estadísticas.
Y para poder hablar de “hacer inferencias” como lo hacen lxs estadísticxs, tenemos que ser un poco más explícitxs sobre **de dónde** extraemos inferencias (la muestra)
y **sobre qué** extraemos inferencias (la población).

En casi cualquier situación de interés, lo que tenemos disponible como investigadores es una **muestra** de datos.
Podés haber hecho un experimento con cierta cantidad de participantes; una encuestadora puede haber llamado a cierta cantidad de personas para preguntarles su intención de voto; etc.
En todos los casos: el conjunto de datos que tenemos es **finito e incompleto**.
No podemos hacer que cada persona del mundo participe en nuestro experimento; una encuestadora no tiene ni el tiempo ni el dinero para llamar a cada votante del país, etc.

En nuestra discusión anterior sobre estadística descriptiva, la muestra era **lo único** que nos interesaba.
Nuestro único objetivo era encontrar formas de describir, resumir y graficar **esa muestra**. Pero eso está por cambiar.


### Definir una población

Una muestra es algo concreto. Podés abrir un archivo de datos y ver los valores de tu muestra ahí.
Una **población**, en cambio, es un concepto más abstracto.
Se refiere al conjunto de **todas** las personas, o de **todas** las observaciones, sobre las que querés sacar conclusiones,
y generalmente es **mucho** más grande que la muestra.

En un mundo ideal, lxs investigadores empezarían cada estudio con una idea clara de cuál es su población de interés,
ya que el proceso de diseñar un estudio y poner a prueba hipótesis con los datos obtenidos **depende de esa población sobre la que queremos hablar**.

Sin embargo, eso **no siempre** ocurre en la práctica: en general, lxs investigadores tienen solo una idea vaga de cuál es la población,
y diseñan el estudio **lo mejor que pueden** con base en eso.

A veces es fácil definir la población de interés.
Por ejemplo, en el caso de la “encuestadora”, la población está compuesta por **todas las personas habilitadas para votar** en el momento de la encuesta —millones de personas. La muestra era un conjunto de 1000 personas que todas pertenecen a esa población.

En la mayoría de los casos, la situación es mucho menos clara.
En un experimento psicológico típico, determinar cuál es la población de interés puede ser algo más complicado.

Supongamos que hago un experimento con 100 estudiantes universitarios como participantes.
Mi objetivo, como científica cognitiva, es aprender algo sobre cómo funciona la mente.
Entonces, ¿cuál de las siguientes opciones debería contar como “la población”?

- ¿Todxs lxs estudiantes de psicología de grado de la Universidad de Adelaida?
- ¿Estudiantes de psicología de grado en general, en cualquier parte del mundo?
- ¿Personas que viven actualmente en Australia?
- ¿Personas australianas de edades similares a mi muestra?
- ¿Cualquier persona viva en la actualidad?
- ¿Cualquier ser humano, pasado, presente o futuro?
- ¿Cualquier organismo biológico con suficiente inteligencia y que opere en un entorno terrestre?
- ¿Cualquier ser inteligente?

Cada una de estas opciones define un grupo real de entidades con mente, que podrían interesarme como científica cognitiva,
y **no está nada claro cuál de ellas debería considerarse la verdadera población de interés**.


### Muestras aleatorias simples

Independientemente de cómo definamos la población, el punto clave es que la muestra es un **subconjunto** de la población,
y nuestro objetivo es usar lo que sabemos de la muestra para hacer inferencias sobre las propiedades de la población.

La relación entre la muestra y la población **depende del procedimiento** por el cual se seleccionó la muestra.
Este procedimiento se conoce como **método de muestreo**, y es importante entender por qué eso importa.

Para mantenerlo simple, imaginá que tenemos una bolsa con 10 fichas.
Cada ficha tiene una letra única impresa, así que podemos distinguirlas.
Las fichas vienen en dos colores: negro y blanco.

```{r echo=F}
#| label: fig-srs1
#| fig-cap: "Muestreo aleatorio simple sin reemplazo a partir de una población finita."

knitr::include_graphics("imgs/navarro_img/estimation/srs1.png")
```

Este conjunto de fichas es la población de interés, y está representada gráficamente en la parte izquierda de la figura @fig-srs1.

Como podés ver en la imagen, hay 4 fichas negras y 6 fichas blancas,
pero en la vida real **no sabríamos eso a menos que miremos dentro de la bolsa**.

Ahora imaginá que hacés el siguiente “experimento”: agitás la bolsa, cerrás los ojos y sacás 4 fichas, sin devolverlas después de sacarlas.
Primero sale la ficha $a$ (negra), luego la $c$ (blanca), después la $j$ (blanca), y finalmente la $b$ (negra).
Si quisieras, podrías volver a meter todas las fichas en la bolsa y repetir el experimento, como se muestra en el lado derecho de la figura @fig-srs1.

Cada vez vas a obtener resultados distintos, pero el procedimiento es **idéntico** en todos los casos.
El hecho de que el mismo procedimiento pueda producir distintos resultados cada vez es lo que hace que lo llamemos un **proceso aleatorio**.
Sin embargo, como agitamos la bolsa antes de sacar cualquier ficha, parece razonable pensar que **cada ficha tenía la misma probabilidad de ser elegida**. Un procedimiento en el que **cada miembro de la población tiene la misma probabilidad de ser seleccionado** se llama una **muestra aleatoria simple**.El hecho de que **no** devolvimos las fichas a la bolsa después de sacarlas significa que **no podés observar la misma ficha dos veces**, y en estos casos se dice que las observaciones fueron tomadas **sin reemplazo**.

Para ayudarte a entender la importancia del procedimiento de muestreo, considerá una alternativa.
Supongamos que mi hijo de 5 años abre la bolsa y decide sacar cuatro fichas negras, sin devolver ninguna.
Este esquema de muestreo **sesgado** se muestra en la figura @fig-brs.

```{r echo=F}
#| label: fig-brs
#| fig-cap: "Muestreo sesgado sin reemplazo a partir de una población finita."

knitr::include_graphics("imgs/navarro_img/estimation/brs.png")
```

Ahora considerá el valor informativo de observar 4 fichas negras y 0 blancas.
Claramente, eso **depende del esquema de muestreo**, ¿no?
Si sabés que el procedimiento estaba sesgado a seleccionar solo fichas negras, entonces una muestra compuesta únicamente por fichas negras **no te dice mucho** sobre la población. Por esta razón, a lxs estadísticxs **les encanta** cuando un conjunto de datos puede considerarse una muestra aleatoria simple, porque hace que el análisis de los datos sea **mucho** más fácil.

Hay un tercer procedimiento que vale la pena mencionar.
Esta vez, cerramos los ojos, agitamos la bolsa y sacamos una ficha.
**Pero ahora**, registramos la ficha y luego la devolvemos a la bolsa.
De nuevo, cerramos los ojos, agitamos la bolsa y sacamos otra ficha.
Repetimos este procedimiento hasta tener 4 fichas.

Los conjuntos de datos generados de esta manera **también** se consideran muestras aleatorias simples,
pero como devolvemos las fichas a la bolsa después de cada extracción, se dice que es un muestreo **con reemplazo**.
La diferencia con el primer caso es que ahora **es posible observar el mismo miembro de la población más de una vez**, como se muestra en la figura @fig-srs2.

```{r echo=F}
#| label: fig-srs2
#| fig-cap: "Muestreo aleatorio simple con reemplazo a partir de una población finita."

knitr::include_graphics("imgs/navarro_img/estimation/srs2.png")
```

La mayoría de los experimentos en psicología tienden a ser sin reemplazo,
porque **no se permite que una misma persona participe dos veces** en el mismo experimento.
Sin embargo, la mayoría de la teoría estadística **asume** que los datos provienen de una muestra aleatoria simple **con reemplazo**.

En la vida real, esto **rara vez importa**.
Si la población es grande (por ejemplo, más de 10 elementos),
la diferencia entre muestreo con o sin reemplazo es **demasiado pequeña como para preocuparse**.

En cambio, la diferencia entre una **muestra aleatoria simple** y una **muestra sesgada** **no** es algo que podamos ignorar tan fácilmente.


### La mayoría de las muestras no son aleatorias simples

Como pudiste ver en la lista de posibles poblaciones que mostré antes, es casi imposible obtener una muestra aleatoria simple de la mayoría de las poblaciones de interés.
Cuando hago experimentos, ya considero un pequeño milagro que mis participantes sean una muestra aleatoria de lxs estudiantes de psicología de grado en la Universidad de Adelaida,
¡y eso que esa es por lejos la población más acotada a la que podría querer generalizar!

Una discusión detallada de otros esquemas de muestreo está más allá del alcance de este libro,
pero para que tengas una idea de lo que existe, acá listo algunos de los más importantes:

- **Muestreo estratificado**. Supongamos que tu población se divide (o se puede dividir) en varias subpoblaciones diferentes, o **estratos**.
  Por ejemplo, tal vez estés haciendo un estudio en varios sitios distintos.
  En lugar de intentar muestrear al azar de la población total, podés intentar recolectar una muestra aleatoria separada de cada uno de los estratos.
  El muestreo estratificado a veces es más fácil de realizar que el muestreo aleatorio simple, especialmente cuando la población ya está dividida en estratos definidos.
  También puede ser más eficiente, sobre todo si algunas subpoblaciones son poco frecuentes.
  Por ejemplo, al estudiar esquizofrenia, sería mucho mejor dividir la población en dos estratos (con y sin esquizofrenia), y luego seleccionar la misma cantidad de personas de cada grupo.
  Si seleccionaras gente al azar, obtendrías tan pocas personas con esquizofrenia que el estudio sería inútil.
  Este tipo específico de muestreo estratificado se conoce como **sobremuestreo** (*oversampling*), porque busca deliberadamente sobre-representar grupos poco frecuentes.

- **Muestreo en bola de nieve** (*snowball sampling*) es una técnica especialmente útil cuando la población de interés es “oculta” o difícil de acceder, y es bastante común en las ciencias sociales.
  Por ejemplo, supongamos que lxs investigadorxs quieren hacer una encuesta de opinión entre personas trans.
  El equipo de investigación tal vez tenga datos de contacto de unas pocas personas trans, así que la encuesta empieza por invitarlas a participar (etapa 1).
  Al final de la encuesta, se les pide a lxs participantes que proporcionen contactos de otras personas que podrían querer participar.
  En la etapa 2, se encuesta a esas nuevas personas.
  El proceso continúa hasta que lxs investigadorxs hayan reunido suficientes datos.

  La gran **ventaja** del muestreo en bola de nieve es que te permite obtener datos en situaciones donde de otro modo sería **imposible**.
  En el plano estadístico, la principal **desventaja** es que la muestra es fuertemente no aleatoria, y en formas difíciles de compensar.
  En el plano ético, la desventaja es que el procedimiento puede ser problemático si no se maneja bien, porque las poblaciones ocultas a menudo están ocultas **por una razón**.

  Elegí a las personas trans como ejemplo para destacar esto: si no sos cuidadoso, podrías terminar **exponiendo a alguien que no quiere ser visibilizadx** (algo realmente inaceptable).
  Y eso puede tener consecuencias personales o profesionales graves para esa persona. Incluso si no cometés ese error, **sigue siendo una intromisión** usar las redes sociales de las personas para estudiarlas. Es muy difícil obtener consentimiento informado **antes** de contactarlas, y en muchos casos el simple hecho de decirles “hola, queremos estudiar tus datos” puede ser molesto o invasivo. Las redes sociales son cosas complejas, y el hecho de que *puedas* usarlas para recolectar datos no siempre significa que *debás* hacerlo.

- **Muestreo por conveniencia** es más o menos lo que suena: las muestras se eligen de una forma que le resulte conveniente al/la investigador/a,
  y no son seleccionadas al azar de la población de interés.
  El muestreo en bola de nieve es una forma de muestreo por conveniencia, pero hay muchas otras.
  Un ejemplo común en psicología son los estudios que se hacen con estudiantes de grado en psicología.
  Estas muestras suelen ser no aleatorias en dos sentidos: primero, porque limitás los datos a una sola subpoblación (estudiantes de psicología);
  segundo, porque lxs estudiantes suelen elegir en qué estudios participar,
  así que la muestra es un subconjunto **autoseleccionado** de estudiantes de psicología,
  no un subconjunto seleccionado aleatoriamente.
  En la vida real, **la mayoría de los estudios son muestras por conveniencia** de algún tipo.
  A veces eso es una limitación seria... pero **no siempre**.


### ¿Qué tan grave es no tener una muestra aleatoria simple?

Ok, entonces recolectar datos en el mundo real **casi nunca** involucra una muestra aleatoria simple. ¿Y eso importa?

Con un poco de reflexión, te debería quedar claro que **puede** importar si tus datos **no** son una muestra aleatoria simple:
basta con pensar en la diferencia entre la figura @fig-srs1 y la figura @fig-brs.

Sin embargo, **no es tan grave como suena**.
Algunos tipos de muestras sesgadas **no son problemáticos en absoluto**.
Por ejemplo, cuando usás muestreo estratificado, en realidad **sabés** cuál es el sesgo porque **vos mismx lo generaste a propósito**,
a menudo para hacer que tu estudio sea más efectivo.
Y existen técnicas estadísticas que permiten ajustar los análisis para tener en cuenta esos sesgos (¡aunque este libro no las cubre!).

En general, es importante recordar que el muestreo aleatorio **es un medio para un fin**, no un fin en sí mismo.
Supongamos que usaste una muestra por conveniencia, y por eso podés asumir que tiene algún sesgo.
Un sesgo en el método de muestreo **solo es problemático si te lleva a sacar conclusiones equivocadas**.

Desde esa perspectiva, **no necesitamos que la muestra sea aleatoria en absolutamente todos los aspectos**:
solo necesitamos que sea aleatoria **en relación al fenómeno psicológico que estamos estudiando**.

Supongamos que estoy haciendo un estudio sobre la capacidad de memoria de trabajo.
En el estudio 1, tengo la capacidad de muestrear al azar de toda la población humana viva, **con una sola excepción**: solo puedo muestrear personas nacidas un lunes.
En el estudio 2, puedo muestrear al azar de la población australiana.

Quiero generalizar mis resultados a **toda la población humana actual**.

¿Cuál de los dos estudios preferirías? La respuesta, obviamente, es el estudio 1. ¿Por qué? Porque **no hay ninguna razón** para pensar que “haber nacido un lunes” tenga alguna relación interesante con la capacidad de memoria de trabajo. En cambio, **sí puedo imaginar varias razones** por las que “ser australianx” podría importar. Australia es un país rico, industrializado, con un sistema educativo muy desarrollado. Las personas que crecieron en ese sistema habrán tenido experiencias de vida **mucho más parecidas** a las de quienes diseñaron los tests de capacidad de memoria de trabajo.
Esa experiencia compartida podría traducirse en creencias similares sobre cómo “hacer un test”, en supuestos comunes sobre cómo funcionan los experimentos psicológicos, y así.

Estas cosas **podrían importar**. Por ejemplo, el “estilo de rendir exámenes” puede haber enseñado a lxs participantes australianxs a concentrarse exclusivamente en materiales bastante abstractos,
comparado con personas que no crecieron en un entorno similar, lo que podría llevar a una **imagen distorsionada** de lo que realmente es la capacidad de memoria de trabajo.

Hay dos ideas importantes escondidas en esta discusión: Primero, cuando diseñás tus propios estudios, es importante pensar **cuál es la población que te interesa**,
y esforzarte por muestrear de una forma apropiada para esa población. En la práctica, muchas veces no te queda otra que trabajar con una “muestra por conveniencia”
(por ejemplo, docentes de psicología que usan estudiantes de psicología porque es la forma más barata de recolectar datos, y nuestros presupuestos no son exactamente desbordantes de oro). Pero si hacés eso, al menos tendrías que dedicar algo de tiempo a pensar **cuáles son los posibles riesgos** de trabajar así.

Segundo, si vas a criticar el estudio de otra persona porque usó una muestra por conveniencia,en lugar de haber hecho el esfuerzo enorme de muestrear aleatoriamente de toda la población humana, al menos tené la cortesía de ofrecer una **hipótesis concreta** sobre **cómo** podría haberse distorsionado el resultado. Recordá: toda persona que trabaja en ciencia es consciente de este problema,
y hace lo que puede por compensarlo.

Decir simplemente “el estudio solo incluyó personas del grupo TAL” **no ayuda en nada**,
y roza lo insultante para lxs investigadorxs, que probablemente **sí estaban al tanto del problema**,
pero no disponían de la **infinita cantidad de tiempo y dinero** que haría falta para construir la muestra perfecta. En resumen: si querés ofrecer una crítica **responsable** sobre el muestreo, entonces sé **útil**. Repetir verdades obvias como las que acabo de presentar en esta sección **no sirve de nada**.
Gracias. A continuación te presento la **traducción fiel** del comienzo de la sección *“Population parameters and sample statistics”*:

---

### Parámetros poblacionales y estadísticas muestrales

Bien. Dejando de lado los espinosos problemas metodológicos asociados con obtener una muestra aleatoria, consideremos un tema algo distinto.

Hasta este punto, venimos hablando de poblaciones como lo haría una persona científica.
Para una psicóloga, una población podría ser un grupo de personas.
Para una ecóloga, una población podría ser un grupo de osos.
En la mayoría de los casos, las poblaciones que interesan a la ciencia son cosas concretas que realmente existen en el mundo.

Lxs estadísticxs, sin embargo, son un grupo curioso.
Por un lado, **sí** se interesan en datos reales y en la ciencia, del mismo modo que lxs científicxs.
Pero por otro lado, también trabajan en el plano de la abstracción pura, como lo hacen lxs matemáticxs.
Como consecuencia, la teoría estadística tiende a definir las poblaciones de forma algo más abstracta.

Del mismo modo que lxs psicólogxs convierten ideas teóricas abstractas en mediciones concretas,
lxs estadísticxs operacionalizan el concepto de “población” en términos de **objetos matemáticos** con los que saben trabajar.

Ya te cruzaste con estos objetos: se llaman **distribuciones de probabilidad** (¿te acordás? el lugar del que vienen los datos).

La idea es muy simple. Supongamos que hablamos de puntuaciones de CI (coeficiente intelectual).
Para una psicóloga, la población de interés es un grupo de personas reales que tienen puntajes de CI.
Una estadística “simplifica” eso definiendo operativamente la población como la distribución de probabilidad mostrada en la figura @fig-IQdist (panel a).

```r
#| label: fig-IQdist
#| fig-cap: "Distribución poblacional de puntuaciones de CI (panel a) y dos muestras extraídas al azar de esa población. En el panel b hay una muestra de 100 observaciones; en el panel c, una muestra de 10.000 observaciones."
#| out-width: "100%"

knitr::include_graphics("imgs/figures/navIQ.png")
```

Los tests de CI están diseñados para que el promedio sea 100, la desviación estándar sea 15, y la distribución de puntajes sea normal.
Estos valores se conocen como **parámetros poblacionales**, porque son características de toda la población.
Es decir, decimos que la media poblacional \( \mu \) es 100, y la desviación estándar poblacional \( \sigma \) es 15.

Ahora supongamos que recolectamos algunos datos.
Seleccionamos 100 personas al azar y les administramos un test de CI, lo que nos da una muestra aleatoria simple de la población.
La muestra consistiría en una colección de números como esta:

`106 101 98 80 74 ... 107 72 100`

Cada una de estas puntuaciones fue extraída de una distribución normal con media 100 y desviación estándar 15.
Si dibujo un histograma de la muestra, obtengo algo como lo que se ve en el panel b de la figura @fig-IQdist.
Como podés ver, el histograma tiene **más o menos** la forma correcta, pero es una aproximación muy burda a la verdadera distribución poblacional del panel a.

La media muestral es bastante cercana a la media poblacional (100), pero no es idéntica.
En este caso, resulta que las personas de la muestra tienen un CI medio de 98.5...

---

¿Querés que continúe con la parte siguiente de esta sección?
