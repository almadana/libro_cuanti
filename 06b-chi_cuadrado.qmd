---
author:
    -GPT4-o y √Ålvaro Cabana
lang: es
abstract-title: Notas
abstract: Traducido al espa√±ol rioplatense por ChatGPT4-o bajo la supervisi√≥n de √Ålvaro Cabana.
aliases: [06b-chi_cuadrado.html]
---

# Las pruebas de Chi Cuadrado

## Chi cuadrado: contar tambi√©n es hacer inferencia

¬øTe acord√°s cuando te dijeron que ‚Äúla estad√≠stica no es solo para n√∫meros continuos‚Äù? Bueno, capaz nunca te lo dijeron, pero deber√≠an. Porque la mayor√≠a de los datos que vas a encontrar en psicolog√≠a no son promedios, ni puntajes en escalas. Son **categor√≠as**. Personas que dijeron ‚Äús√≠‚Äù o ‚Äúno‚Äù. Pacientes que respondieron ‚Äúde acuerdo‚Äù, ‚Äúneutral‚Äù o ‚Äúen desacuerdo‚Äù. Estudiantes que eligieron Psicolog√≠a, Derecho o Ingenier√≠a. Frecuencias. Tablas. Conteos.

Y ac√° es donde aparece nuestro h√©roe estad√≠stico del d√≠a: la **prueba chi cuadrado**.

Pero antes de contarte c√≥mo funciona, vamos a meternos en un problema real que podr√≠as encontrarte en el pasillo de la facultad.


### ¬øImporta tu carrera?

Imagin√° que hac√©s una encuesta en la universidad. Les pregunt√°s a 100 estudiantes de diferentes carreras si est√°n a favor o en contra de legalizar la eutanasia.

Cuando junt√°s los datos, ves algo as√≠:

| Carrera    | A favor | En contra |
| ---------- | ------- | --------- |
| Psicolog√≠a | 30      | 10        |
| Medicina   | 20      | 20        |
| Derecho    | 10      | 10        |

Mir√° los n√∫meros. Parece que los de Psicolog√≠a est√°n m√°s a favor que el resto, ¬øno? ¬øY los de Derecho? Parecen m√°s divididos. Pero par√°... ¬øestas diferencias son reales? ¬øO podr√≠an haberse dado por azar?

Eso es lo que queremos saber. Y no lo podemos saber solo ‚Äúmirando la tabla‚Äù.


### Contar tambi√©n puede ser enga√±oso

En los tests *t* ve√≠amos diferencias entre promedios. Y aprendimos que el azar puede producir diferencias entre medias incluso cuando no hay ning√∫n efecto. Ac√° pasa lo mismo: **el azar tambi√©n puede producir diferencias entre frecuencias**.

Entonces, si quer√©s saber si hay una relaci√≥n entre dos variables categ√≥ricas (como carrera y opini√≥n), ten√©s que hacer lo mismo que hac√≠amos con medias: **ver qu√© tan diferente es lo que observ√°s de lo que esperar√≠as si no hubiera relaci√≥n**.

Pero, ¬øqu√© significa ‚Äúsi no hubiera relaci√≥n‚Äù?

Significa que **la opini√≥n sobre eutanasia no deber√≠a depender de la carrera**. Deber√≠as ver m√°s o menos la misma proporci√≥n de opiniones en todas las carreras. Si hay m√°s o menos es porque algo est√° pasando... o porque justo te tocaron respuestas as√≠, de pura suerte.

Ese es el coraz√≥n del test chi cuadrado: **comparar lo que observaste con lo que esperar√≠as si las cosas fueran independientes**, y medir cu√°n grande es esa diferencia.


## La gran idea del test chi cuadrado

Ac√° va una idea poderosa: **el azar tambi√©n puede producir diferencias llamativas en tablas de frecuencias**.

Cuando lo que est√°s midiendo son cantidades (como puntajes), lo que cambia de muestra en muestra es el promedio. Pero cuando med√≠s categor√≠as, lo que cambia de muestra en muestra son los **conteos**. Y eso puede ser tan enga√±oso como cualquier otra cosa.

As√≠ que, como buenos cient√≠ficos, vamos a hacer lo mismo que en los *t*-tests: vamos a comparar lo que vimos con lo que **esperar√≠amos si no hubiera ning√∫n efecto**.

En otras palabras: vamos a construir una tabla de **frecuencias esperadas**, y ver qu√© tan distinta es de la tabla que observamos. Y para eso usamos esta f√≥rmula:

$$
  \chi^2 = \sum \frac{(O - E)^2}{E}
$$

Donde:

* $O$ es lo que **observaste** (Observed)
* $E$ es lo que **esperar√≠as** si no hubiera relaci√≥n (Expected)

La idea es simple: **mir√°s cada celda de la tabla**, calcul√°s cu√°n diferente es de lo esperado, lo elev√°s al cuadrado (para que las diferencias positivas y negativas no se cancelen), y lo divid√≠s por el valor esperado. Despu√©s sum√°s todo. Y eso te da un n√∫mero: el valor de chi cuadrado.

### Pero... ¬øc√≥mo se calculan las esperadas?

Gran pregunta. Y la respuesta tambi√©n tiene sentido. Si no hubiera ninguna relaci√≥n entre las variables (por ejemplo, entre carrera y opini√≥n), entonces la proporci√≥n de respuestas ‚Äúa favor‚Äù deber√≠a ser la misma en todas las carreras. Lo que esper√°s en cada celda se calcula as√≠:

$$
  E_{ij} = \frac{(total\ fila) \times (total\ columna)}{(total\ general)}
$$

No hace falta memorizarlo. Vamos a hacerlo con los datos de reci√©n.


### Cargar los datos y armar la tabla

```{r}
#| label: tbl-opinion-carrera
#| tbl-cap: "Frecuencias observadas: opini√≥n sobre eutanasia por carrera"

opinion <- matrix(c(30, 10, 20, 20, 10, 10),
                  nrow = 3, byrow = TRUE)
rownames(opinion) <- c("Psicolog√≠a", "Medicina", "Derecho")
colnames(opinion) <- c("A favor", "En contra")

opinion
```


### Calcular las esperadas

```{r}
#| label: tbl-esperadas
#| tbl-cap: "Frecuencias esperadas bajo la hip√≥tesis nula de independencia"

chisq_expected <- chisq.test(opinion)$expected
chisq_expected
```

Listo. Ahora ten√©s dos tablas: la observada y la esperada. La chi cuadrado compara ambas. Cuanto m√°s distintas sean, m√°s grande ser√° el valor del estad√≠stico, y menos probable ser√° que esas diferencias se deban solo al azar.

En el siguiente paso vamos a visualizar estas diferencias, para que puedas ver con tus propios ojos lo que el test est√° midiendo.


```{r}
#| label: fig-residuales-heatmap
#| fig-cap: "Mapa de calor de los residuales (O - E) entre lo observado y lo esperado"

library(tidyverse)

# Crear la tabla
observado <- matrix(c(30, 10, 20, 20, 10, 10), 
                    nrow = 3, byrow = TRUE,
                    dimnames = list(c("Psicolog√≠a", "Medicina", "Derecho"),
                                    c("A favor", "En contra")))

# Calcular las esperadas
esperado <- chisq.test(observado)$expected

# Calcular los residuales
residual <- observado - esperado

# Pasar a formato largo para ggplot
resid_df <- as.data.frame(as.table(residual)) |>
  rename(Carrera = Var1, Opinion = Var2, Residual = Freq)

# Graficar
ggplot(resid_df, aes(x = Opinion, y = Carrera, fill = Residual)) +
  geom_tile(color = "white") +
  geom_text(aes(label = round(Residual, 1)), size = 5) +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0,
                       name = "O - E") +
  theme_minimal(base_size = 14) +
  labs(title = "Mapa de calor de residuales (O - E)",
       x = NULL, y = NULL)
```

Este gr√°fico ayuda a responder visualmente la pregunta: **¬øcu√°les celdas est√°n m√°s lejos de lo que esperar√≠amos si no hubiera relaci√≥n?**

Este mapa de calor muestra visualmente **d√≥nde est√°n las mayores discrepancias** entre lo observado y lo esperado:

* Rojo = m√°s de lo esperado
* Azul = menos de lo esperado
* Blanco = cerca de lo esperado

Como ves, Psicolog√≠a tiene m√°s respuestas ‚ÄúA favor‚Äù de lo que esperar√≠a el azar. Medicina est√° m√°s cerca del equilibrio. Derecho tiene menos ‚ÄúA favor‚Äù de lo esperado. Todo eso es lo que est√° capturando el valor chi cuadrado.

Perfecto, ahora seguimos con el c√°lculo del estad√≠stico $\chi^2$, su valor *p*, y c√≥mo se interpreta dentro de su distribuci√≥n.

---

## Calcular el valor chi cuadrado

Ya tenemos nuestras tablas de frecuencias observadas y esperadas, y tambi√©n los residuales. Ahora vamos a calcular el valor de la estad√≠stica chi cuadrado. Como dijimos antes, esta estad√≠stica resume **cu√°n diferentes son en total** las frecuencias observadas de las esperadas.

Lo pod√©s hacer a mano con la f√≥rmula, pero es m√°s com√∫n dejar que R lo haga por vos:

```{r}
#| label: chisq-prueba
#| tbl-cap: "Resultado de la prueba chi cuadrado"

chisq.test(observado)
```

Este test te devuelve varias cosas importantes:

* El valor de $\chi^2$
* Los **grados de libertad** (df), que son $(n_{\text{filas}} - 1) \times (n_{\text{columnas}} - 1)$
* El **valor *p***, que indica la probabilidad de obtener un $\chi^2$ igual o mayor al observado, si la hip√≥tesis nula fuera verdadera

---

## La distribuci√≥n chi cuadrado

¬øDe d√≥nde sale ese valor *p*? Del mismo lugar que en todos los tests: de una **distribuci√≥n nula**. En este caso, es la distribuci√≥n **chi cuadrado** con los grados de libertad apropiados.

### üß† Gran idea:

> La distribuci√≥n chi cuadrado te dice **qu√© tan grandes pueden ser las diferencias por puro azar**, cuando no hay relaci√≥n entre las variables.

Y tiene una forma particular: empieza en cero (nunca es negativa), y tiene una **cola hacia la derecha**. Cuanto m√°s grandes las diferencias, menos probables.

Podemos visualizarla as√≠:

```{r}
#| label: fig-chisq-dist
#| fig-cap: "Distribuci√≥n chi cuadrado con 2 grados de libertad"

library(ggplot2)

df <- 2
x_vals <- seq(0, 15, length.out = 300)
y_vals <- dchisq(x_vals, df = df)

ggplot(data.frame(x = x_vals, y = y_vals), aes(x, y)) +
  geom_line() +
  geom_vline(xintercept = chisq.test(observado)$statistic, linetype = "dashed", color = "red") +
  annotate("text", x = chisq.test(observado)$statistic + 0.5, y = max(y_vals)/2,
           label = "œá¬≤ observado", color = "red") +
  theme_minimal(base_size = 14) +
  labs(title = "Distribuci√≥n chi cuadrado bajo la hip√≥tesis nula",
       x = "Valor œá¬≤", y = "Densidad")
```

La l√≠nea roja muestra el valor de $\chi^2$ que obtuvimos. El √°rea bajo la curva a su derecha es el **valor *p***.


### Interpretar el resultado

En este ejemplo, si el valor *p* es menor a 0.05, dir√≠amos que es **poco probable** que esas diferencias se deban solo al azar. Entonces, **rechazamos la hip√≥tesis nula** de independencia: creemos que **la carrera est√° asociada con la opini√≥n** sobre la eutanasia.

Pero como siempre, eso no significa que sepamos por qu√©, ni cu√°l grupo hizo la diferencia. Para eso miramos los **residuales**, que ya graficamos.

