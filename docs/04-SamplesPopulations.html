<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Danielle J. Navarro">
<meta name="author" content="Matthew J. C. Crump">

<title>Respondiendo preguntas con datos - 5&nbsp; Probabilidad, muestreo y estimación</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./05-Foundation_Inference.html" rel="next">
<link href="./03-Correlation.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-1116FZ99DZ"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-1116FZ99DZ', { 'anonymize_ip': true});
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta property="og:title" content="Respondiendo preguntas con datos - 5&nbsp; Probabilidad, muestreo y estimación">
<meta property="og:description" content="Sections 4.1 &amp; 4.9 - Adapted text by Danielle Navarro Section 4.10 - 4.11 &amp; 4.13 - Mix of Matthew Crump &amp; Danielle Navarro Section 4.12 - 4.13 - Adapted text by Danielle Navarro">
<meta property="og:image" content="https://almadana.github.io/libro_cuanti/imgs/navarro_img/probability/frequentistProb_es.png">
<meta property="og:site-name" content="Respondiendo preguntas con datos">
<meta property="og:image:height" content="4800">
<meta property="og:image:width" content="7200">
<meta name="twitter:title" content="Respondiendo preguntas con datos - 5&nbsp; Probabilidad, muestreo y estimación">
<meta name="twitter:description" content="A free textbook teaching introductory statistics for undergraduates in psychology, including a lab manual, and course website. Licensed on CC BY SA 4.0">
<meta name="twitter:image" content="https://almadana.github.io/libro_cuanti/imgs/TextbookCover.png">
<meta name="twitter:site" content="@MattCrumpLab">
<meta name="twitter:card" content="summary">
<meta name="twitter:image-height" content="1310">
<meta name="twitter:image-width" content="916">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./04-SamplesPopulations.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Probabilidad, muestreo y estimación</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Respondiendo preguntas con datos</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/almadana/libro_cuanti/" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Buscar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefacio</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-Science_Data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">¿Por qué estadística?</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-Describing_Data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Describir los datos</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02b-tablas_final.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Tablas</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-Correlation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Correlación</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-SamplesPopulations.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Probabilidad, muestreo y estimación</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-Foundation_Inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Fundamentos de la inferencia</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-ttests.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Pruebas t</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06b-chi_cuadrado.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Pruebas chi cuadrado</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-ANOVA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">ANOVA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-RMANOVA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Repeated Measures ANOVA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-FactorialANOVA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Factorial ANOVA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-MixedANOVA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">More On Factorial Designs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-Simulation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Simulating Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-Thinking.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Thinking about answering questions with data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-Gifs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">GIFs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#en-qué-se-diferencian-la-probabilidad-y-la-estadística" id="toc-en-qué-se-diferencian-la-probabilidad-y-la-estadística" class="nav-link active" data-scroll-target="#en-qué-se-diferencian-la-probabilidad-y-la-estadística"><span class="header-section-number">5.1</span> ¿En qué se diferencian la probabilidad y la estadística?</a></li>
  <li><a href="#qué-significa-probabilidad" id="toc-qué-significa-probabilidad" class="nav-link" data-scroll-target="#qué-significa-probabilidad"><span class="header-section-number">5.2</span> ¿Qué significa probabilidad?</a>
  <ul class="collapse">
  <li><a href="#la-visión-frecuentista" id="toc-la-visión-frecuentista" class="nav-link" data-scroll-target="#la-visión-frecuentista"><span class="header-section-number">5.2.1</span> La visión frecuentista</a></li>
  <li><a href="#la-visión-bayesiana" id="toc-la-visión-bayesiana" class="nav-link" data-scroll-target="#la-visión-bayesiana"><span class="header-section-number">5.2.2</span> La visión bayesiana</a></li>
  <li><a href="#cuál-es-la-diferencia-y-quién-tiene-razón" id="toc-cuál-es-la-diferencia-y-quién-tiene-razón" class="nav-link" data-scroll-target="#cuál-es-la-diferencia-y-quién-tiene-razón"><span class="header-section-number">5.2.3</span> ¿Cuál es la diferencia? ¿Y quién tiene razón?</a></li>
  </ul></li>
  <li><a href="#teoría-básica-de-la-probabilidad" id="toc-teoría-básica-de-la-probabilidad" class="nav-link" data-scroll-target="#teoría-básica-de-la-probabilidad"><span class="header-section-number">5.3</span> Teoría básica de la probabilidad</a>
  <ul class="collapse">
  <li><a href="#introducción-a-las-distribuciones-de-probabilidad" id="toc-introducción-a-las-distribuciones-de-probabilidad" class="nav-link" data-scroll-target="#introducción-a-las-distribuciones-de-probabilidad"><span class="header-section-number">5.3.1</span> Introducción a las distribuciones de probabilidad</a></li>
  </ul></li>
  <li><a href="#la-distribución-binomial" id="toc-la-distribución-binomial" class="nav-link" data-scroll-target="#la-distribución-binomial"><span class="header-section-number">5.4</span> La distribución binomial</a>
  <ul class="collapse">
  <li><a href="#introducción-a-la-binomial" id="toc-introducción-a-la-binomial" class="nav-link" data-scroll-target="#introducción-a-la-binomial"><span class="header-section-number">5.4.1</span> Introducción a la binomial</a></li>
  <li><a href="#trabajando-con-la-distribución-binomial-en-r" id="toc-trabajando-con-la-distribución-binomial-en-r" class="nav-link" data-scroll-target="#trabajando-con-la-distribución-binomial-en-r"><span class="header-section-number">5.4.2</span> Trabajando con la distribución binomial en R</a></li>
  </ul></li>
  <li><a href="#la-distribución-normal" id="toc-la-distribución-normal" class="nav-link" data-scroll-target="#la-distribución-normal"><span class="header-section-number">5.5</span> La distribución normal</a>
  <ul class="collapse">
  <li><a href="#densidad-de-probabilidad" id="toc-densidad-de-probabilidad" class="nav-link" data-scroll-target="#densidad-de-probabilidad"><span class="header-section-number">5.5.1</span> Densidad de probabilidad</a></li>
  </ul></li>
  <li><a href="#otras-distribuciones-útiles" id="toc-otras-distribuciones-útiles" class="nav-link" data-scroll-target="#otras-distribuciones-útiles"><span class="header-section-number">5.6</span> Otras distribuciones útiles</a></li>
  <li><a href="#resumen-sobre-la-probabilidad" id="toc-resumen-sobre-la-probabilidad" class="nav-link" data-scroll-target="#resumen-sobre-la-probabilidad"><span class="header-section-number">5.7</span> Resumen sobre la probabilidad</a></li>
  <li><a href="#muestras-poblaciones-y-muestreo" id="toc-muestras-poblaciones-y-muestreo" class="nav-link" data-scroll-target="#muestras-poblaciones-y-muestreo"><span class="header-section-number">5.8</span> Muestras, poblaciones y muestreo</a>
  <ul class="collapse">
  <li><a href="#definir-una-población" id="toc-definir-una-población" class="nav-link" data-scroll-target="#definir-una-población"><span class="header-section-number">5.8.1</span> Definir una población</a></li>
  <li><a href="#muestras-aleatorias-simples" id="toc-muestras-aleatorias-simples" class="nav-link" data-scroll-target="#muestras-aleatorias-simples"><span class="header-section-number">5.8.2</span> Muestras aleatorias simples</a></li>
  <li><a href="#la-mayoría-de-las-muestras-no-son-aleatorias-simples" id="toc-la-mayoría-de-las-muestras-no-son-aleatorias-simples" class="nav-link" data-scroll-target="#la-mayoría-de-las-muestras-no-son-aleatorias-simples"><span class="header-section-number">5.8.3</span> La mayoría de las muestras no son aleatorias simples</a></li>
  <li><a href="#qué-tan-grave-es-no-tener-una-muestra-aleatoria-simple" id="toc-qué-tan-grave-es-no-tener-una-muestra-aleatoria-simple" class="nav-link" data-scroll-target="#qué-tan-grave-es-no-tener-una-muestra-aleatoria-simple"><span class="header-section-number">5.8.4</span> ¿Qué tan grave es no tener una muestra aleatoria simple?</a></li>
  <li><a href="#parámetros-poblacionales-y-estadísticas-muestrales" id="toc-parámetros-poblacionales-y-estadísticas-muestrales" class="nav-link" data-scroll-target="#parámetros-poblacionales-y-estadísticas-muestrales"><span class="header-section-number">5.8.5</span> Parámetros poblacionales y estadísticas muestrales</a></li>
  </ul></li>
  <li><a href="#la-ley-de-los-grandes-números" id="toc-la-ley-de-los-grandes-números" class="nav-link" data-scroll-target="#la-ley-de-los-grandes-números"><span class="header-section-number">5.9</span> La ley de los grandes números</a></li>
  <li><a href="#distribuciones-muestrales-y-el-teorema-central-del-límite" id="toc-distribuciones-muestrales-y-el-teorema-central-del-límite" class="nav-link" data-scroll-target="#distribuciones-muestrales-y-el-teorema-central-del-límite"><span class="header-section-number">5.10</span> Distribuciones muestrales y el teorema central del límite</a>
  <ul class="collapse">
  <li><a href="#distribución-muestral-de-las-medias-muestrales" id="toc-distribución-muestral-de-las-medias-muestrales" class="nav-link" data-scroll-target="#distribución-muestral-de-las-medias-muestrales"><span class="header-section-number">5.10.1</span> Distribución muestral de las medias muestrales</a></li>
  <li><a href="#viendo-las-partes" id="toc-viendo-las-partes" class="nav-link" data-scroll-target="#viendo-las-partes"><span class="header-section-number">5.10.2</span> Viendo las partes</a></li>
  <li><a href="#las-distribuciones-muestrales-existen-para-cualquier-estadístico-muestral" id="toc-las-distribuciones-muestrales-existen-para-cualquier-estadístico-muestral" class="nav-link" data-scroll-target="#las-distribuciones-muestrales-existen-para-cualquier-estadístico-muestral"><span class="header-section-number">5.10.3</span> ¡Las distribuciones muestrales existen para cualquier estadístico muestral!</a></li>
  <li><a href="#el-teorema-central-del-límite" id="toc-el-teorema-central-del-límite" class="nav-link" data-scroll-target="#el-teorema-central-del-límite"><span class="header-section-number">5.10.4</span> El teorema central del límite</a></li>
  </ul></li>
  <li><a href="#puntajes-z" id="toc-puntajes-z" class="nav-link" data-scroll-target="#puntajes-z"><span class="header-section-number">5.11</span> Puntajes z</a>
  <ul class="collapse">
  <li><a href="#la-idea-detrás-de-los-puntajes-z" id="toc-la-idea-detrás-de-los-puntajes-z" class="nav-link" data-scroll-target="#la-idea-detrás-de-los-puntajes-z"><span class="header-section-number">5.11.1</span> La idea detrás de los puntajes z</a></li>
  <li><a href="#cómo-calcular-puntajes-z" id="toc-cómo-calcular-puntajes-z" class="nav-link" data-scroll-target="#cómo-calcular-puntajes-z"><span class="header-section-number">5.11.2</span> Cómo calcular puntajes z</a></li>
  </ul></li>
  <li><a href="#estimación-de-parámetros-poblacionales" id="toc-estimación-de-parámetros-poblacionales" class="nav-link" data-scroll-target="#estimación-de-parámetros-poblacionales"><span class="header-section-number">5.12</span> Estimación de parámetros poblacionales</a>
  <ul class="collapse">
  <li><a href="#parámetros-poblacionales-concretos" id="toc-parámetros-poblacionales-concretos" class="nav-link" data-scroll-target="#parámetros-poblacionales-concretos"><span class="header-section-number">5.12.1</span> Parámetros poblacionales concretos</a></li>
  <li><a href="#parámetros-poblacionales-abstractos" id="toc-parámetros-poblacionales-abstractos" class="nav-link" data-scroll-target="#parámetros-poblacionales-abstractos"><span class="header-section-number">5.12.2</span> Parámetros poblacionales abstractos</a></li>
  <li><a href="#experimentos-y-parámetros-poblacionales" id="toc-experimentos-y-parámetros-poblacionales" class="nav-link" data-scroll-target="#experimentos-y-parámetros-poblacionales"><span class="header-section-number">5.12.3</span> Experimentos y parámetros poblacionales</a></li>
  <li><a href="#resumen-intermedio" id="toc-resumen-intermedio" class="nav-link" data-scroll-target="#resumen-intermedio"><span class="header-section-number">5.12.4</span> Resumen intermedio</a></li>
  <li><a href="#estimación-de-la-media-poblacional" id="toc-estimación-de-la-media-poblacional" class="nav-link" data-scroll-target="#estimación-de-la-media-poblacional"><span class="header-section-number">5.12.5</span> Estimación de la media poblacional</a></li>
  <li><a href="#estimación-del-desvío-estándar-poblacional" id="toc-estimación-del-desvío-estándar-poblacional" class="nav-link" data-scroll-target="#estimación-del-desvío-estándar-poblacional"><span class="header-section-number">5.12.6</span> Estimación del desvío estándar poblacional</a></li>
  </ul></li>
  <li><a href="#estimación-de-un-intervalo-de-confianza" id="toc-estimación-de-un-intervalo-de-confianza" class="nav-link" data-scroll-target="#estimación-de-un-intervalo-de-confianza"><span class="header-section-number">5.13</span> Estimación de un intervalo de confianza</a>
  <ul class="collapse">
  <li><a href="#un-pequeño-error-en-la-fórmula" id="toc-un-pequeño-error-en-la-fórmula" class="nav-link" data-scroll-target="#un-pequeño-error-en-la-fórmula"><span class="header-section-number">5.13.1</span> Un pequeño error en la fórmula</a></li>
  </ul></li>
  <li><a href="#resumen" id="toc-resumen" class="nav-link" data-scroll-target="#resumen"><span class="header-section-number">5.14</span> Resumen</a></li>
  <li><a href="#videos" id="toc-videos" class="nav-link" data-scroll-target="#videos"><span class="header-section-number">5.15</span> Videos</a>
  <ul class="collapse">
  <li><a href="#introducción-a-la-probabilidad" id="toc-introducción-a-la-probabilidad" class="nav-link" data-scroll-target="#introducción-a-la-probabilidad"><span class="header-section-number">5.15.1</span> Introducción a la probabilidad</a></li>
  <li><a href="#teorema-de-chebychev" id="toc-teorema-de-chebychev" class="nav-link" data-scroll-target="#teorema-de-chebychev"><span class="header-section-number">5.15.2</span> Teorema de Chebychev</a></li>
  <li><a href="#puntajes-z-1" id="toc-puntajes-z-1" class="nav-link" data-scroll-target="#puntajes-z-1"><span class="header-section-number">5.15.3</span> Puntajes Z</a></li>
  <li><a href="#distribución-normal-i" id="toc-distribución-normal-i" class="nav-link" data-scroll-target="#distribución-normal-i"><span class="header-section-number">5.15.4</span> Distribución normal I</a></li>
  <li><a href="#distribución-normal-ii" id="toc-distribución-normal-ii" class="nav-link" data-scroll-target="#distribución-normal-ii"><span class="header-section-number">5.15.5</span> Distribución normal II</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/almadana/libro_cuanti/edit/master/04-SamplesPopulations.qmd" class="toc-action">Editar esta página</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Probabilidad, muestreo y estimación</span></h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Autores/as</div>
    <div class="quarto-title-meta-contents">
             <p>Danielle J. Navarro </p>
             <p>Matthew J. C. Crump </p>
          </div>
  </div>
    
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="abstract-title">Chapter notes</div>
    Sections 4.1 &amp; 4.9 - Adapted text by Danielle Navarro Section 4.10 - 4.11 &amp; 4.13 - Mix of Matthew Crump &amp; Danielle Navarro Section 4.12 - 4.13 - Adapted text by Danielle Navarro
  </div>
</div>

</header>

<blockquote class="blockquote">
<p>He estudiado muchos idiomas —francés, español y un poco de italiano, pero nadie me dijo que la estadística era una lengua extranjera. —Charmaine J. Forde</p>
</blockquote>
<p>Hasta ahora en el libro, hablamos sobre algunas de las ideas clave en el diseño experimental, y comentamos un poco cómo podés resumir un conjunto de datos. Para muchas personas, eso es todo lo que hay en estadística: se trata de calcular promedios, juntar números, hacer gráficos y poner todo eso en un informe. Algo así como coleccionar estampillas, pero con números. Sin embargo, la estadística abarca mucho más que eso. De hecho, la estadística descriptiva es una de las partes más pequeñas —y menos potentes— de la estadística. La parte más grande y útil de la estadística es que nos da herramientas <strong>para hacer inferencias a partir de los datos</strong>.</p>
<p>Cuando empezás a pensar en la estadística en estos términos —que está ahí para ayudarnos a sacar conclusiones a partir de los datos—, empezás a ver ejemplos por todas partes. Por ejemplo, acá hay un pequeño extracto de un artículo del <em>Sydney Morning Herald</em> (30 de octubre de 2010):</p>
<blockquote class="blockquote">
<p>“Tengo un trabajo difícil”, dijo la Premier en respuesta a una encuesta que reveló que su gobierno es ahora la administración laborista menos popular de la historia de los sondeos, con una intención de voto primaria de apenas el 23 por ciento.</p>
</blockquote>
<p>Este tipo de afirmación es totalmente común en los diarios y en la vida cotidiana, pero pensemos por un momento qué implica. Una encuestadora hizo un sondeo —probablemente bastante grande porque pueden pagarlo—. No tengo ganas de buscar el informe original, así que imaginemos que llamaron a 1000 votantes de New South Wales al azar, y que 230 (23%) dijeron que pensaban votar al Partido Laborista Australiano. Para las elecciones federales de 2010, la Comisión Electoral Australiana informó que había 4.610.795 votantes registrados en New South Wales; así que las opiniones de los 4.609.795 votantes restantes (aproximadamente el 99,98%) <strong>no las conocemos</strong>. Incluso suponiendo que nadie le mintió a la encuestadora, lo único que podemos decir con 100% de certeza es que el voto real está entre 230/4.610.795 (aprox. 0,005%) y 4.610.025/4.610.795 (aprox. 99,83%). Entonces, ¿en qué se basa la encuestadora, el diario y la opinión pública para concluir que el voto al partido es aproximadamente del 23%?</p>
<p>La respuesta es bastante obvia: si llamo a 1000 personas al azar y 230 dicen que votarían a ese partido, parece muy poco probable que <strong>sean las únicas</strong> 230 personas en toda la población que lo harían. En otras palabras, asumimos que los datos recolectados por la encuestadora representan bastante bien a toda la población. Pero, ¿cuán representativos son? ¿Nos sorprendería descubrir que el verdadero apoyo al partido es en realidad del 24%? ¿Del 29%? ¿Del 37%? Acá es donde la intuición cotidiana empieza a fallar. A nadie le sorprendería un 24%, y a todo el mundo le sorprendería un 37%, pero no es tan fácil decidir si un 29% sería plausible. Necesitamos herramientas más potentes que simplemente mirar los números y adivinar.</p>
<p>La <strong>estadística inferencial</strong> proporciona las herramientas necesarias para responder ese tipo de preguntas. Y como ese tipo de preguntas están en el corazón del trabajo científico, ocupan la mayor parte de cualquier curso introductorio de estadística o métodos de investigación. Y como ese tipo de preguntas están en el corazón del trabajo científico, ocupan la mayor parte de cualquier curso introductorio de estadística o métodos de investigación. Sin embargo, nuestras herramientas para hacer inferencias estadísticas están: 1. construidas sobre la base de la <strong>teoría de la probabilidad</strong>, y 2. requieren entender cómo se comportan las muestras cuando se extraen de distribuciones (definidas por la teoría de la probabilidad…). Así que este capítulo tiene dos partes principales: una breve introducción a la teoría de la probabilidad, y una introducción al muestreo a partir de distribuciones.</p>
<section id="en-qué-se-diferencian-la-probabilidad-y-la-estadística" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="en-qué-se-diferencian-la-probabilidad-y-la-estadística"><span class="header-section-number">5.1</span> ¿En qué se diferencian la probabilidad y la estadística?</h2>
<p>Antes de empezar a hablar de teoría de la probabilidad, conviene dedicar un momento a pensar en la relación entre probabilidad y estadística. Las dos disciplinas están muy relacionadas, pero no son lo mismo. La teoría de la probabilidad es “la doctrina del azar”. Es una rama de las matemáticas que te dice con qué frecuencia ocurren distintos tipos de eventos. Por ejemplo, todas estas preguntas pueden responderse usando teoría de la probabilidad:</p>
<ul>
<li><p>¿Cuál es la probabilidad de que una moneda salga cara 10 veces seguidas?</p></li>
<li><p>Si tiro dos dados de seis caras, ¿qué tan probable es que salgan dos seises?</p></li>
<li><p>¿Qué probabilidad hay de que cinco cartas extraídas al azar de un mazo bien mezclado sean todas corazones?</p></li>
<li><p>¿Qué chance tengo de ganar la lotería?</p></li>
</ul>
<p>Fijate que todas estas preguntas tienen algo en común. En cada caso la “verdad del mundo” es conocida, y mi pregunta se relaciona con “qué clase de eventos” van a ocurrir. En la primera pregunta, <strong>sabemos</strong> que la moneda es justa, así que hay un 50% de probabilidad de que cualquier lanzamiento individual salga cara. En la segunda, <strong>sabemos</strong> que la chance de sacar un 6 con un dado es 1 en 6. En la tercera, <strong>sabemos</strong> que el mazo está bien mezclado. Y en la cuarta, <strong>sabemos</strong> que la lotería sigue reglas específicas. Ya te hacés una idea. Lo importante es que las preguntas de probabilidad parten de un <strong>modelo</strong> conocido del mundo, y usamos ese modelo para hacer algunos cálculos.</p>
<p>El modelo subyacente puede ser muy simple. Por ejemplo, en el caso de la moneda, podemos escribir el modelo así: <span class="math inline">\(P(\text{cara}) = 0.5\)</span> que se lee: “la probabilidad de que salga cara es 0.5”.</p>
<p>Como veremos más adelante, así como los porcentajes van de 0% a 100%, las probabilidades son simplemente números que van de 0 a 1. Cuando usamos este modelo para responder la primera pregunta, en realidad no sabemos exactamente qué va a pasar. Tal vez salgan 10 caras, como plantea la pregunta. Pero también podrían salir 3 caras. Eso es lo importante: en la teoría de la probabilidad, el <strong>modelo</strong> es conocido, pero los <strong>datos</strong> no lo son.</p>
<p>Eso es la probabilidad. ¿Y la estadística? Las preguntas estadísticas <strong>funcionan al revés</strong>. En estadística, <strong>no sabemos cómo es el mundo en realidad</strong>. Lo único que tenemos son datos, y a partir de ellos queremos <strong>aprender</strong> la verdad sobre el mundo. Las preguntas estadísticas suelen ser más del tipo:</p>
<ul>
<li><p>Si mi amiga lanza una moneda 10 veces y sale cara todas las veces, ¿me está haciendo trampa?</p></li>
<li><p>Si saco cinco cartas y todas son corazones, ¿qué tan probable es que el mazo estuviera mezclado?</p></li>
<li><p>Si la pareja del comisario de la lotería gana la lotería, ¿qué tan probable es que esté arreglada?</p></li>
</ul>
<p>Esta vez, lo único que tenemos son los datos. Lo que <strong>sé</strong> es que vi a mi amiga lanzar la moneda 10 veces y salió cara todas las veces. Y lo que quiero <em>inferir</em> es si debería concluir que lo que acabo de ver fue realmente una moneda justa siendo lanzada 10 veces seguidas, o si debería sospechar que mi amiga me está haciendo una trampa. Los datos que tengo se ven así:</p>
<pre><code>H H H H H H H H H H</code></pre>
<p>y lo que estoy intentando hacer es decidir en cuál “modelo del mundo” debería confiar. Si la moneda es justa, entonces el modelo que debería adoptar es uno en el que la probabilidad de que salga cara es 0.5; es decir, <span class="math inline">\(P(\text{cara}) = 0.5\)</span> Si la moneda no es justa, entonces debería concluir que la probabilidad de que salga cara <strong>no</strong> es 0.5, lo que escribiríamos como <span class="math inline">\(P(\text{cara}) \neq 0.5\)</span>. En otras palabras, el problema de la inferencia estadística consiste en darme cuenta cuál de estos modelos de probabilidad es el correcto. Está claro que la pregunta estadística no es la misma que la pregunta de probabilidad, pero están profundamente relacionadas. Por eso, una buena introducción a la teoría estadística comienza con una discusión sobre qué es la probabilidad y cómo funciona.</p>
</section>
<section id="qué-significa-probabilidad" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="qué-significa-probabilidad"><span class="header-section-number">5.2</span> ¿Qué significa probabilidad?</h2>
<p>Empecemos con la primera de estas preguntas: ¿qué es la “probabilidad”? Puede parecerte sorprendente, pero aunque los estadísticos y matemáticos (en general) están de acuerdo sobre cuáles son las <strong>reglas</strong> de la probabilidad, hay mucho menos consenso sobre qué <strong>significa</strong> realmente la palabra. Suena raro, porque todos usamos palabras como “chance”, “posibilidad” y “probable” sin problema, y no parece una pregunta difícil de responder. Si tuvieras que explicarle a una persona de cinco años qué es la probabilidad, probablemente te las arreglarías bastante bien. Pero si alguna vez viviste esa situación en la vida real, tal vez te fuiste con la sensación de que no lo explicaste tan bien, y que —como pasa con muchos conceptos cotidianos— no sabés <strong>realmente</strong> de qué se trata.</p>
<p>Así que voy a intentarlo. Supongamos que quiero apostar en un partido de fútbol entre dos equipos de robots, <strong>Arduino Arsenal</strong> y <strong>C Milan</strong>. Después de pensarlo, decido que hay una probabilidad del 80% de que <strong>Arduino Arsenal</strong> gane. ¿Qué quiero decir con eso? Acá hay tres posibles interpretaciones:</p>
<ul>
<li><p>Son equipos robot, así que puedo hacerlos jugar muchas veces. Si lo hiciera, <strong>Arduino Arsenal</strong> ganaría 8 de cada 10 partidos, en promedio.</p></li>
<li><p>Para cualquier partido en particular, solo estaría de acuerdo en que apostar es “justo” si una apuesta de $1 a favor de <strong>C Milan</strong> paga $5 (es decir, recupero mi $1 más $4 de ganancia), al igual que lo sería una apuesta de $4 a favor de <strong>Arduino Arsenal</strong> (recupero mis $4 más $1 de ganancia).</p></li>
<li><p>Mi “creencia” o “confianza” subjetiva en que gana <strong>Arduino Arsenal</strong> es cuatro veces más fuerte que la que tengo en que gane <strong>C Milan</strong>.</p></li>
</ul>
<p>Todas estas opciones parecen razonables. Sin embargo, no son idénticas, y no todos los estadísticos estarían de acuerdo con todas. La razón es que existen diferentes ideologías estadísticas (¡sí, en serio!), y dependiendo de cuál suscribas, podrías decir que algunas de esas afirmaciones no tienen sentido o son irrelevantes. En esta sección, voy a introducir brevemente los dos enfoques principales que existen en la literatura. No son los únicos, pero sí son los más importantes.</p>
<section id="la-visión-frecuentista" class="level3" data-number="5.2.1">
<h3 data-number="5.2.1" class="anchored" data-anchor-id="la-visión-frecuentista"><span class="header-section-number">5.2.1</span> La visión frecuentista</h3>
<p>El primero de los dos enfoques principales, y el más dominante en estadística, se conoce como la <strong>visión frecuentista</strong>, que define la probabilidad como una <strong>frecuencia a largo plazo</strong>. Supongamos que empezamos a lanzar una moneda justa, una y otra vez. Por definición, es una moneda en la que <span class="math inline">\(P(H) = 0.5\)</span>. ¿Qué podríamos observar? Una posibilidad es que los primeros 20 lanzamientos se vean así:</p>
<pre><code>T, H, H, H, H, T, T, H, H, H, H, T, H, H, T, T, T, T, T, H</code></pre>
<p>En este caso, 11 de los 20 lanzamientos (55%) salieron cara. Ahora supongamos que fui llevando la cuenta del número de caras (que voy a llamar $ N_H $) en los primeros $ N $ lanzamientos, y que cada vez calculo la proporción de caras $ N_H / N $. Esto es lo que obtendría (¡sí, de verdad lancé monedas para obtener esto!):</p>
<table class="table">
<colgroup>
<col style="width: 32%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
</colgroup>
<thead>
<tr class="header">
<th>número de lanzamientos</th>
<th style="text-align: center;">1</th>
<th style="text-align: center;">2</th>
<th style="text-align: center;">3</th>
<th style="text-align: center;">4</th>
<th style="text-align: center;">5</th>
<th style="text-align: center;">6</th>
<th style="text-align: center;">7</th>
<th style="text-align: center;">8</th>
<th style="text-align: center;">9</th>
<th style="text-align: center;">10</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>número de caras</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">7</td>
</tr>
<tr class="even">
<td>proporción</td>
<td style="text-align: center;">.00</td>
<td style="text-align: center;">.50</td>
<td style="text-align: center;">.67</td>
<td style="text-align: center;">.75</td>
<td style="text-align: center;">.80</td>
<td style="text-align: center;">.67</td>
<td style="text-align: center;">.57</td>
<td style="text-align: center;">.63</td>
<td style="text-align: center;">.67</td>
<td style="text-align: center;">.70</td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 32%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
</colgroup>
<thead>
<tr class="header">
<th>número de lanzamientos</th>
<th style="text-align: center;">11</th>
<th style="text-align: center;">12</th>
<th style="text-align: center;">13</th>
<th style="text-align: center;">14</th>
<th style="text-align: center;">15</th>
<th style="text-align: center;">16</th>
<th style="text-align: center;">17</th>
<th style="text-align: center;">18</th>
<th style="text-align: center;">19</th>
<th style="text-align: center;">20</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>número de caras</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">11</td>
</tr>
<tr class="even">
<td>proporción</td>
<td style="text-align: center;">.73</td>
<td style="text-align: center;">.67</td>
<td style="text-align: center;">.69</td>
<td style="text-align: center;">.71</td>
<td style="text-align: center;">.67</td>
<td style="text-align: center;">.63</td>
<td style="text-align: center;">.59</td>
<td style="text-align: center;">.56</td>
<td style="text-align: center;">.53</td>
<td style="text-align: center;">.55</td>
</tr>
</tbody>
</table>
<p>Fijate que al principio de la secuencia, la <strong>proporción</strong> de caras fluctúa bastante, empezando en .00 y subiendo hasta .80. Más adelante, da la impresión de que se estabiliza, con valores que se acercan cada vez más al valor “correcto” de 0.50. Esta es la definición frecuentista de probabilidad en pocas palabras: lanzá una moneda justa muchas veces, y a medida que $ N $ crece (se acerca al infinito, denotado $ N $), la proporción de caras converge a 50%. Hay algunas sutilezas técnicas que le importan a los matemáticos, pero en términos cualitativos, así es como los frecuentistas definen la probabilidad. Por supuesto, no tengo un número infinito de monedas, ni la paciencia infinita para lanzarlas eternamente. Pero sí tengo una computadora, y las computadoras son excelentes para tareas repetitivas. Así que le pedí a la computadora que simulara lanzar una moneda 1000 veces, y luego grafiqué lo que pasa con la proporción $ N_H / N $ a medida que $ N $ aumenta. En realidad, lo hice cuatro veces, solo para asegurarme de que no fuera casualidad. Los resultados se muestran en la <a href="#fig-4FreqProb">Figura&nbsp;<span>5.1</span></a>. Como podés ver, la <strong>proporción de caras observadas</strong> eventualmente deja de fluctuar, y se estabiliza. Cuando eso ocurre, el número al que se estabiliza es la verdadera probabilidad de cara.</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/fig-4FreqProb_b1ced871147202d5605a477c7149df5d">
<div class="cell-output-display">
<div id="fig-4FreqProb" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="imgs/navarro_img/probability/frequentistProb_es.png" class="img-fluid figure-img" width="3600"></p>
<figcaption class="figure-caption">Figura&nbsp;5.1: Ilustración de cómo funciona la probabilidad frecuentista. Si lanzás una moneda justa muchas veces, la proporción de caras observadas se estabiliza y converge hacia la probabilidad verdadera de 0.5. Cada panel muestra un experimento simulado distinto: en cada caso, se simula lanzar una moneda 1000 veces y se lleva un registro de la proporción de caras acumuladas. Aunque ninguna secuencia termina exactamente en 0.5, si el experimento se extendiera indefinidamente, lo haría.</figcaption>
</figure>
</div>
</div>
</div>
<p>La definición frecuentista de probabilidad tiene algunas características deseables. Primero, es objetiva: la probabilidad de un evento está <strong>necesariamente</strong> anclada en el mundo. La única forma en que las afirmaciones probabilísticas tienen sentido es si se refieren a (una secuencia de) eventos que ocurren en el universo físico. Segundo, no es ambigua: dos personas que observan la misma secuencia de eventos y tratan de calcular la probabilidad de un evento, necesariamente deben llegar a la misma respuesta.</p>
<p>Sin embargo, también tiene características indeseables. Las secuencias infinitas no existen en el mundo físico. Supongamos que agarrás una moneda de tu bolsillo y empezás a lanzarla. Cada vez que cae, impacta contra el suelo. Cada impacto desgasta un poco la moneda; eventualmente, la moneda se va a destruir. Entonces, uno podría preguntarse si realmente tiene sentido fingir que una “secuencia infinita” de lanzamientos de moneda es un concepto significativo, o incluso objetivo. No podemos decir que una “secuencia infinita” de eventos sea algo real en el universo físico, porque el universo físico no permite nada infinito.</p>
<p>Más seriamente, la definición frecuentista tiene un alcance muy limitado. Hay un montón de cosas a las que les asignamos probabilidades en el lenguaje cotidiano, pero que no pueden (ni siquiera en teoría) ser representadas como una secuencia hipotética de eventos. Por ejemplo, si una meteoróloga aparece en la tele y dice: “la probabilidad de que llueva en Adelaida el 2 de noviembre de 2048 es del 60%”, las personas aceptamos esa afirmación sin problemas. Pero no está claro cómo definir eso en términos frecuentistas. Solo hay una ciudad de Adelaida, y solo hay un 2 de noviembre de 2048. No hay ninguna secuencia infinita de eventos acá: es algo que ocurre una sola vez. Desde la perspectiva frecuentista, <strong>está prohibido</strong> hacer afirmaciones de probabilidad sobre un evento único. Para un frecuentista, mañana o va a llover o no va a llover; no hay ninguna “probabilidad” asociada a un evento no repetible. Ahora bien, hay que decir que los frecuentistas tienen algunos trucos muy ingeniosos para sortear esta limitación. Una posibilidad es que lo que quiso decir la meteoróloga sea algo así como: “Hay una categoría de días para los que yo predigo un 60% de chance de lluvia; si miramos sólo esos días en los que hice esa predicción, entonces en el 60% de ellos efectivamente llueve”. Es una forma rara de pensarlo y contraria a la intuición, pero sí: los frecuentistas hacen esto a veces.</p>
</section>
<section id="la-visión-bayesiana" class="level3" data-number="5.2.2">
<h3 data-number="5.2.2" class="anchored" data-anchor-id="la-visión-bayesiana"><span class="header-section-number">5.2.2</span> La visión bayesiana</h3>
<p>La <strong>visión bayesiana</strong> de la probabilidad también se llama la visión subjetivista, y es una posición minoritaria entre los estadísticos, pero que ha ido ganando terreno de forma sostenida en las últimas décadas. Hay muchas variantes del bayesianismo, lo que dificulta definir exactamente cuál es “la” visión bayesiana. La forma más común de pensar en la probabilidad subjetiva es definir la probabilidad de un evento como el <strong>grado de creencia</strong> que una persona (o agente racional e inteligente) asigna a la verdad de ese evento. Desde esta perspectiva, las probabilidades no existen en el mundo, sino que viven en los pensamientos y suposiciones de las personas (o seres inteligentes). Sin embargo, para que este enfoque funcione, necesitamos alguna forma de operacionalizar ese “grado de creencia”. Una manera de hacerlo es formalizarlo en términos de “apuestas racionales”, aunque existen otras formas. Supongamos que creo que hay un 60% de probabilidad de que mañana llueva. Si alguien me ofrece una apuesta que dice: si llueve, ganás $5; si no llueve, perdés $5, desde mi perspectiva es una buena apuesta. En cambio, si creo que hay solo un 40% de probabilidad de lluvia, entonces esa misma apuesta sería una mala idea. Así, podemos operacionalizar el concepto de “probabilidad subjetiva” en función de qué apuestas estoy dispuesto a aceptar.</p>
<p>¿Cuáles son las ventajas y desventajas de este enfoque bayesiano? La principal ventaja es que permite asignar probabilidades a cualquier evento que queramos. No es necesario que el evento sea repetible. La principal desventaja (para muchas personas) es que no podemos ser completamente objetivos: al asignar una probabilidad, es necesario especificar una entidad que posea el grado de creencia pertinente. Esa entidad puede ser una persona, un extraterrestre, un robot, o incluso un estadístico, pero tiene que haber un agente inteligente que tenga creencias. Para muchos esto resulta incómodo: hace que la probabilidad parezca arbitraria. Mientras que el enfoque bayesiano exige que el agente en cuestión sea racional (es decir, que respete las reglas de la probabilidad), permite que cada quien tenga sus propias creencias; yo puedo creer que la moneda está equilibrada y vos no, y aun así ambos ser racionales. La visión frecuentista no permite que dos observadores asignen probabilidades distintas al mismo evento: si eso ocurre, al menos uno de los dos está equivocado. La perspectiva bayesiana no impone esa restricción. Dos personas con conocimientos previos diferentes pueden, de forma legítima, tener creencias distintas sobre un mismo evento. En resumen, mientras que la visión frecuentista a veces se considera demasiado restrictiva (prohíbe asignar probabilidades a muchas cosas que nos interesa evaluar), la visión bayesiana a veces se percibe como demasiado amplia (permite demasiadas diferencias entre observadores).</p>
</section>
<section id="cuál-es-la-diferencia-y-quién-tiene-razón" class="level3" data-number="5.2.3">
<h3 data-number="5.2.3" class="anchored" data-anchor-id="cuál-es-la-diferencia-y-quién-tiene-razón"><span class="header-section-number">5.2.3</span> ¿Cuál es la diferencia? ¿Y quién tiene razón?</h3>
<p>Ahora que viste cada una de estas dos perspectivas por separado, conviene asegurarse de que podés compararlas. Volvé al partido hipotético de fútbol robot al comienzo de la sección. ¿Qué pensás que dirían un frecuentista y un bayesiano sobre estas tres afirmaciones? ¿Cuál de ellas consideraría un frecuentista como la definición correcta de probabilidad? ¿Y cuál aceptaría un bayesiano? ¿Algunas de estas afirmaciones carecerían de sentido para un frecuentista o para un bayesiano? Si entendiste bien las dos perspectivas, deberías tener una idea de cómo responder esas preguntas.</p>
<p>Bien, suponiendo que entendiste la diferencia, tal vez te estés preguntando cuál de ellas es la <strong>correcta</strong>. Sinceramente, no sé si hay una respuesta correcta. Hasta donde puedo decir, no hay nada matemáticamente incorrecto en la forma en que los frecuentistas piensan las secuencias de eventos, y tampoco hay nada matemáticamente incorrecto en la forma en que los bayesianos definen las creencias de un agente racional. De hecho, cuando uno se mete en los detalles, los bayesianos y los frecuentistas en realidad están de acuerdo en muchas cosas. Muchos métodos frecuentistas llevan a decisiones que los bayesianos aceptarían como consistentes con un agente racional. Y muchos métodos bayesianos tienen muy buenas propiedades frecuentistas.</p>
<p>En general, yo soy pragmática, así que uso cualquier método estadístico en el que confíe. Resulta que eso me hace preferir los métodos bayesianos, por razones que voy a explicar hacia el final del libro, pero no estoy fundamentalmente en contra de los métodos frecuentistas. No todos son tan relajados. Por ejemplo, pensemos en Sir Ronald Fisher, una de las figuras más importantes de la estadística del siglo XX y un ferviente opositor de todo lo bayesiano, cuyo artículo sobre los fundamentos matemáticos de la estadística se refiere a la probabilidad bayesiana como “una selva impenetrable [que] detiene el progreso hacia la precisión de los conceptos estadísticos” <span class="citation" data-cites="Fisher1922b">Fisher (<a href="references.html#ref-Fisher1922b" role="doc-biblioref">1922, 311</a>)</span>. O el psicólogo Paul Meehl, quien sugiere que confiar en métodos frecuentistas podría convertirte en “un libertino intelectual potente pero estéril, que deja a su paso alegre una larga estela de doncellas seducidas, pero ninguna descendencia científica viable” <span class="citation" data-cites="Meehl1967">Meehl (<a href="references.html#ref-Meehl1967" role="doc-biblioref">1967, 114</a>)</span>. La historia de la estadística, como podés ver, no carece de entretenimiento.</p>
</section>
</section>
<section id="teoría-básica-de-la-probabilidad" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="teoría-básica-de-la-probabilidad"><span class="header-section-number">5.3</span> Teoría básica de la probabilidad</h2>
<p>Más allá de las discusiones ideológicas entre bayesianos y frecuentistas, resulta que en general hay bastante consenso sobre las reglas que deben seguir las probabilidades. Hay muchas maneras de llegar a estas reglas. El enfoque más común se basa en el trabajo de Andrey Kolmogorov, uno de los grandes matemáticos soviéticos del siglo XX. No voy a entrar en demasiados detalles, pero voy a intentar darte una idea general de cómo funciona. Y para hacerlo, voy a tener que hablar de mis pantalones.</p>
<section id="introducción-a-las-distribuciones-de-probabilidad" class="level3" data-number="5.3.1">
<h3 data-number="5.3.1" class="anchored" data-anchor-id="introducción-a-las-distribuciones-de-probabilidad"><span class="header-section-number">5.3.1</span> Introducción a las distribuciones de probabilidad</h3>
<p>Una de las verdades perturbadoras de mi vida es que solo tengo cinco pares de pantalones: tres jeans, la parte de abajo de un traje, y un pantalón deportivo. Más triste aún: les puse nombre. Los llamo $ X_1 $, $ X_2 $, $ X_3 $, $ X_4 $ y $ X_5 $. De verdad lo hago: por eso me dicen “Señor Imaginativo”. Cada día, elijo exactamente un par de pantalones para usar. Ni yo soy tan tonto como para tratar de usar dos al mismo tiempo, y gracias a años de entrenamiento ya no salgo de casa sin pantalones. Si quisiera describir esta situación usando el lenguaje de la teoría de la probabilidad, diría que cada par de pantalones (es decir, cada $ X $) es un <em>evento elemental</em>. La característica clave de los eventos elementales es que cada vez que hacemos una observación (por ejemplo, cada vez que me pongo un par de pantalones), el resultado será uno y solo uno de esos eventos. Como dije, hoy en día siempre uso exactamente un par, así que mis pantalones cumplen con esa condición. De forma similar, al conjunto de todos los posibles eventos se lo llama <em>espacio muestral</em>. Es verdad que algunas personas lo llamarían “guardarropa”, pero eso es porque se niegan a pensar en mis pantalones desde una perspectiva probabilística. Triste.</p>
<p>Bien, ahora que tenemos un espacio muestral (un guardarropa), formado por varios eventos elementales (pantalones), lo que queremos hacer es asignar una <em>probabilidad</em> a cada uno de esos eventos. Para un evento $ X $, la probabilidad de ese evento $ P(X) $ es un número entre 0 y 1. Cuanto mayor es el valor de $ P(X) $, más probable es que ocurra ese evento. Por ejemplo: - Si $ P(X) = 0 $, significa que el evento $ X $ es <strong>imposible</strong> (nunca uso ese pantalón). - Si $ P(X) = 1 $, significa que el evento $ X $ es <strong>seguro</strong> (siempre uso ese pantalón). - Valores de probabilidad intermedios significan que a veces uso ese pantalón. Por ejemplo, si $ P(X) = 0.5 $, significa que uso ese pantalón la mitad del tiempo.</p>
<p>A esta altura, ya casi terminamos. Lo último que necesitamos reconocer es que “algo siempre ocurre”. Cada vez que me pongo pantalones, efectivamente termino con un par puesto (una locura, ¿no?). Esta afirmación algo trillada quiere decir, en términos probabilísticos, que las probabilidades de todos los eventos elementales deben sumar 1. Esto se conoce como la <em>ley de probabilidad total</em>, aunque a nadie le importe demasiado. Más importante, si se cumplen estos requisitos, lo que tenemos es una <em>distribución de probabilidad</em>. Por ejemplo, esta es una distribución de probabilidad</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: left;">¿Qué pantalón?</th>
<th style="text-align: center;">Etiqueta</th>
<th style="text-align: center;">Probabilidad</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Jean azul</td>
<td style="text-align: center;">$ X_1 $</td>
<td style="text-align: center;">$ P(X_1) = 0.5 $</td>
</tr>
<tr class="even">
<td style="text-align: left;">Jean gris</td>
<td style="text-align: center;">$ X_2 $</td>
<td style="text-align: center;">$ P(X_2) = 0.3 $</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Jean negro</td>
<td style="text-align: center;">$ X_3 $</td>
<td style="text-align: center;">$ P(X_3) = 0.1 $</td>
</tr>
<tr class="even">
<td style="text-align: left;">Pantalón de traje</td>
<td style="text-align: center;">$ X_4 $</td>
<td style="text-align: center;">$ P(X_4) = 0 $</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Pantalón deportivo</td>
<td style="text-align: center;">$ X_5 $</td>
<td style="text-align: center;">$ P(X_5) = 0.1 $</td>
</tr>
</tbody>
</table>
<p>Cada uno de estos eventos tiene una probabilidad que está entre 0 y 1, y si sumamos todas las probabilidades, el total es 1. Genial. Incluso podemos hacer un lindo gráfico de barras para visualizar esta distribución, como se muestra en la <a href="#fig-4pantsprob">Figura&nbsp;<span>5.2</span></a>. Y en este punto, todos logramos algo. Vos aprendiste qué es una distribución de probabilidad, y yo por fin encontré la forma de hacer un gráfico que trata exclusivamente sobre mis pantalones. ¡Ganamos todos!</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/fig-4pantsprob_0fbe468df89628a519123cc24abdf6e8">
<div class="cell-output-display">
<div id="fig-4pantsprob" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="imgs/navarro_img/probability/pantsDistribution_es.png" class="img-fluid figure-img" width="2400"></p>
<figcaption class="figure-caption">Figura&nbsp;5.2: Representación visual de la distribución de probabilidad de los pantalones. Hay cinco eventos elementales, que corresponden a los cinco pares de pantalones que tengo. Cada evento tiene alguna probabilidad de ocurrir: ese valor es un número entre 0 y 1. La suma de estas probabilidades es igual a 1.</figcaption>
</figure>
</div>
</div>
</div>
<p>La única otra cosa que necesito señalar es que la teoría de la probabilidad también te permite hablar de <em>eventos no elementales</em>, además de los elementales. La forma más fácil de ilustrar esto es con un ejemplo. En el caso de los pantalones, es perfectamente válido referirse a la probabilidad de que use jeans. En este escenario, decimos que el evento “Dan usa jeans” ocurre si el evento elemental que ocurrió fue uno de los apropiados; en este caso, “jean azul”, “jean negro” o “jean gris”. En términos matemáticos, definimos el evento “jeans” $ E $ como el conjunto de eventos elementales $ (X_1, X_2, X_3) $. Si ocurre cualquiera de esos eventos, entonces se dice que ocurrió $ E $. Una vez definida así la $ E $, es muy fácil calcular la probabilidad $ P(E) $: simplemente sumamos todo. En este caso:</p>
<p><span class="math display">\[
P(E) = P(X_1) + P(X_2) + P(X_3)
\]</span></p>
<p>Y como las probabilidades de jean azul, gris y negro son 0.5, 0.3 y 0.1 respectivamente, la probabilidad de que use jeans es igual a 0.9.</p>
<p>A esta altura tal vez estés pensando que todo esto es increíblemente obvio y simple, y tenés razón. Lo único que hicimos fue envolver algunas intuiciones de sentido común con un poco de matemática básica. Sin embargo, a partir de estos comienzos simples se pueden construir herramientas matemáticas extremadamente poderosas. Definitivamente no voy a entrar en esos detalles en este libro, pero lo que sí voy a hacer es listar algunas otras reglas que las probabilidades deben cumplir. Estas reglas se pueden derivar de los supuestos básicos que acabamos de ver, pero como no las vamos a usar directamente en este libro, no me voy a detener en eso.</p>
<table class="table">
<caption>Algunas reglas básicas que deben cumplir las probabilidades. No necesitás conocerlas para entender los análisis que vamos a ver más adelante en el libro, pero son importantes si querés entender la teoría de la probabilidad con más profundidad.</caption>
<thead>
<tr class="header">
<th>Evento</th>
<th>Notación</th>
<th>=</th>
<th>Regla</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>no <span class="math inline">\(A\)</span></td>
<td><span class="math inline">\(P(\neg A)\)</span></td>
<td>=</td>
<td><span class="math inline">\(1 - P(A)\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(A\)</span> o <span class="math inline">\(B\)</span></td>
<td><span class="math inline">\(P(A \cup B)\)</span></td>
<td>=</td>
<td><span class="math inline">\(P(A) + P(B) - P(A \cap B)\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(A\)</span> y <span class="math inline">\(B\)</span></td>
<td><span class="math inline">\(P(A \cap B)\)</span></td>
<td>=</td>
<td><span class="math inline">\(P(A|B) \cdot P(B)\)</span></td>
</tr>
</tbody>
</table>
<p>Ahora que tenemos la capacidad de “definir” eventos no elementales en términos de eventos elementales, en realidad podemos usar eso para construir (o, si querés sonar matemáticamente refinado, “derivar”) algunas de las otras reglas de probabilidad. Estas reglas están listadas arriba, y aunque estoy bastante seguro de que muy pocos lectores realmente están interesados en cómo se construyen, te las voy a mostrar igual: aunque sea aburrido y probablemente nunca les encuentres mucho uso práctico, si lo leés un par de veces y tratás de entender cómo funciona, vas a ver que la probabilidad deja de parecer tan misteriosa, y con suerte te va a intimidar menos. Así que ahí vamos. Primero, para construir las reglas voy a necesitar un espacio muestral $ X $ compuesto por un conjunto de eventos elementales $ x $, y dos eventos no elementales que voy a llamar $ A $ y $ B $. Supongamos que:</p>
<p><span class="math display">\[
\begin{array}{rcl}
X &amp;=&amp; (x_1, x_2, x_3, x_4, x_5) \\
A &amp;=&amp; (x_1, x_2, x_3) \\
B &amp;=&amp; (x_3, x_4)
\end{array}
\]</span></p>
<p>Para hacerlo más concreto, supongamos que todavía estamos hablando de la distribución de pantalones. Si es así, $ A $ correspondería al evento “jeans”, y $ B $ al evento “negro”:</p>
<p><span class="math display">\[
\begin{array}{rcl}
\text{“jeans”} &amp;=&amp; (\text{“jean azul”}, \text{“jean gris”}, \text{“jean negro”}) \\
\text{“negro”} &amp;=&amp; (\text{“jean negro”}, \text{“traje negro”})
\end{array}
\]</span></p>
<p>Ahora podemos empezar a comprobar las reglas que figuran en la tabla.</p>
<p>En la primera línea, la tabla dice que: $ P(A) = 1 - P(A)$ y lo que <strong>significa</strong> esto es que la probabilidad de “no $ A $” es igual a 1 menos la probabilidad de $ A $. Con un poco de reflexión (y un ejemplo tedioso) se vuelve evidente por qué esto tiene que ser verdad. Si $ A $ corresponde al evento de que me pongo jeans (es decir, que ocurre alguno de los eventos $ x_1 $, $ x_2 $ o $ x_3 $), entonces la única definición razonable de “no $ A $” (que se denota matemáticamente como $ A $) es decir que $ A $ consiste en <strong>todos</strong> los eventos elementales que no pertenecen a $ A $. En el caso de los pantalones, eso significa que: <span class="math display">\[ \neg A = (x_4, x_5) \]</span> o, dicho en español: “no jeans” incluye todos los pantalones que no son jeans (es decir, el pantalón de traje negro y el pantalón deportivo azul). Por lo tanto, cada uno de los eventos elementales pertenece o bien a $ A $, o bien a $ A $, pero no a ambos. Bien, entonces reorganicemos lo anterior: <span class="math display">\[P(\neg A) + P(A) = 1\]</span> que no es más que una forma matemática de decir: o uso jeans, o no uso jeans; la probabilidad de “no jeans” más la probabilidad de “jeans” es igual a 1.</p>
<p>Matemáticamente:</p>
<p><span class="math display">\[
\begin{array}{rcl}
P(\neg A) &amp;=&amp; P(x_4) + P(x_5) \\
P(A) &amp;=&amp; P(x_1) + P(x_2) + P(x_3)
\end{array}
\]</span></p>
<p>así que:</p>
<p><span class="math display">\[
\begin{array}{rcl}
P(\neg A) + P(A) &amp;=&amp; P(x_1) + P(x_2) + P(x_3) + P(x_4) + P(x_5) \\
&amp;=&amp; \sum_{x \in X} P(x) \\
&amp;=&amp; 1
\end{array}
\]</span> Excelente. Todo parece funcionar.</p>
<p>“Guau”, te escucho decir. “Todo esto para decirme lo increíblemente obvio”. Y tenés razón: esto <strong>es</strong> increíblemente obvio. El <strong>propósito</strong> de la teoría de la probabilidad es formalizar y matematizar unas pocas intuiciones de sentido común. Así que sigamos un poco más con esta línea de razonamiento. En la sección anterior definí un evento correspondiente a <strong>no</strong> A, que denoté como $ A <span class="math inline">\(. Ahora vamos a definir dos nuevos eventos que corresponden a conceptos cotidianos importantes: **\)</span> A $ y $ B <span class="math inline">\(**, y **\)</span> A $ o $ B $**. Específicamente:</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: left;">Afirmación en español</th>
<th style="text-align: center;">Notación matemática</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">“$ A $ y $ B $” ocurren ambos</td>
<td style="text-align: center;">$ A B $</td>
</tr>
<tr class="even">
<td style="text-align: left;">ocurre al menos uno: “$ A $ o $ B $”</td>
<td style="text-align: center;">$ A B $</td>
</tr>
</tbody>
</table>
<p>Ya que $ A $ y $ B $ están definidos en términos de nuestros eventos elementales (los $ x $s), necesitamos describir también $ A B $ y $ A B $ en términos de nuestros eventos elementales. ¿Podemos hacerlo? ¡Sí que podemos! La única forma en que ocurran ambos eventos, $ A $ y $ B $, es que el evento elemental observado pertenezca tanto a $ A $ como a $ B <span class="math inline">\(. Así que "\)</span>A B$” incluye solamente aquellos eventos elementales que pertenecen a <span class="math inline">\(A\)</span> y <span class="math inline">\(B\)</span>…</p>
<p><span class="math display">\[
\begin{array}{rcl}
A &amp;=&amp; (x_1, x_2, x_3) \\
B &amp;=&amp; (x_3, x_4) \\
A \cap B &amp;=&amp; (x_3)
\end{array}
\]</span> Es decir, la única forma en que pueda estar usando “jeans” ($ x_1, x_2, x_3 <span class="math inline">\() y “pantalón negro” (\)</span> x_3, x_4 <span class="math inline">\() al mismo tiempo, es que esté usando los “jeans negros” (\)</span> x_3 $). Otro triunfo para lo absolutamente obvio.</p>
<p>A esta altura, no te va a sorprender para nada la definición de $ A B $, aunque probablemente te parezca increíblemente aburrida. La única forma en que puedo estar usando “jeans” o “pantalón negro” es si el pantalón elemental que realmente uso pertenece a $ A $, o a $ B $, o a ambos. Así que:</p>
<p><span class="math display">\[
\begin{array}{rcl}
A &amp;=&amp; (x_1, x_2, x_3) \\
B &amp;=&amp; (x_3, x_4) \\
A \cup B &amp;=&amp; (x_1, x_2, x_3, x_4)
\end{array}
\]</span></p>
<p>Vaaamooooooooo!!!! Matemáticas, sabelo!</p>
<p>Entonces, ya definimos qué queremos decir con $ A B $ y $ A B <span class="math inline">\(. Ahora asignemos probabilidades a esos eventos. Más específicamente, vamos a verificar la regla que dice que:\)</span>$ P(A B) = P(A) + P(B) - P(A B) $$</p>
<p>Usando las definiciones anteriores, sabemos que: <span class="math inline">\(A \cup B = (x_1, x_2, x_3, x_4)\)</span>, entonces <span class="math display">\[
P(A \cup B) = P(x_1) + P(x_2) + P(x_3) + P(x_4)
\]</span></p>
<p>y usando el hecho de que sabemos qué eventos elementales pertenecen a $ A $, $ B $, y $ A B <span class="math inline">\(, tenemos:\)</span>$</p>
<span class="math display">\[\begin{array}{rcl}
P(A) &amp;=&amp; P(x_1) + P(x_2) + P(x_3) \\
P(B) &amp;=&amp; P(x_3) + P(x_4) \\
P(A \cap B) &amp;=&amp; P(x_3)
\end{array}\]</span>
<p><span class="math display">\[
y por lo tanto:
\]</span></p>
<span class="math display">\[\begin{array}{rcl}
P(A) + P(B) - P(A \cap B)
&amp;=&amp; P(x_1) + P(x_2) + P(x_3) + P(x_3) + P(x_4) - P(x_3) \\
&amp;=&amp; P(x_1) + P(x_2) + P(x_3) + P(x_4) \\
&amp;=&amp; P(A \cup B)
\end{array}\]</span>
<p>$$</p>
<p>Listo.</p>
<p>El próximo concepto que necesitamos definir es la notación “$ B $ dado $ A $”, que se escribe típicamente como $ B A $. Esto es lo que quiero decir: supongamos que me levanto una mañana y me pongo un pantalón. Ocurre un evento elemental $ x $. Supongamos que le grito a mi esposa (que está en la otra habitación, y no puede ver qué pantalón me puse): “¡Hoy estoy usando jeans!”. Asumiendo que ella me cree, entonces sabe que $ A $ es verdadero. <strong>Dado</strong> que sabe que ocurrió $ A $, ¿cuál es la <strong>probabilidad condicional</strong> de que también sea cierto $ B $? Bueno, pensemos qué información tiene. Estas son las cosas que sabe:</p>
<ul>
<li><p><strong>Los eventos que no son jeans son imposibles</strong>. Si $ A $ es verdadero, entonces sabemos que los únicos eventos elementales que pueden haber ocurrido son $ x_1 $, $ x_2 $ y $ x_3 $ (o sea, los jeans). Los eventos no jeans, $ x_4 $ y $ x_5 $, ahora son imposibles y deben tener probabilidad cero. En otras palabras, nuestro <strong>espacio muestral</strong> se ha restringido a los eventos jeans. Pero sigue siendo cierto que la suma de las probabilidades de estos eventos <strong>debe</strong> ser 1: sabemos con certeza que estoy usando jeans.</p></li>
<li><p><strong>Ella no aprendió nada sobre qué jeans estoy usando</strong>. Antes de que yo anunciara que estoy usando jeans, ella ya sabía que era cinco veces más probable que estuviera usando jeans azules ($ P(x_1) = 0.5 <span class="math inline">\() que jeans negros (\)</span> P(x_3) = 0.1 $). Mi anuncio no cambia eso… no dije <strong>nada</strong> sobre el color, así que la proporción $ P(x_1) / P(x_3) $ se mantiene igual, con un valor de 5.</p></li>
</ul>
<p>Solo hay una forma de satisfacer estas restricciones: asignar probabilidad cero a los eventos imposibles (es decir, <span class="math inline">\(P(x | A) = 0\)</span> si <span class="math inline">\(x\)</span> no está en <span class="math inline">\(A\)</span>), y luego dividir las probabilidades de todos los demás por <span class="math inline">\(P(A)\)</span>. En este caso, como <span class="math inline">\(P(A) = 0.9\)</span>, dividimos entre 0.9. Esto da:</p>
<table class="table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">¿Qué pantalón?</th>
<th style="text-align: center;">Evento elemental</th>
<th style="text-align: center;">Prob. original ( P(x) )</th>
<th style="text-align: center;">Nueva prob. ( P(x A) )</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Jean azul</td>
<td style="text-align: center;">( x_1 )</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.556</td>
</tr>
<tr class="even">
<td style="text-align: left;">Jean gris</td>
<td style="text-align: center;">( x_2 )</td>
<td style="text-align: center;">0.3</td>
<td style="text-align: center;">0.333</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Jean negro</td>
<td style="text-align: center;">( x_3 )</td>
<td style="text-align: center;">0.1</td>
<td style="text-align: center;">0.111</td>
</tr>
<tr class="even">
<td style="text-align: left;">Traje negro</td>
<td style="text-align: center;">( x_4 )</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Pantalón deportivo</td>
<td style="text-align: center;">( x_5 )</td>
<td style="text-align: center;">0.1</td>
<td style="text-align: center;">0</td>
</tr>
</tbody>
</table>
<p>En términos matemáticos, decimos que: $ P(x A) = x A, P(x A) = 0 x A $</p>
<p>Por lo tanto:</p>
<p><span class="math display">\[
\begin{array}{rcl}
P(B \mid A) &amp;=&amp; P(x_3 \mid A) + P(x_4 \mid A) \\\\
&amp;=&amp; \displaystyle \frac{P(x_3)}{P(A)} + 0 \\\\
&amp;=&amp; \displaystyle \frac{P(x_3)}{P(A)}
\end{array}
\]</span></p>
<p>Y recordando que <span class="math inline">\(A \cap B = (x_3)\)</span> , podemos escribir esto como: $ P(B A) = $</p>
<p>Y si multiplicamos ambos lados por ( P(A) ), obtenemos:</p>
<p>$ P(A B) = P(B A) P(A) $ que es la tercera regla que habíamos listado en la tabla anterior.</p>
</section>
</section>
<section id="la-distribución-binomial" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="la-distribución-binomial"><span class="header-section-number">5.4</span> La distribución binomial</h2>
<p>Como te podés imaginar, las distribuciones de probabilidad varían muchísimo, y hay una enorme cantidad de distribuciones ahí afuera. Sin embargo, no todas son igual de importantes. De hecho, la gran mayoría del contenido de este libro se basa en una de cinco distribuciones: la distribución binomial, la distribución normal, la distribución ( t ), la distribución ( ^2 ) (“ji-cuadrado”) y la distribución ( F ). Dicho esto, lo que voy a hacer en las próximas secciones es darte una breve introducción a esas cinco, prestando especial atención a la binomial y a la normal. Voy a empezar con la distribución binomial, porque es la más sencilla de las cinco.</p>
<section id="introducción-a-la-binomial" class="level3" data-number="5.4.1">
<h3 data-number="5.4.1" class="anchored" data-anchor-id="introducción-a-la-binomial"><span class="header-section-number">5.4.1</span> Introducción a la binomial</h3>
<p>La teoría de la probabilidad se originó como un intento de describir cómo funcionan los juegos de azar, así que parece apropiado que nuestra discusión sobre la <em>distribución binomial</em> empiece con tirar dados y lanzar monedas. Imaginá un experimento simple: en mi mano tengo 20 dados idénticos de seis caras. En una de las caras de cada dado hay una calavera; las otras cinco están en blanco. Si lanzo los 20 dados, ¿cuál es la probabilidad de que salgan exactamente 4 calaveras? Asumiendo que los dados son justos, sabemos que la chance de que cualquier dado salga calavera es 1 en 6; dicho de otra forma, la probabilidad de calavera para un solo dado es aproximadamente ( 0{,}167 ). Con eso ya tenemos suficiente información para responder la pregunta, así que veamos cómo se hace.</p>
<p>Como siempre, vamos a introducir algunos nombres y notación. Vamos a usar ( N ) para referirnos al número de lanzamientos en nuestro experimento; esto es lo que se conoce como el <strong>parámetro de tamaño</strong> de la distribución binomial. También vamos a usar ( ) para referirnos a la <strong>probabilidad de éxito</strong> de un solo lanzamiento, es decir, la probabilidad de que salga calavera. Finalmente, usaremos ( X ) para referirnos al resultado de nuestro experimento, es decir, la cantidad de calaveras que obtengo al lanzar los dados. Como el valor concreto de ( X ) depende del azar, nos referimos a él como una <strong>variable aleatoria</strong>. Con toda esta terminología y notación, podemos expresar el problema de forma un poco más precisa: la cantidad que queremos calcular es la probabilidad de que ( X = 4 ), dado que sabemos que ( = 0{,}167 ) y ( N = 20 ). La forma general de lo que queremos calcular se puede escribir como:</p>
<p>$ P(X , N) $</p>
<p>y nos interesa el caso particular en el que ( X = 4 ), ( = 0{,}167 ) y ( N = 20 ). Hay una última notación que quiero mencionar antes de pasar a cómo resolver el problema. Si quiero decir que ( X ) fue generado aleatoriamente a partir de una distribución binomial con parámetros ( ) y ( N ), lo escribo así:</p>
<p>Sí, sí, ya sé lo que estás pensando: notación, notación, notación. ¿A quién le importa? Muy pocos lectores están acá por la notación, así que mejor sigo y explico <strong>cómo usar</strong> la distribución binomial. Para eso, la <a href="#fig-4binomial1">Figura&nbsp;<span>5.3</span></a> muestra las probabilidades binomiales para todos los valores posibles de ( X ) en nuestro experimento con los dados, desde ( X = 0 ) (ninguna calavera) hasta ( X = 20 ) (todas calaveras). Notá que básicamente es un gráfico de barras, y no es distinto del gráfico de “probabilidad de pantalones” que hicimos en <a href="#fig-4pantsprob">Figura&nbsp;<span>5.2</span></a>. En el eje horizontal están todos los eventos posibles, y en el eje vertical podemos ver la probabilidad de cada uno de esos eventos. Entonces, la probabilidad de obtener 4 calaveras al lanzar 20 dados es de aproximadamente 0.20 (la respuesta exacta es 0.2022036, como veremos enseguida). En otras palabras, esperarías que eso ocurra alrededor del 20% de las veces que repitas este experimento.</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/fig-4binomial1_1a3c9ab2bca462437fed2a875e87432a">
<div class="cell-output-display">
<div id="fig-4binomial1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="imgs/navarro_img/probability/binomSkulls20_es.png" class="img-fluid figure-img" width="2400"></p>
<figcaption class="figure-caption">Figura&nbsp;5.3: La distribución binomial con parámetro de tamaño <span class="math inline">\(N = 20\)</span> y una probabilidad de éxito de 1/6. Cada barra vertical representa la probabilidad de un resultado específico (es decir, un valor posible de <span class="math inline">\(X\)</span>). Como se trata de una distribución de probabilidad, cada probabilidad debe ser un número entre 0 y 1, y la suma de las alturas de las barras también debe ser 1.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="trabajando-con-la-distribución-binomial-en-r" class="level3" data-number="5.4.2">
<h3 data-number="5.4.2" class="anchored" data-anchor-id="trabajando-con-la-distribución-binomial-en-r"><span class="header-section-number">5.4.2</span> Trabajando con la distribución binomial en R</h3>
<p>R tiene una función llamada <code>dbinom</code> que calcula probabilidades binomiales por nosotros. Los argumentos principales de la función son:</p>
<ul>
<li><p><code>x</code>: Un número (o vector de números) que especifica los valores para los que querés calcular la probabilidad.</p></li>
<li><p><code>size</code>: Un número que le indica a R el tamaño del experimento.</p></li>
<li><p><code>prob</code>: La probabilidad de éxito en un solo intento del experimento.</p></li>
</ul>
<p>Entonces, para calcular la probabilidad de obtener 4 calaveras en un experimento de 20 lanzamientos, donde la probabilidad de calavera en cada lanzamiento es 1/6, el comando sería simplemente:</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/unnamed-chunk-2_e3d45d5e72f561fb800bb88a5cbdeb8b">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="at">x =</span> <span class="dv">4</span>, <span class="at">size =</span> <span class="dv">20</span>, <span class="at">prob =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">6</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2022036</code></pre>
</div>
</div>
<p>Para que veas cómo cambia la distribución binomial cuando alteramos los valores de ( ) y ( N ), supongamos ahora que, en lugar de tirar dados, estoy lanzando monedas. En este caso, el experimento consiste en lanzar una moneda justa repetidamente, y el resultado que me interesa es cuántas veces sale cara. En este escenario, la probabilidad de éxito es ahora ( = 1/2 ). Supongamos que lanzo la moneda ( N = 20 ) veces. En este ejemplo, cambié la probabilidad de éxito, pero mantuve igual el tamaño del experimento. ¿Qué le pasa a la distribución binomial?</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/fig-4binomial2_f1abe4a0156cfe935b9cb5d4a9314e6f">
<div class="cell-output-display">
<div id="fig-4binomial2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="imgs/navarro_img/probability/Binomial2_es.png" class="img-fluid figure-img" width="2400"></p>
<figcaption class="figure-caption">Figura&nbsp;5.4: Dos distribuciones binomiales, en un escenario donde lanzo una moneda justa, con probabilidad de éxito <span class="math inline">\(1/2\)</span>. En el panel (a), se supone que lanzo la moneda <span class="math inline">\(N = 20\)</span> veces. En el panel (b), que la lanzo <span class="math inline">\(N = 100\)</span> veces.</figcaption>
</figure>
</div>
</div>
</div>
<p>Bueno, como se ve en la <a href="#fig-4binomial2">Figura&nbsp;<span>5.4</span></a> (a), el efecto principal es que la distribución se desplaza, como cabría esperar. Ahora, ¿qué pasa si lanzo la moneda ( N = 100 ) veces? En ese caso, obtenemos la <a href="#fig-4binomial2">Figura&nbsp;<span>5.4</span></a> (b). La distribución se mantiene más o menos centrada, pero hay más variabilidad en los posibles resultados.</p>
<p>En este punto, probablemente debería explicar el nombre de la función <code>dbinom()</code>. Obviamente, la parte “binom” proviene del hecho de que estamos trabajando con la distribución binomial, pero el prefijo “d” probablemente sea un pequeño misterio. En esta sección voy a dar una explicación parcial: específicamente, voy a explicar por qué existe un prefijo. En cuanto a por qué es precisamente una “d”, vas a tener que esperar hasta la próxima sección. R incluye <strong>cuatro funciones</strong> para trabajar con la distribución binomial. Estas funciones son <code>dbinom</code>, <code>pbinom</code>, <code>rbinom</code> y <code>qbinom</code>, y cada una calcula una cantidad distinta de interés. No solo eso, R hace lo mismo para <em>todas</em> las distribuciones de probabilidad que implementa. No importa de qué distribución se trate, siempre vas a encontrar una función <code>d</code>, una función <code>p</code>, una función <code>r</code> y una función <code>q</code>.</p>
<p>Veamos qué hace cada una de estas funciones. Primero, las cuatro versiones de la función requieren que le indiques los argumentos <code>size</code> y <code>prob</code>: no importa qué querés que R calcule, siempre necesita saber cuáles son los parámetros de la distribución. Sin embargo, difieren en cuanto a cuál es el otro argumento y cuál es la salida. Así que veámoslas una por una:</p>
<ul>
<li><p>La versión <code>d</code> ya la vimos. Se especifica un resultado particular <code>x</code>, y lo que devuelve es la probabilidad de obtener exactamente ese resultado (la “d” viene de <em>density</em>, aunque por ahora podés ignorarlo).</p></li>
<li><p>La versión <code>p</code> calcula la <strong>probabilidad acumulada</strong>. Se especifica un cuantil <code>q</code>, y te devuelve la probabilidad de obtener un resultado <strong>menor o igual a</strong> <code>q</code>.</p></li>
<li><p>La versión <code>q</code> calcula los <strong>cuantiles</strong> de la distribución. Se especifica un valor de probabilidad <code>p</code>, y te devuelve el percentil correspondiente. Es decir, el valor de la variable para el cual hay una probabilidad <code>p</code> de obtener un resultado inferior a ese valor.</p></li>
<li><p>La versión <code>r</code> es un <em>generador de números aleatorios</em>: genera <code>n</code> resultados aleatorios tomados de la distribución.</p></li>
</ul>
<p>Esto puede sonar algo abstracto, así que veamos algunos ejemplos concretos. Como ya vimos <code>dbinom</code>, vamos a concentrarnos en las otras tres. Empecemos con <code>pbinom</code>, y volvamos al ejemplo de los dados con calaveras. Recordá: lanzo 20 dados, cada uno tiene una chance de 1 en 6 de mostrar una calavera. Supongamos, en cambio, que quiero saber la probabilidad de obtener 4 <strong>o menos</strong> calaveras. Podría usar <code>dbinom</code> para calcular la probabilidad exacta de obtener 0, 1, 2, 3 y 4 calaveras, y luego sumar esos valores. Pero hay una forma más rápida: usar la función <code>pbinom</code>. El comando sería:</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/unnamed-chunk-3_0c53d4c840e81310bac37a3a3b4d96f1">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pbinom</span>(<span class="at">q =</span> <span class="dv">4</span>, <span class="at">size =</span> <span class="dv">20</span>, <span class="at">prob =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">6</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.7687492</code></pre>
</div>
</div>
<p>En otras palabras, hay un 76.9% de probabilidad de que al lanzar los 20 dados obtenga 4 calaveras o menos. O, dicho de otra manera, R nos está diciendo que 4 es el percentil 76.9 de esta distribución binomial.</p>
<p>Ahora consideremos la función <code>qbinom</code>. Supongamos que quiero calcular el percentil 75 de la distribución binomial. Siguiendo con el ejemplo de las calaveras, el comando sería:</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/unnamed-chunk-4_28b15c3871d307e47ebf7d85aa947a7a">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qbinom</span>(<span class="at">p =</span> <span class="fl">0.75</span>, <span class="at">size =</span> <span class="dv">20</span>, <span class="at">prob =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">6</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 4</code></pre>
</div>
</div>
<p>Mmm. Hay algo raro acá. Pensemos bien esto. Lo que parece decir la función <code>qbinom</code> es que el percentil 75 de la distribución binomial es 4, aunque vimos recién en la función que 4 es <strong>en realidad</strong> el percentil 76.9. Y la función <code>pbinom</code> es la correcta, te lo prometo. Lo raro acá surge del hecho de que nuestra distribución binomial en realidad <strong>no tiene</strong> un percentil 75. ¿Por qué no? Bueno, hay un 56.7% de chance de obtener 3 o menos calaveras (podés escribir <code>pbinom(3, 20, 1/6)</code> para comprobarlo), y un 76.9% de chance de obtener 4 o menos calaveras. Entonces, en cierto sentido, el percentil 75 debería estar “entre medio” de 3 y 4 calaveras. ¡Pero eso no tiene sentido! No podés tirar 20 dados y que salgan 3.9 calaveras. Este problema se puede manejar de distintas formas: podrías reportar un valor intermedio (o <strong>interpolado</strong>, como se dice técnicamente), como 3.9 podrías redondear hacia abajo (a 3) o podrías redondear hacia arriba (a 4).</p>
<p>La función <code>qbinom</code> redondea hacia arriba: si pedís un percentil que no existe literalmente (como el 75 en este ejemplo), R encuentra el valor más pequeño cuyo percentil acumulado sea <strong>al menos</strong> el que pediste. En este caso, como el “verdadero” percentil 75 (sea lo que sea que eso signifique) está entre 3 y 4 calaveras, R redondea hacia arriba y te da 4. Esta sutileza puede ser molesta, lo admito, pero por suerte solo es un problema en distribuciones discretas como la binomial. Las otras distribuciones de las que voy a hablar (normal, ( t ), ( ^2 ) y ( F )) son todas continuas, así que R siempre puede devolver un cuantil exacto cuando se lo pedís.</p>
<p>Finalmente, tenemos el generador de números aleatorios. Para usar la función <code>rbinom</code>, tenés que especificar cuántas veces querés que R “simule” el experimento usando el argumento <code>n</code>, y te va a generar resultados aleatorios tomados de la distribución binomial. Por ejemplo, si quisiera repetir el experimento de tirar dados 100 veces, puedo hacer que R simule esos resultados así:</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/unnamed-chunk-5_cb0655b49192996f9134349f63a4d235">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rbinom</span>(<span class="at">n =</span> <span class="dv">100</span>, <span class="at">size =</span> <span class="dv">20</span>, <span class="at">prob =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">6</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  [1]  4  2  5  3  1  2  6  6  8  2  3  4  3  2  3  3 10  2  5  5  5  0  3  3  2
 [26]  5  1  3  5  1  7  2  5  4  6  1  3  1  5  5  4  2  2  3  3  2  3  2  1  5
 [51]  5  2  2  3  5  7  4  4  2  5  1  4  2  5  4  2  2  1  1  3  3  5  5  6  2
 [76]  2  4  2  5  2  2  3  5  3  6  2  4  7  4  3  5  4  2  6  1  2  4  5  5  1</code></pre>
</div>
</div>
<p>Como podés ver, los números que aparecen son lo que uno esperaría, dada la distribución que se muestra en la <a href="#fig-4binomial1">Figura&nbsp;<span>5.3</span></a>. La mayoría de las veces saco entre 1 y 5 calaveras. Hay muchas sutilezas sobre cómo se generan números aleatorios en una computadora, pero para los fines de este libro no necesitamos preocuparnos demasiado.</p>
</section>
</section>
<section id="la-distribución-normal" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="la-distribución-normal"><span class="header-section-number">5.5</span> La distribución normal</h2>
<p>Aunque la distribución binomial es conceptualmente la más fácil de entender, <strong>no es la más importante</strong>. Ese honor particular le corresponde a la <em>distribución normal</em>, también conocida como “curva de campana” o “distribución gaussiana”.</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/fig-4normal_00dcd58d85db4d5be88cd8aa583ec6e7">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"imgs/navarro_img/probability/standardNormal_es.png"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-4normal" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="imgs/navarro_img/probability/standardNormal_es.png" class="img-fluid figure-img" width="2400"></p>
<figcaption class="figure-caption">Figura&nbsp;5.5: La distribución normal con media = 0 y desviación estándar = 1. El eje x representa los valores posibles de una variable, y el eje y nos dice qué tan probable es observar ese valor. Sin embargo, notá que el eje y está etiquetado como Densidad de Probabilidad y no como Probabilidad. Esto se debe a una característica sutil —y algo frustrante— de las distribuciones continuas, que hace que el eje y se comporte de manera un poco extraña: la altura de la curva no representa literalmente la probabilidad de observar un valor x en particular. Por otro lado, es cierto que las alturas de la curva te indican cuáles valores de x son más probables (¡los más altos!).</figcaption>
</figure>
</div>
</div>
</div>
<p>Una distribución normal se describe usando dos parámetros: la media de la distribución (( )) y la desviación estándar (( )). La notación que usamos a veces para indicar que una variable ( X ) tiene distribución normal es:</p>
<p>$ X (, ) $</p>
<p>Claro que eso es solo notación. No nos dice nada especialmente interesante sobre la distribución normal en sí. La fórmula matemática de la distribución normal es:</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/4normalformula_08a789c5d23c7e45a0c57b78f5ac4b24">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/navarro_img/probability/Normal_formula.png" class="img-fluid figure-img" width="268"></p>
<figcaption class="figure-caption">Fórmula de la distribución normal</figcaption>
</figure>
</div>
</div>
</div>
<p>La fórmula es lo suficientemente importante como para que cualquiera que aprenda estadística la mire al menos una vez, pero como este es un texto introductorio, no quiero enfocarme demasiado en eso. En cambio, vamos a ver cómo se puede usar R para trabajar con distribuciones normales. Las funciones en R para la distribución normal son <code>dnorm()</code>, <code>pnorm()</code>, <code>qnorm()</code> y <code>rnorm()</code>. Sin embargo, se comportan exactamente igual que sus equivalentes para la distribución binomial, así que no hay mucho que necesites saber. Lo único que vale la pena señalar es que los argumentos para los parámetros se llaman <code>mean</code> y <code>sd</code>. En casi todo lo demás, no hay más que agregar.</p>
<p>En lugar de enfocarnos en las matemáticas, tratemos de entender qué significa que una variable tenga distribución normal. Para eso, mirá la <a href="#fig-4normal">Figura&nbsp;<span>5.5</span></a>, que muestra una distribución normal con media ( = 0 ) y desviación estándar ( = 1 ). Podés ver de dónde viene el nombre “curva de campana”: se parece un poco a una campana. Notá que, a diferencia de los gráficos que dibujé para ilustrar la distribución binomial, la <a href="#fig-4normal">Figura&nbsp;<span>5.5</span></a> muestra una curva suave, no un gráfico tipo histograma. Esto no es una elección arbitraria: la distribución normal es continua, mientras que la binomial es discreta. En el ejemplo anterior, era posible obtener 3 calaveras o 4 calaveras, pero era imposible obtener 3.9 calaveras.</p>
<p>Teniendo eso en cuenta, veamos si podemos desarrollar una intuición de cómo funciona la distribución normal. Primero, vamos a ver qué pasa cuando jugamos con los parámetros de la distribución. Uno de los parámetros que podemos modificar es la media. Esto desplaza la distribución hacia la derecha o hacia la izquierda. La animación en la <a href="#fig-4normalMeanShift">Figura&nbsp;<span>5.6</span></a> muestra una distribución normal con media = 0, que se va moviendo desde media = 0 hasta media = 5. Notá que, cuando cambiás la media, la forma de la distribución no cambia: simplemente se traslada de izquierda a derecha. En la animación, la curva normal sube y baja un poco, pero eso es solo una característica visual de la animación (además queda lindo así).</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/fig-4normalMeanShift_771c872b4d9d633ccff82ed81b05548b">
<div class="cell-output-display">
<div id="fig-4normalMeanShift" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="imgs/gifs/normalMovingMean-1_es.gif" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">Figura&nbsp;5.6: Una distribución normal con media variable</figcaption>
</figure>
</div>
</div>
</div>
<p>En cambio, si aumentamos la desviación estándar manteniendo constante la media, el pico de la distribución se queda en el mismo lugar, pero la distribución se ensancha. La animación en <a href="#fig-4normalSDShift">Figura&nbsp;<span>5.7</span></a> muestra lo que pasa cuando empezamos con una desviación estándar pequeña (sd = 0.5), y la aumentamos gradualmente hasta sd = 5. Como podés ver, la distribución se expande y se vuelve más ancha a medida que aumenta la desviación estándar.</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/fig-4normalSDShift_d97155434c407bef7e419b5857845f6d">
<div class="cell-output-display">
<div id="fig-4normalSDShift" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="imgs/gifs/normalMovingSD-1_es.gif" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">Figura&nbsp;5.7: Una distribución normal con desviación estándar variable.</figcaption>
</figure>
</div>
</div>
</div>
<p>Fijate que cuando ensanchamos la distribución, la altura del pico disminuye. Eso tiene que ocurrir: al igual que las alturas de las barras en la distribución binomial debían <em>sumar</em> 1, el <em>área bajo la curva</em> de la distribución normal también debe ser igual a 1. Antes de continuar, quiero señalar una característica importante de la distribución normal. Sin importar cuál sea la media o la desviación estándar específica, el 68.3% del área cae dentro de 1 desviación estándar de la media. De forma similar, el 95.4% cae dentro de 2 desviaciones estándar, y el 99.7% está dentro de 3 desviaciones estándar.</p>
<section id="densidad-de-probabilidad" class="level3" data-number="5.5.1">
<h3 data-number="5.5.1" class="anchored" data-anchor-id="densidad-de-probabilidad"><span class="header-section-number">5.5.1</span> Densidad de probabilidad</h3>
<p>Hay algo que estuve intentando ocultar durante toda mi discusión sobre la distribución normal. Algo que algunos libros introductorios directamente omiten por completo. Tal vez tengan razón en hacerlo: esta “cosa” que estoy ocultando es rara y contraintuitiva, incluso según los estándares algo retorcidos que rigen en estadística. Afortunadamente, no es algo que necesites entender a fondo para hacer estadística básica: es algo que empieza a volverse importante más adelante, cuando salís de lo introductorio. Así que si no te queda completamente claro, no te preocupes: tratá de captar la idea general.</p>
<p>A lo largo de esta discusión sobre la distribución normal, hay una o dos cosas que no cierran del todo. Quizás notaste que el eje ( y ) en esas figuras está etiquetado como “Densidad de probabilidad” y no como “Probabilidad”. Tal vez notaste que usé ( p(X) ) en lugar de ( P(X) ) al mostrar la fórmula de la normal. Quizás te preguntás por qué R usa el prefijo <code>"d"</code> para funciones como <code>dnorm()</code>. Y tal vez, solo tal vez, estuviste jugando con la función <code>dnorm()</code> y accidentamente escribiste un comando como este:</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/unnamed-chunk-6_2b76cf2a90d6cd88f9be10904166c106">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dnorm</span>(<span class="at">x =</span> <span class="dv">1</span>, <span class="at">mean =</span> <span class="dv">1</span>, <span class="at">sd =</span> <span class="fl">0.1</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3.989423</code></pre>
</div>
</div>
<p>Y si hiciste eso, seguramente quedaste muy confundido. Le pedí a R que calcule la probabilidad de que ( x = 1 ) para una variable con distribución normal, media = 1 y desviación estándar = 0.1; y R me responde que la “probabilidad” es 3.99. Pero, como discutimos antes, las probabilidades <strong>no pueden</strong> ser mayores que 1. Entonces, o me equivoqué, o eso que R me dio no es una probabilidad.</p>
<p>Resulta que la segunda opción es la correcta. Lo que calculamos ahí no es una probabilidad: es otra cosa. Para entender qué es esa otra cosa, tenemos que dedicar un momento a pensar qué <em>significa</em> realmente decir que ( X ) es una variable continua. Supongamos que estamos hablando de la temperatura exterior. El termómetro me dice que hace 23 grados, pero yo sé que eso no es del todo cierto. No son exactamente 23 grados. Quizás sean 23.1. Pero tampoco es del todo cierto, porque podrían ser 23.09. Pero, claro, también podrían ser 23.091. Bueno… ya entendés la idea. El problema con las cantidades verdaderamente continuas es que nunca sabés exactamente qué son.</p>
<p>Ahora pensá qué implica esto cuando hablamos de probabilidades. Supongamos que la temperatura máxima de mañana se extrae de una distribución normal con media 23 y desviación estándar 1. ¿Cuál es la probabilidad de que la temperatura sea <em>exactamente</em> 23 grados? La respuesta es “cero”, o si querés, “un número tan cercano a cero que es indistinguible de cero”. ¿Por qué?</p>
<p>Es como intentar tirar un dardo a un blanco infinitamente pequeño: no importa qué tan buena sea tu puntería, nunca lo vas a acertar. En la vida real, nunca vas a obtener un valor exactamente igual a 23. Siempre va a ser algo como 23,1 o 22,99998 o algo por el estilo. En otras palabras, no tiene ningún sentido hablar de la probabilidad de que la temperatura sea exactamente 23 grados. Sin embargo, en el lenguaje cotidiano, si yo te dijera que afuera hace 23 grados y en realidad son 22,9998, probablemente no me dirías que estoy mintiendo. Porque en la vida diaria, decir “23 grados” suele significar algo así como “entre 22,5 y 23,5 grados”. Y aunque no tiene mucho sentido preguntar cuál es la probabilidad de que la temperatura sea exactamente 23 grados, sí parece razonable preguntar cuál es la probabilidad de que esté entre 22,5 y 23,5, o entre 20 y 30, o dentro de cualquier otro rango de temperaturas.</p>
<p>El punto de toda esta discusión es dejar en claro que, cuando hablamos de distribuciones continuas, no tiene sentido hablar de la probabilidad de un valor específico. Sin embargo, <strong>sí podemos</strong> hablar de la <strong>probabilidad de que el valor esté dentro de un cierto rango</strong>. Y para calcular esa probabilidad, lo que necesitamos hacer es calcular el “área bajo la curva”.</p>
<p>Ok, eso explica parte del asunto. Hablamos un poco sobre cómo deberían interpretarse las distribuciones continuas (es decir, el área bajo la curva es la clave), pero todavía no expliqué realmente qué calcula la función <em><code>dnorm()</code></em>. O, en forma equivalente, ¿qué significa la fórmula de ( p(x) ) que presentamos antes? Evidentemente, ( p(x) ) no describe una probabilidad. Entonces, ¿qué es? El nombre técnico de esa cantidad ( p(x) ) es <em>densidad de probabilidad</em>, y en los gráficos que venimos dibujando, corresponde a la <em>altura</em> de la curva. Las densidades no tienen sentido por sí solas; pero están “diseñadas” de manera que el <em>área</em> bajo la curva sea siempre interpretable como probabilidades genuinas. Para ser sincero, eso es más o menos todo lo que necesitás saber por ahora.</p>
</section>
</section>
<section id="otras-distribuciones-útiles" class="level2" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="otras-distribuciones-útiles"><span class="header-section-number">5.6</span> Otras distribuciones útiles</h2>
<p>Hay muchas otras distribuciones útiles, entre ellas la distribución <code>t</code>, la distribución <code>F</code> y la distribución chi cuadrado (<code>χ²</code>). Pronto vamos a aprender más sobre las distribuciones <code>t</code> y <code>F</code> cuando discutamos los t-tests y los ANOVA en capítulos posteriores.</p>
</section>
<section id="resumen-sobre-la-probabilidad" class="level2" data-number="5.7">
<h2 data-number="5.7" class="anchored" data-anchor-id="resumen-sobre-la-probabilidad"><span class="header-section-number">5.7</span> Resumen sobre la probabilidad</h2>
<p>Hablamos sobre qué significa la probabilidad, y por qué los estadísticos no logran ponerse de acuerdo sobre su significado. Hablamos de las reglas que deben cumplir las probabilidades. Y presentamos la idea de una distribución de probabilidad, dedicando una buena parte del capítulo a algunas de las distribuciones más importantes con las que trabajan los estadísticos. Discutimos cosas como:</p>
<ul>
<li><p>Teoría de la probabilidad versus estadística</p></li>
<li><p>Visiones frecuentista versus bayesiana de la probabilidad</p></li>
<li><p>Fundamentos básicos de la teoría de la probabilidad</p></li>
<li><p>Distribuciones binomial y normal</p></li>
</ul>
<p>Como era de esperarse, esta cobertura está lejos de ser exhaustiva. La teoría de la probabilidad es una rama amplia de las matemáticas, con entidad propia, separada de su aplicación a la estadística y al análisis de datos. Hay miles de libros escritos sobre el tema, y en general las universidades ofrecen varias materias dedicadas exclusivamente a la teoría de la probabilidad. Incluso la tarea “más sencilla” de documentar las distribuciones de probabilidad estándar es un tema extenso. Por suerte para vos, muy poco de todo eso es necesario. Es poco probable que necesites conocer decenas de distribuciones estadísticas para hacer análisis de datos en el mundo real, y definitivamente no las vas a necesitar para este libro. Pero nunca está de más saber que existen otras posibilidades.</p>
<p>Retomando ese último punto, en cierto sentido todo este capítulo es una especie de digresión. Muchas materias de estadística en psicología a nivel de grado pasan muy por arriba este contenido (sé que así fue en mi caso), e incluso las materias más avanzadas suelen “olvidarse” de volver sobre los fundamentos básicos del campo. La mayoría de los psicólogos académicos no sabría explicar la diferencia entre probabilidad y densidad, y hasta hace poco, muy pocos sabían que había una diferencia entre la probabilidad bayesiana y la frecuentista. Sin embargo, creo que es importante entender estas cosas antes de pasar a las aplicaciones. Por ejemplo, hay muchas reglas sobre lo que se puede o no se puede decir cuando hacés inferencia estadística, y muchas de esas reglas pueden parecer arbitrarias o extrañas. Pero empiezan a tener sentido cuando entendés que existe esta distinción entre lo bayesiano y lo frecuentista.</p>
</section>
<section id="muestras-poblaciones-y-muestreo" class="level2" data-number="5.8">
<h2 data-number="5.8" class="anchored" data-anchor-id="muestras-poblaciones-y-muestreo"><span class="header-section-number">5.8</span> Muestras, poblaciones y muestreo</h2>
<p>Recordá que el rol de la estadística descriptiva es resumir de forma concisa lo que <strong>sí</strong> sabemos. En cambio, el propósito de la estadística inferencial es “aprender lo que no sabemos a partir de lo que sí sabemos”. ¿Qué tipo de cosas nos gustaría aprender? ¿Y cómo las aprendemos? Estas son las preguntas que están en el corazón de la estadística inferencial, y que tradicionalmente se dividen en dos “grandes ideas”: estimación y pruebas de hipótesis. El objetivo de este capítulo es presentar la primera de estas ideas, la teoría de la estimación, pero antes vamos a hablar sobre teoría del muestreo, porque la estimación no tiene sentido si no entendés cómo funciona el muestreo. Así que este capítulo se divide en dos partes: teoría del muestreo, y cómo usar esa teoría para hablar sobre cómo piensan los estadísticos el problema de la estimación. Ya hicimos bastante muestreo, así que ya estás familiarizado con algunas de las ideas principales.</p>
<p>La <strong>teoría del muestreo</strong> cumple un rol enorme a la hora de definir los supuestos sobre los que se apoyan tus inferencias estadísticas. Y para poder hablar de hacer inferencias como lo hacen los estadísticos, tenemos que ser un poco más explícitos sobre <strong>de dónde</strong> extraemos inferencias (la muestra) y <strong>sobre qué</strong> extraemos inferencias (la población).</p>
<p>En casi cualquier situación de interés, lo que tenemos disponible como investigadores es una <strong>muestra</strong> de datos. Podés haber hecho un experimento con cierta cantidad de participantes; una encuestadora puede haber llamado a cierta cantidad de personas para preguntarles su intención de voto; etc. En todos los casos: el conjunto de datos que tenemos es finito e incompleto. No podemos hacer que cada persona del mundo participe en nuestro experimento; una encuestadora no tiene ni el tiempo ni el dinero para llamar a cada votante del país, etc. En nuestra discusión anterior sobre estadística descriptiva, la muestra era lo único que nos interesaba. Nuestro único objetivo era encontrar formas de describir, resumir y graficar esa muestra. Pero eso está por cambiar.</p>
<section id="definir-una-población" class="level3" data-number="5.8.1">
<h3 data-number="5.8.1" class="anchored" data-anchor-id="definir-una-población"><span class="header-section-number">5.8.1</span> Definir una población</h3>
<p>Una muestra es algo concreto. Podés abrir un archivo de datos y ver los valores de tu muestra ahí. Una <strong>población</strong>, en cambio, es un concepto más abstracto. Se refiere al conjunto de todas las personas, o de <strong>todas</strong> las observaciones, sobre las que querés sacar conclusiones, y generalmente es mucho más grande que la muestra. En un mundo ideal, los investigadores empezarían cada estudio con una idea clara de cuál es su población de interés, ya que el proceso de diseñar un estudio y poner a prueba hipótesis con los datos obtenidos depende de esa población sobre la que queremos hablar. Sin embargo, eso no siempre ocurre en la práctica: en general, los investigadores tienen solo una idea vaga de cuál es la población, y diseñan el estudio lo mejor que pueden con base en eso.</p>
<p>A veces es fácil definir la población de interés. Por ejemplo, en el caso de la “encuestadora”, la población está compuesta por todas las personas habilitadas para votar en el momento de la encuesta —millones de personas. La muestra era un conjunto de 1000 personas y todas pertenecen a esa población. En la mayoría de los casos, la situación es mucho menos clara. En un experimento psicológico típico, determinar cuál es la población de interés puede ser algo más complicado. Supongamos que hago un experimento con 100 estudiantes universitarios como participantes. Mi objetivo, como científica cognitiva, es aprender algo sobre cómo funciona la mente. Entonces, ¿cuál de las siguientes opciones debería contar como “la población”?</p>
<ul>
<li><p>¿Todxs los estudiantes de psicología de grado de la Universidad de Adelaide?</p></li>
<li><p>¿Estudiantes de psicología de grado en general, en cualquier parte del mundo?</p></li>
<li><p>¿Personas que viven actualmente en Australia?</p></li>
<li><p>¿Personas australianas de edades similares a mi muestra?</p></li>
<li><p>¿Cualquier persona viva en la actualidad?</p></li>
<li><p>¿Cualquier ser humano, pasado, presente o futuro?</p></li>
<li><p>¿Cualquier organismo biológico con suficiente inteligencia y que opere en un entorno terrestre?</p></li>
<li><p>¿Cualquier ser inteligente?</p></li>
</ul>
<p>Cada una de estas opciones define un grupo real de entidades con mente, que podrían interesarme como científica cognitiva, y no está nada claro cuál de ellas debería considerarse la verdadera población de interés.</p>
</section>
<section id="muestras-aleatorias-simples" class="level3" data-number="5.8.2">
<h3 data-number="5.8.2" class="anchored" data-anchor-id="muestras-aleatorias-simples"><span class="header-section-number">5.8.2</span> Muestras aleatorias simples</h3>
<p>Independientemente de cómo definamos la población, el punto clave es que la muestra es un subconjunto de la población, y nuestro objetivo es usar lo que sabemos de la muestra para hacer inferencias sobre las propiedades de la población. La relación entre la muestra y la población depende del <strong>procedimiento</strong> por el cual se seleccionó la muestra. Este procedimiento se conoce como <strong>método de muestreo</strong>, y es importante entender por qué eso importa.</p>
<p>Para mantenerlo simple, imaginá que tenemos una bolsa con 10 fichas. Cada ficha tiene una letra única impresa, así que podemos distinguirlas. Las fichas vienen en dos colores: negro y blanco.</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/fig-srs1_440e8a757a7c73b96ca15620a3d8eaee">
<div class="cell-output-display">
<div id="fig-srs1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="imgs/navarro_img/estimation/srs1_es.png" class="img-fluid figure-img" width="562"></p>
<figcaption class="figure-caption">Figura&nbsp;5.8: Muestreo aleatorio simple sin reemplazo a partir de una población finita.</figcaption>
</figure>
</div>
</div>
</div>
<p>Este conjunto de fichas es la población de interés, y está representada gráficamente en la parte izquierda de la <a href="#fig-srs1">Figura&nbsp;<span>5.8</span></a>.</p>
<p>Como podés ver en la imagen, hay 4 fichas negras y 6 fichas blancas, pero en la vida real no sabríamos eso a menos que miremos dentro de la bolsa. Ahora imaginá que hacés el siguiente “experimento”: agitás la bolsa, cerrás los ojos y sacás 4 fichas, sin devolverlas después de sacarlas. Primero sale la ficha <span class="math inline">\(a\)</span> (negra), luego la <span class="math inline">\(c\)</span> (blanca), después la <span class="math inline">\(j\)</span> (blanca), y finalmente la <span class="math inline">\(b\)</span> (negra). Si quisieras, podrías volver a meter todas las fichas en la bolsa y repetir el experimento, como se muestra en el lado derecho de la <a href="#fig-srs1">Figura&nbsp;<span>5.8</span></a>. Cada vez vas a obtener resultados distintos, pero el procedimiento es idéntico en todos los casos. El hecho de que el mismo procedimiento pueda producir distintos resultados cada vez es lo que hace que lo llamemos un <strong>proceso aleatorio</strong>. Sin embargo, como agitamos la bolsa antes de sacar cualquier ficha, parece razonable pensar que cada ficha tenía la misma probabilidad de ser elegida. Un procedimiento en el que cada miembro de la población tiene la misma probabilidad de ser seleccionado se llama una <strong>muestra aleatoria simple</strong>. El hecho de que <strong>no</strong> devolvimos las fichas a la bolsa después de sacarlas significa que no podés observar la misma ficha dos veces, y en estos casos se dice que las observaciones fueron tomadas <strong>sin reemplazo</strong>.</p>
<p>Para ayudarte a entender la importancia del procedimiento de muestreo, considerá una alternativa. Supongamos que mi hijo de 5 años abre la bolsa y decide sacar cuatro fichas negras, sin devolver ninguna. Este esquema de muestreo <strong>sesgado</strong> se muestra en la <a href="#fig-brs">Figura&nbsp;<span>5.9</span></a>.</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/fig-brs_b0e1a516a8667940e64077afb5fee392">
<div class="cell-output-display">
<div id="fig-brs" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="imgs/navarro_img/estimation/brs_es.png" class="img-fluid figure-img" width="550"></p>
<figcaption class="figure-caption">Figura&nbsp;5.9: Muestreo sesgado sin reemplazo a partir de una población finita.</figcaption>
</figure>
</div>
</div>
</div>
<p>Ahora considerá el valor informativo de observar 4 fichas negras y 0 blancas. Claramente, eso depende del esquema de muestreo, ¿no? Si sabés que el procedimiento estaba sesgado a seleccionar solo fichas negras, entonces una muestra compuesta únicamente por fichas negras no te dice mucho sobre la población. Por esta razón, a los estadísticos les encanta cuando un conjunto de datos puede considerarse una muestra aleatoria simple, porque hace que el análisis de los datos sea <strong>mucho</strong> más fácil.</p>
<p>Hay un tercer procedimiento que vale la pena mencionar. Esta vez, cerramos los ojos, agitamos la bolsa y sacamos una ficha. Pero ahora, registramos la ficha y luego la devolvemos a la bolsa. De nuevo, cerramos los ojos, agitamos la bolsa y sacamos otra ficha. Repetimos este procedimiento hasta tener 4 fichas. Los conjuntos de datos generados de esta manera también se consideran muestras aleatorias simples, pero como devolvemos las fichas a la bolsa después de cada extracción, se dice que es un muestreo <strong>con reemplazo</strong>. La diferencia con el primer caso es que ahora es posible observar el mismo miembro de la población más de una vez, como se muestra en la <a href="#fig-srs2">Figura&nbsp;<span>5.10</span></a>.</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/fig-srs2_290f87ccf46fd6544f5b91051c1d9986">
<div class="cell-output-display">
<div id="fig-srs2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="imgs/navarro_img/estimation/srs2_es.png" class="img-fluid figure-img" width="562"></p>
<figcaption class="figure-caption">Figura&nbsp;5.10: Muestreo aleatorio simple con reemplazo a partir de una población finita.</figcaption>
</figure>
</div>
</div>
</div>
<p>La mayoría de los experimentos en psicología tienden a ser sin reemplazo, porque no se permite que una misma persona participe dos veces en el mismo experimento. Sin embargo, la mayoría de la teoría estadística asume que los datos provienen de una muestra aleatoria simple <strong>con</strong> reemplazo. En la vida real, esto rara vez importa. Si la población es grande (por ejemplo, más de 10 elementos), la diferencia entre muestreo con o sin reemplazo es demasiado pequeña como para preocuparse. En cambio, la diferencia entre una muestra aleatoria simple y una muestra sesgada no es algo que podamos ignorar tan fácilmente.</p>
</section>
<section id="la-mayoría-de-las-muestras-no-son-aleatorias-simples" class="level3" data-number="5.8.3">
<h3 data-number="5.8.3" class="anchored" data-anchor-id="la-mayoría-de-las-muestras-no-son-aleatorias-simples"><span class="header-section-number">5.8.3</span> La mayoría de las muestras no son aleatorias simples</h3>
<p>Como pudiste ver en la lista de posibles poblaciones que mostré antes, es casi imposible obtener una muestra aleatoria simple de la mayoría de las poblaciones de interés. Cuando hago experimentos, ya considero un pequeño milagro que mis participantes sean una muestra aleatoria de los estudiantes de psicología de grado en la Universidad de Adelaide, ¡y eso que esa es por lejos la población más acotada a la que podría querer generalizar! Una discusión detallada de otros esquemas de muestreo está más allá del alcance de este libro, pero para que tengas una idea de lo que existe, acá listo algunos de los más importantes:</p>
<ul>
<li><p><strong>Muestreo estratificado</strong>. Supongamos que tu población se divide (o se puede dividir) en varias subpoblaciones diferentes, o <strong>estratos</strong>. Por ejemplo, tal vez estés haciendo un estudio en varios sitios distintos. En lugar de intentar muestrear al azar de la población total, podés intentar recolectar una muestra aleatoria separada de cada uno de los estratos. El muestreo estratificado a veces es más fácil de realizar que el muestreo aleatorio simple, especialmente cuando la población ya está dividida en estratos definidos. También puede ser más eficiente, sobre todo si algunas subpoblaciones son poco frecuentes. Por ejemplo, al estudiar esquizofrenia, sería mucho mejor dividir la población en dos estratos (con y sin esquizofrenia), y luego seleccionar la misma cantidad de personas de cada grupo. Si seleccionaras gente al azar, obtendrías tan pocas personas con esquizofrenia que el estudio sería inútil. Este tipo específico de muestreo estratificado se conoce como <strong>sobremuestreo</strong>, porque busca deliberadamente sobre-representar grupos poco frecuentes.</p></li>
<li><p><strong>Muestreo en bola de nieve</strong> es una técnica especialmente útil cuando la población de interés es “oculta” o difícil de acceder, y es bastante común en las ciencias sociales. Por ejemplo, supongamos que los investigadores quieren hacer una encuesta de opinión entre personas trans. El equipo de investigación tal vez tenga datos de contacto de unas pocas personas trans, así que la encuesta empieza por invitarlas a participar (etapa 1). Al final de la encuesta, se les pide a los participantes que proporcionen contactos de otras personas que podrían querer participar. En la etapa 2, se encuesta a esas nuevas personas. El proceso continúa hasta que los investigadores hayan reunido suficientes datos. La gran ventaja del muestreo en bola de nieve es que te permite obtener datos en situaciones donde de otro modo sería imposible. En el plano estadístico, la principal desventaja es que la muestra realmente es no aleatoria, y en formas difíciles de compensar. En el plano ético, la desventaja es que el procedimiento puede ser problemático si no se maneja bien, porque las poblaciones ocultas a menudo están ocultas por una razón. Elegí a las personas trans como ejemplo para destacar esto: si no sos cuidadoso, podrías terminar exponiendo a alguien que no quiere ser expuesto (algo realmente inaceptable). Y eso puede tener consecuencias personales o profesionales graves para esa persona. Incluso si no cometés ese error, sigue siendo una intromisión usar las redes sociales de las personas para estudiarlas. Es muy difícil obtener consentimiento informado <strong>antes</strong> de contactarlas, y en muchos casos el simple hecho de decirles “hola, queremos estudiar tus datos” puede ser molesto o invasivo. Las redes sociales son cosas complejas, y el hecho de que puedas usarlas para recolectar datos no siempre significa que debas hacerlo.</p></li>
<li><p><strong>Muestreo por conveniencia</strong> es más o menos lo que suena: las muestras se eligen de una forma que le resulte conveniente al investigador, y no son seleccionadas al azar de la población de interés. El muestreo en bola de nieve es una forma de muestreo por conveniencia, pero hay muchas otras. Un ejemplo común en psicología son los estudios que se hacen con estudiantes de grado en psicología. Estas muestras suelen no ser aleatorias en dos sentidos: primero, depender de estudiantes de psicología de grado implica automáticamente que los datos se limitan a una única subpoblación. Segundo, los propios estudiantes suelen elegir en qué estudios participar, por lo que la muestra termina siendo un subconjunto autoseleccionado de estudiantes de psicología, y no uno seleccionado al azar. En la práctica, la mayoría de los estudios se basan en muestras por conveniencia de una forma u otra. A veces esto representa una limitación importante, pero no siempre.</p></li>
</ul>
</section>
<section id="qué-tan-grave-es-no-tener-una-muestra-aleatoria-simple" class="level3" data-number="5.8.4">
<h3 data-number="5.8.4" class="anchored" data-anchor-id="qué-tan-grave-es-no-tener-una-muestra-aleatoria-simple"><span class="header-section-number">5.8.4</span> ¿Qué tan grave es no tener una muestra aleatoria simple?</h3>
<p>Ok, entonces recolectar datos en el mundo real casi nunca involucra una muestra aleatoria simple. ¿Y eso importa? Con un poco de reflexión, te debería quedar claro que <strong>puede</strong> importar si tus datos no son una muestra aleatoria simple: basta con pensar en la diferencia entre la <a href="#fig-srs1">Figura&nbsp;<span>5.8</span></a> y la <a href="#fig-brs">Figura&nbsp;<span>5.9</span></a>. Sin embargo, no es tan grave como suena. Algunos tipos de muestras sesgadas no son problemáticas en absoluto. Por ejemplo, cuando usás muestreo estratificado, en realidad <strong>sabés</strong> cuál es el sesgo porque vos mismo lo generaste a propósito, a menudo para <strong>incrementar</strong> la efectividad de tu estudio. Y existen técnicas estadísticas que permiten ajustar los análisis para tener en cuenta esos sesgos (¡aunque este libro no las cubre!).</p>
<p>En general, es importante recordar que el muestreo aleatorio es un medio para un fin, no un fin en sí mismo. Supongamos que usaste una muestra por conveniencia, y por eso podés asumir que tiene algún sesgo. Un sesgo en el método de muestreo solo es problemático si te lleva a sacar conclusiones equivocadas. Desde esa perspectiva, no necesitamos que la muestra sea aleatoria en absolutamente <strong>todos</strong> los aspectos: solo necesitamos que sea aleatoria en relación al fenómeno psicológico que estamos estudiando. Supongamos que estoy haciendo un estudio sobre la capacidad de memoria de trabajo. En el estudio 1, tengo la capacidad de muestrear al azar a toda la población humana viva, con una sola excepción: solo puedo muestrear personas nacidas un lunes. En el estudio 2, puedo muestrear al azar a la población australiana. Quiero generalizar mis resultados a toda la población humana actual. ¿Cuál de los dos estudios preferirías? La respuesta, obviamente, es el estudio 1. ¿Por qué? Porque no hay ninguna razón para pensar que “haber nacido un lunes” tenga alguna relación interesante con la capacidad de memoria de trabajo. En cambio, sí puedo imaginar varias razones por las que “ser australiano” podría importar. Australia es un país rico, industrializado, con un sistema educativo muy desarrollado. Las personas que crecieron en ese sistema habrán tenido experiencias de vida mucho más parecidas a las de quienes diseñaron los tests de capacidad de memoria de trabajo. Esa experiencia compartida podría traducirse en creencias similares sobre cómo “hacer un test”, en supuestos comunes sobre cómo funcionan los experimentos psicológicos, y así. Estas cosas podrían importar. Por ejemplo, el “estilo de rendir exámenes” puede haber enseñado a los participantes australianos a concentrarse exclusivamente en materiales bastante abstractos, comparado con personas que no crecieron en un entorno similar, lo que podría llevar a una imagen distorsionada de lo que realmente es la capacidad de memoria de trabajo.</p>
<p>Hay dos ideas importantes escondidas en esta discusión: Primero, cuando diseñás tus propios estudios, es importante pensar cuál es la población que te interesa, y esforzarte por muestrear de una forma apropiada para esa población. En la práctica, muchas veces no te queda otra que trabajar con una “muestra por conveniencia” (por ejemplo, docentes de psicología que muestrean estudiantes de psicología porque es la forma más barata de recolectar datos, y nuestros presupuestos no son exactamente desbordantes de oro). Pero si hacés eso, al menos tendrías que dedicar algo de tiempo a pensar cuáles son los posibles riesgos de esta práctica.</p>
<p>Segundo, si vas a criticar el estudio de otra persona porque usó una muestra por conveniencia, en lugar de haber hecho el esfuerzo enorme de muestrear aleatoriamente de toda la población humana, al menos tené la cortesía de ofrecer una hipótesis concreta sobre <strong>cómo</strong> podría haberse distorsionado el resultado. Recordá: toda persona que trabaja en ciencia es consciente de este problema, y hace lo que puede por compensarlo. Decir simplemente “el estudio solo incluyó personas del grupo TAL” no ayuda en nada, y roza lo insultante para los investigadores, que probablemente sí estaban al tanto del problema, pero no disponían de la infinita cantidad de tiempo y dinero que haría falta para construir la muestra perfecta. En resumen: si querés ofrecer una crítica responsable sobre el muestreo, entonces sé <em>útil</em>. Repetir verdades obvias como las que acabo de presentar en esta sección es inútil.</p>
</section>
<section id="parámetros-poblacionales-y-estadísticas-muestrales" class="level3" data-number="5.8.5">
<h3 data-number="5.8.5" class="anchored" data-anchor-id="parámetros-poblacionales-y-estadísticas-muestrales"><span class="header-section-number">5.8.5</span> Parámetros poblacionales y estadísticas muestrales</h3>
<p>Bien. Dejando de lado los espinosos problemas metodológicos asociados con obtener una muestra aleatoria, consideremos un tema algo distinto. Hasta este punto, venimos hablando de poblaciones como lo haría una persona científica. Para una psicóloga, una población podría ser un grupo de personas. Para una ecóloga, una población podría ser un grupo de osos. En la mayoría de los casos, las poblaciones que interesan a la ciencia son cosas concretas que realmente existen en el mundo.</p>
<p>Los estadísticos, sin embargo, son un grupo curioso. Por un lado, <strong>sí</strong> se interesan en datos reales y en la ciencia, del mismo modo que los científicos. Pero por otro lado, también trabajan en el plano de la abstracción pura, como lo hacen los matemáticos. Como consecuencia, la teoría estadística tiende a definir las poblaciones de forma algo más abstracta. Del mismo modo que los psicólogos convierten ideas teóricas abstractas en mediciones concretas, los estadísticos operacionalizan el concepto de “población” en términos de <strong>objetos matemáticos</strong> con los que saben trabajar. Ya te cruzaste con estos objetos: se llaman <strong>distribuciones de probabilidad</strong> (¿te acordás? el lugar del que vienen los datos).</p>
<p>La idea es muy simple. Supongamos que hablamos de puntuaciones de CI (coeficiente intelectual). Para una psicóloga, la población de interés es un grupo de personas reales que tienen puntajes de CI. Un estadístico “simplifica” eso definiendo operativamente la población como la distribución de probabilidad mostrada en la <a href="#fig-IQdist">Figura&nbsp;<span>5.11</span></a> (panel a).</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/fig-IQdist_982f8c1843c28439fc67177a2d4f5b87">
<div class="cell-output-display">
<div id="fig-IQdist" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="imgs/navarro_img/navIQ_es.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figura&nbsp;5.11: Distribución poblacional de puntuaciones de CI (panel a) y dos muestras extraídas al azar de esa población. En el panel b hay una muestra de 100 observaciones; en el panel c, una muestra de 10.000 observaciones.</figcaption>
</figure>
</div>
</div>
</div>
<p>Los tests de CI están diseñados para que el promedio sea 100, la desviación estándar sea 15, y la distribución de puntajes sea normal. Estos valores se conocen como <strong>parámetros poblacionales</strong>, porque son características de toda la población. Es decir, decimos que la media poblacional ( ) es 100, y la desviación estándar poblacional ( ) es 15.</p>
<p>Ahora supongamos que recolectamos algunos datos. Seleccionamos 100 personas al azar y les administramos un test de CI, lo que nos da una muestra aleatoria simple de la población. La muestra consistiría en una colección de números como esta:</p>
<p><code>106 101 98 80 74 ... 107 72 100</code></p>
<p>Cada uno de estos puntajes de CI fue extraído de una distribución normal con media 100 y desviación estándar 15. Así que, si dibujo un histograma de la muestra, obtengo algo como lo que se muestra en <a href="#fig-IQdist">Figura&nbsp;<span>5.11</span></a> <span class="math inline">\(b\)</span>. Como podés ver, el histograma tiene una forma <strong>aproximadamente</strong> correcta, pero es una aproximación bastante burda de la verdadera distribución poblacional que aparece en <a href="#fig-IQdist">Figura&nbsp;<span>5.11</span></a> <span class="math inline">\(a\)</span>. La media de la muestra está bastante cerca de la media poblacional (100), pero no es idéntica. En este caso, resulta que las personas de la muestra tienen un CI promedio de 98.5, y la desviación estándar de sus puntajes es 15.9. Estas <strong>estadísticas muestrales</strong> son propiedades del conjunto de datos, y aunque son bastante parecidas a los verdaderos valores poblacionales, no son iguales. <strong>En general, las estadísticas muestrales son las cosas que podés calcular a partir de tus datos, y los parámetros poblacionales son las cosas sobre las que querés aprender.</strong> Más adelante en este capítulo vamos a hablar sobre cómo podés estimar los parámetros poblacionales a partir de las estadísticas muestrales, y cómo calcular qué tan confiado podés estar en tus estimaciones. Pero antes de llegar a eso, todavía hay algunas ideas de teoría del muestreo que necesitás conocer.</p>
</section>
</section>
<section id="la-ley-de-los-grandes-números" class="level2" data-number="5.9">
<h2 data-number="5.9" class="anchored" data-anchor-id="la-ley-de-los-grandes-números"><span class="header-section-number">5.9</span> La ley de los grandes números</h2>
<p>En el ejemplo anterior mostramos los resultados de un experimento ficticio sobre CI con un tamaño muestral de <span class="math inline">\(N = 100\)</span>. Los resultados fueron bastante alentadores: la verdadera media poblacional es 100, y la media muestral fue 98.5, una aproximación bastante razonable. En muchos estudios científicos, ese nivel de precisión es perfectamente aceptable, pero en otras situaciones quizás necesitemos ser mucho más precisos. Entonces, si queremos que nuestras estadísticas muestrales se acerquen más a los parámetros poblacionales, ¿qué podemos hacer?</p>
<p>La respuesta obvia es: recolectar más datos. Supongamos que hacemos un experimento mucho más grande, esta vez midiendo el CI de 10.000 personas. Podemos simular los resultados de este experimento usando R y la función <code>rnorm()</code>, que genera números aleatorios extraídos de una distribución normal. Para un experimento con tamaño muestral <span class="math inline">\(n = 10000\)</span>, y una población con media 100 y desviación estándar 15, R puede generar datos simulados de CI así:</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/unnamed-chunk-7_60ff68fec671891936cc25326505f3c4">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>IQ <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> <span class="dv">10000</span>, <span class="at">mean =</span> <span class="dv">100</span>, <span class="at">sd =</span> <span class="dv">15</span>)  <span class="co"># generar los CI</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>IQ <span class="ot">&lt;-</span> <span class="fu">round</span>(IQ)  <span class="co"># redondear a números enteros</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Y listo, ya generamos 10.000 valores de CI simulados. ¿Dónde están esos datos? En la variable <code>IQ</code> de mi computadora. Podés hacer lo mismo en tu propia computadora copiando el código. Ver los 10.000 números sería demasiado, pero podés mirar los primeros 100 así:</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/unnamed-chunk-8_9cc822840c2eb82739902dbfda8e8f36">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(IQ[<span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>])</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  [1]  91  98  85  88  91  69 115 105 100 110 120  90  77  74  92  94 121  79
 [19] 108 104  95  76 106  94  88  99  88 128 104 100 114  95 118  91  92  85
 [37] 112  90 114 122  84 100  89 109  63  82 104 117  89 101 106  86 132 106
 [55] 112  93  66 103  86  93  91 105  99 113  68  95 114 106 128  94  97  93
 [73] 105 109 125 137 106  81  78 111 115  90 101 107 107  77 126 118 123  83
 [91] 114 120  88  90 115  88 106 115 109  92</code></pre>
</div>
</div>
<p>También podés calcular la media con <code>mean(IQ)</code> y la desviación estándar con <code>sd(IQ)</code>, y hacer un histograma con <code>hist()</code>. El histograma de esta muestra mucho más grande se muestra en el panel c de la <a href="#fig-IQdist">Figura&nbsp;<span>5.11</span></a>. Con solo mirarlo, se nota que esta muestra es una mejor aproximación a la distribución poblacional real que la muestra más pequeña. Eso también se ve en las estadísticas muestrales: la media muestral es 99.9 y la desviación estándar es 15.1. Estos valores son ahora cercanos a los valores reales de la población.</p>
<p>Me siento un poco tonta al decir esto, pero lo que quiero que te lleves de todo esto es que las muestras grandes, en general, te dan mejor información. Me siento tonta porque es tan tremendamente obvio que no debería hacer falta decirlo. De hecho, es tan obvio que cuando Jacob Bernoulli —uno de los fundadores de la teoría de la probabilidad— formalizó esta idea allá por 1713, fue medio arrogante al respecto. Así fue como describió el hecho de que todos compartimos esta intuición:</p>
<blockquote class="blockquote">
<p><strong>Pues incluso el más estúpido de los hombres, por algún instinto natural, por sí mismo y sin ninguna instrucción (lo cual es notable), está convencido de que cuantas más observaciones se han hecho, menor es el peligro de desviarse del objetivo</strong> (ver Stigler, 1986, p.&nbsp;65).</p>
</blockquote>
<p>Bueno, el pasaje suena un poco condescendiente (por no decir sexista), pero su punto principal es correcto: realmente parece obvio que más datos te van a dar mejores respuestas. La pregunta es: ¿por qué es así? No sorprende que esta intuición que todos compartimos resulta ser correcta, y los estadísticos se refieren a ella como la <strong>ley de los grandes números</strong>. La ley de los grandes números es una ley matemática que se aplica a muchas estadísticas muestrales, pero la forma más simple de entenderla es como una ley sobre promedios. La media muestral es el ejemplo más obvio de una estadística que se basa en promediar (porque eso es justamente lo que es la media… un promedio), así que vamos a mirar eso. <strong>Aplicada a la media muestral, lo que dice la ley de los grandes números es que a medida que la muestra se hace más grande, la media muestral tiende a acercarse a la media verdadera de la población.</strong> O, dicho de manera un poco más precisa, cuando el tamaño de la muestra “tiende” a infinito (se escribe <span class="math inline">\(N \rightarrow \infty\)</span>), la media muestral se aproxima a la media poblacional (<span class="math inline">\(\bar{X} \rightarrow \mu\)</span>).</p>
<p>No tengo intención de torturarte con una demostración de que la ley de los grandes números es cierta, pero es una de las herramientas más importantes de la teoría estadística. Es lo que podemos usar para justificar nuestra creencia de que, si seguimos recolectando más y más datos, eventualmente vamos a llegar a la verdad. Para un conjunto de datos en particular, las estadísticas muestrales que calculemos estarán equivocadas, pero la ley de los grandes números nos dice que si seguimos recolectando más datos, esas estadísticas tenderán a acercarse cada vez más a los verdaderos parámetros de la población.</p>
</section>
<section id="distribuciones-muestrales-y-el-teorema-central-del-límite" class="level2" data-number="5.10">
<h2 data-number="5.10" class="anchored" data-anchor-id="distribuciones-muestrales-y-el-teorema-central-del-límite"><span class="header-section-number">5.10</span> Distribuciones muestrales y el teorema central del límite</h2>
<p>La ley de los grandes números es una herramienta muy poderosa, pero no alcanza para responder todas nuestras preguntas. Entre otras cosas, lo único que nos ofrece es una “garantía en el largo plazo”. A largo plazo, si de alguna manera pudiéramos recolectar una cantidad infinita de datos, entonces la ley de los grandes números garantiza que nuestras estadísticas muestrales serán correctas. Pero como John Maynard Keynes argumentó con razón en economía, una garantía en el largo plazo tiene poca utilidad en la vida real:</p>
<blockquote class="blockquote">
<p>[**El] largo plazo es una guía engañosa para los asuntos actuales. A largo plazo, todos estaremos muertos. Los economistas se asignan una tarea demasiado fácil, y por lo tanto inútil, si en tiempos tormentosos sólo pueden decirnos que, cuando la tormenta haya pasado hace tiempo, el océano volverá a estar calmo.** — <span class="citation" data-cites="Keynes1923">Keynes (<a href="references.html#ref-Keynes1923" role="doc-biblioref">1923, 80</a>)</span></p>
</blockquote>
<p>Lo mismo que en economía vale también para la psicología y la estadística. No basta con saber que <strong>eventualmente</strong> llegaremos a la respuesta correcta al calcular la media muestral. Saber que un conjunto de datos infinitamente grande nos dará el valor correcto no resuelve nuestros problemas prácticos en el presente. Saber que un conjunto de datos infinitamente grande me dará el valor exacto de la media poblacional no es precisamente reconfortante cuando mi conjunto de datos <strong>real</strong> tiene un tamaño de muestra de <span class="math inline">\(N=100\)</span>. En la vida real, entonces, necesitamos saber algo sobre el comportamiento de la media muestral cuando se calcula a partir de un conjunto de datos más modesto.</p>
<section id="distribución-muestral-de-las-medias-muestrales" class="level3" data-number="5.10.1">
<h3 data-number="5.10.1" class="anchored" data-anchor-id="distribución-muestral-de-las-medias-muestrales"><span class="header-section-number">5.10.1</span> Distribución muestral de las medias muestrales</h3>
<p>“Oh no, ¿qué es la distribución muestral de las medias muestrales? ¿Eso siquiera se puede decir en español?”. Sí, lamentablemente, se puede. La <strong>distribución muestral de las medias muestrales</strong> es la próxima cosa más importante que vas a tener que entender. ES TAN IMPORTANTE QUE ES NECESARIO ESCRIBIRLO TODO EN MAYÚSCULAS. Solo resulta confuso al principio porque es largo y usa muestreo y muestra en la misma frase.</p>
<p>No te preocupes, ya te venimos preparando para esto. Sabés lo que es una distribución, ¿no? Es de donde salen los números. Determina qué números ocurren más o menos seguido, o con la misma frecuencia. Y también sabés qué es una muestra, ¿no? Es un conjunto de números que tomamos de una distribución. Entonces, ¿qué sería la distribución muestral de las medias muestrales?</p>
<p>Primero: ¿a qué nos referimos con medias muestrales? Bueno, si tomás una muestra de números, tenés un conjunto de valores… y podés calcular la media de esos valores. Eso es la media muestral. Simple.</p>
<p>Ahora bien, ¿qué es esa distribución de la que hablamos? Imaginá que tomás muchas muestras distintas: una por acá, otra por allá, muchas más. Tenés un montón de muestras distintas de números. De cada muestra, podés calcular su media. Y entonces tenés muchas medias. ¿Cómo se ven esas medias? Si las ponés en un histograma, lo vas a saber. Y eso que estarías viendo —más o menos— es una distribución: la <strong>distribución muestral de las medias muestrales</strong>.</p>
<p>“Más o menos te sigo… pero, ¿por qué haría esto en vez de mirar Netflix…?” Porque la distribución muestral de las medias te da una nueva manera de entender el azar. Una que podés manejar, igual que manejás el control remoto, si apretás los botones de diseño adecuados.</p>
</section>
<section id="viendo-las-partes" class="level3" data-number="5.10.2">
<h3 data-number="5.10.2" class="anchored" data-anchor-id="viendo-las-partes"><span class="header-section-number">5.10.2</span> Viendo las partes</h3>
<p>Para construir una distribución muestral de medias muestrales, solo necesitamos lo siguiente:</p>
<ol type="1">
<li>Una distribución de donde tomar los números</li>
<li>Un montón de muestras diferentes extraídas de esa distribución</li>
<li>La media de cada una de esas muestras</li>
<li>Juntar todas esas medias muestrales y graficarlas en un histograma</li>
</ol>
<hr>
<p><strong>Pregunta para vos:</strong> ¿Cómo pensás que se va a ver la distribución muestral de las medias? ¿Va a tener la misma forma que la distribución original de la que salieron las muestras? ¿O no? Buena pregunta, pensalo.</p>
<hr>
<p>Hagamos esas cuatro cosas. Vamos a tomar números de una distribución uniforme. La <a href="#fig-4Unif">Figura&nbsp;<span>5.12</span></a> muestra la distribución uniforme usada para muestrear números enteros del 1 al 10:</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/fig-4Unif_e6359e5845410b48bb0dbf87c429cae2">
<div class="cell-output-display">
<div id="fig-4Unif" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="04-SamplesPopulations_files/figure-html/fig-4Unif-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figura&nbsp;5.12: Ilustración de las probabilidades de muestreo para los números del 1 al 10. En una distribución uniforme, todos los números tienen igual probabilidad, así que la línea es plana, indicando que todos tienen la misma chance.</figcaption>
</figure>
</div>
</div>
</div>
<p>La <a href="#fig-4sample20unif">Figura&nbsp;<span>5.13</span></a> anima el proceso de tomar un montón de muestras de la distribución uniforme. Vamos a fijar el tamaño de muestra en 20. Es más fácil ver cómo se comporta la media muestral en una animación. Cada histograma muestra una nueva muestra. La línea roja indica dónde está la media de esa muestra. Las muestras son todas bastante distintas entre sí, pero la línea roja no se mueve mucho: siempre queda más o menos cerca del centro. Sin embargo, sí se mueve un poco, y esa variabilidad es lo que llamamos la <strong>distribución muestral de la media muestral</strong>.</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/fig-4sample20unif_b568e9b60113c4f0289db5df39d791aa">
<div class="cell-output-display">
<div id="fig-4sample20unif" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="imgs/gifs/sampleHistUnif-1_es.gif" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figura&nbsp;5.13: Animación que muestra histogramas para diferentes muestras de tamaño 20 tomadas de la distribución uniforme. La línea roja indica la media de cada muestra.</figcaption>
</figure>
</div>
</div>
</div>
<p>OK, ¿qué tenemos acá? Tenemos una animación de 10 muestras diferentes. Cada muestra tiene 20 observaciones, que están resumidas en los histogramas que aparecen en la animación. Cada histograma tiene una línea roja. Esa línea roja muestra dónde está ubicada la media de esa muestra. Así que hemos calculado las medias muestrales de 10 muestras distintas tomadas de una distribución uniforme.</p>
<p>Primera pregunta: ¿Las medias muestrales son todas iguales? La respuesta es no. Aunque son todas más o menos parecidas, están todas alrededor de cinco, más o menos un par de números. Esto es interesante. Aunque nuestras muestras se ven bastante diferentes entre sí, las medias de esas muestras se ven más similares que distintas.</p>
<p>Segunda pregunta: ¿Qué deberíamos hacer con las medias de nuestras muestras? Bueno, ¿qué tal si las juntamos todas y graficamos un histograma de ellas? Eso nos permitiría ver cómo se ve la distribución de las medias muestrales. El próximo histograma muestra exactamente eso. Solo que, en lugar de tomar 10 muestras, vamos a tomar 10.000. Y para cada una vamos a calcular su media. Así que vamos a tener 10.000 medias muestrales. La figura <a href="#fig-4unifmany">Figura&nbsp;<span>5.14</span></a> muestra ese histograma:</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/fig-4unifmany_87b0380428b2f9c8819dbbe1125bf6ba">
<div class="cell-output cell-output-stderr">
<pre><code>`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
</div>
<div class="cell-output-display">
<div id="fig-4unifmany" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="04-SamplesPopulations_files/figure-html/fig-4unifmany-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figura&nbsp;5.14: Histograma de las medias muestrales de 10.000 muestras, cada una de tamaño 20, tomadas de una distribución uniforme de números del 1 al 10. La media esperada es 5.5, y el histograma está centrado en 5.5. La media de cada muestra no es siempre 5.5, debido al error muestral o al azar.</figcaption>
</figure>
</div>
</div>
</div>
<p>“Pará, ¿qué? Esto no tiene sentido. Pensé que estábamos tomando muestras de una distribución uniforme. Las distribuciones uniformes son planas. ESTO NO SE PARECE A UNA DISTRIBUCIÓN PLANA, ¿QUÉ ESTÁ PASANDO, AAAAAGGGHH.” Te entendemos. Te juro que sí.</p>
<p>Recordá que estamos mirando la distribución de las medias muestrales. Y sí, es cierto que esta distribución no se parece a la distribución original de la que tomamos las muestras. Nuestra distribución de medias muestrales sube y baja. De hecho, esto es lo que ocurre casi siempre con las distribuciones de medias muestrales. Este hecho se conoce como el <strong>teorema central del límite</strong>, del que hablaremos más adelante.</p>
<p>Por ahora, hablemos de lo que está pasando. Recordá que hemos estado muestreando números entre 1 y 10. Se supone que cada número debería aparecer con aproximadamente la misma frecuencia, porque estamos usando una distribución uniforme. Entonces, supongamos que tomamos una muestra de 10 números, y por casualidad obtuvimos uno de cada uno del 1 al 10:</p>
<p><code>1 2 3 4 5 6 7 8 9 10</code></p>
<p>¿Cuál es la media de esos números? Bueno, es 1+2+3+4+5+6+7+8+9+10 = 55, y 55 / 10 = 5.5. Imaginá que tomamos una muestra más grande, digamos de 20 números, y de nuevo obtenemos exactamente 2 de cada número. ¿Cuál sería la media? Sería (1+2+3+4+5+6+7+8+9+10)×2 = 110, y 110 / 20 = 5.5. Sigue siendo 5.5.</p>
<p>Podés ver que el valor medio de nuestra distribución uniforme es 5.5. Ahora que sabemos esto, podríamos esperar que la mayoría de nuestras muestras tengan una media cercana a ese número. Ya sabemos que ninguna muestra va a ser perfecta, y no va a tener exactamente la misma cantidad de cada número. Así que esperamos que la media de nuestras muestras varíe un poco. El histograma que hicimos muestra justamente esa variación. Como era de esperar, los valores se agrupan en torno al 5.5.</p>
</section>
<section id="las-distribuciones-muestrales-existen-para-cualquier-estadístico-muestral" class="level3" data-number="5.10.3">
<h3 data-number="5.10.3" class="anchored" data-anchor-id="las-distribuciones-muestrales-existen-para-cualquier-estadístico-muestral"><span class="header-section-number">5.10.3</span> ¡Las distribuciones muestrales existen para cualquier estadístico muestral!</h3>
<p>Algo importante a tener en cuenta cuando hablamos de distribuciones muestrales es que <strong>cualquier</strong> estadístico muestral que quieras calcular tiene su propia distribución muestral. Por ejemplo, supongamos que cada vez que tomás una muestra de números, anotás el valor más alto de esa muestra. Si repetís esto muchas veces, vas a obtener una distribución muestral completamente distinta: la <strong>distribución muestral del máximo</strong>. Podrías calcular el número más pequeño, o la moda, o la mediana, o la varianza, o el desvío estándar, o cualquier otra cosa a partir de tu muestra. Luego podrías repetir ese procedimiento muchas veces y obtener la distribución muestral de esos estadísticos. ¡Qué genial!</p>
<p>Solo por diversión, acá van algunas distribuciones muestrales para distintos estadísticos. Vamos a tomar una distribución normal con media = 100 y desvío estándar = 20. Luego tomamos muchas muestras de tamaño n = 50 (50 observaciones por muestra). Guardamos todos los estadísticos muestrales y graficamos sus histogramas en la figura <a href="#fig-4samplestats">Figura&nbsp;<span>5.15</span></a>. Hagámoslo:</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/fig-4samplestats_db86956ee5a3d3d454048de930a9c536">
<div class="cell-output cell-output-stderr">
<pre><code>`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
</div>
<div class="cell-output-display">
<div id="fig-4samplestats" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="04-SamplesPopulations_files/figure-html/fig-4samplestats-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figura&nbsp;5.15: Cada panel muestra un histograma de un estadístico muestral distinto</figcaption>
</figure>
</div>
</div>
</div>
<p>Acabamos de calcular 4 distribuciones muestrales diferentes: para la media, el desvío estándar, el valor máximo y la mediana. Si mirás rápido los histogramas, podrías pensar que todos se ven más o menos iguales. Pero esperá un segundo. Es muy importante mirar los ejes x. Son diferentes. Por ejemplo, la media muestral va aproximadamente de 90 a 110, mientras que el desvío estándar va de 15 a 25.</p>
<p>Estas distribuciones muestrales son súper importantes, y vale la pena pensarlas bien. ¿En qué deberías pensar? Bueno, acá va una pista: estas distribuciones te están diciendo qué podés esperar de tu muestra. Y lo más importante: te están diciendo qué deberías esperar cuando tomás una muestra de una distribución específica, en este caso, una distribución normal con media 100 y desvío estándar 20. ¿Qué aprendimos? Aprendimos muchísimo. Aprendimos que podemos esperar que nuestra muestra tenga una media más o menos entre 90 y 108. Notá que las medias muestrales nunca son más extremas que eso. Aprendimos que nuestras muestras normalmente van a tener cierta variabilidad, y que el desvío estándar va a estar entre 15 y 25 (nunca mucho más allá). También vemos que, a veces, obtenemos valores grandes —digamos entre 120 y 180— pero no mucho más que eso. Y que la mediana es bastante similar a la media. Entonces, si alguna vez tomás una muestra de 50 números y tus estadísticas descriptivas caen dentro de esos rangos, es razonable suponer que esa muestra podría venir de una distribución como esta. Pero si tus estadísticas son muy distintas, es probable que no vengan de esta distribución. Usando simulaciones, podemos ver cómo se ven las muestras cuando provienen de ciertas distribuciones, y usar esa información para hacer inferencias sobre si nuestra muestra proviene o no de una distribución en particular.</p>
</section>
<section id="el-teorema-central-del-límite" class="level3" data-number="5.10.4">
<h3 data-number="5.10.4" class="anchored" data-anchor-id="el-teorema-central-del-límite"><span class="header-section-number">5.10.4</span> El teorema central del límite</h3>
<p>Bien, ya viste muchas distribuciones muestrales y sabés qué es la distribución muestral de la media. Acá nos vamos a enfocar en cómo cambia la distribución muestral de la media en función del tamaño de la muestra.</p>
<p>Intuitivamente, ya conocés parte de la respuesta: si tenés pocas observaciones, es probable que la media muestral sea bastante imprecisa (ya viste que puede variar bastante); si repetís un experimento chico y volvés a calcular la media, vas a obtener un resultado bastante distinto. En otras palabras, la distribución muestral es bastante amplia. En cambio, si repetís un experimento grande y calculás de nuevo la media muestral, probablemente obtengas un valor muy parecido al anterior, así que la distribución muestral va a ser mucho más estrecha.</p>
<p>Veamos ahora una linda animación para ver todo esto en acción. Vamos a tomar muestras de una distribución normal. La figura <a href="#fig-4samplingmean">Figura&nbsp;<span>5.16</span></a> tiene cuatro paneles, cada uno representando un tamaño de muestra distinto (n): 10, 50, 100 y 1000. La línea roja muestra la forma de la distribución normal. Las barras grises muestran un histograma de cada una de las muestras que tomamos. La línea roja muestra la media de una muestra individual (es decir, el centro del histograma en gris). Como podés ver, la línea roja se mueve bastante, especialmente cuando el tamaño de la muestra es pequeño (10).</p>
<p>Lo nuevo acá son las barras azules y las líneas azules. Las barras azules representan la <strong>distribución muestral de la media muestral</strong>. Por ejemplo, en el panel con tamaño de muestra 10, vemos un montón de barras azules: es un histograma de 10 medias muestrales, cada una calculada a partir de una muestra de tamaño 10. En el panel de n = 50, vemos un histograma de 50 medias muestrales, tomadas de 50 muestras de tamaño 50, y así sucesivamente. La línea azul en cada panel es la media de esas medias muestrales (“¡aaaaagh, es una media de medias!”; sí, lo es).</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/fig-4samplingmean_9d47c823d2822e4b9940bf5e9bda4ca2">
<div class="cell-output-display">
<div id="fig-4samplingmean" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="imgs/gifs/sampleDistNormal-1_es.gif" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figura&nbsp;5.16: Animación de muestras (el histograma gris muestra la frecuencia de los datos en cada muestra) y de la distribución muestral de la media (histograma azul de medias muestrales de muchas muestras). Cada muestra proviene de la distribución normal mostrada en rojo. La línea roja móvil es la media de una muestra individual. La línea azul es la media del histograma azul, que representa la distribución muestral de la media para muchas muestras.</figcaption>
</figure>
</div>
</div>
</div>
<p>¿Qué deberías notar? Fijate que el rango de las barras azules se reduce a medida que el tamaño de muestra aumenta. La distribución muestral de la media es bastante ancha cuando el tamaño de muestra es 10, se estrecha al aumentar a 50 y 100, y es prácticamente una sola barra en el centro cuando el tamaño llega a 1000. Lo que estamos viendo es que la media de la distribución muestral se aproxima a la media poblacional a medida que crece el tamaño de la muestra.</p>
<p>Entonces, la distribución muestral de la media es otra distribución, y tiene cierta varianza. Varía más cuando el tamaño de muestra es pequeño, y varía menos cuando el tamaño es grande. Podemos cuantificar este efecto calculando el <strong>desvío estándar</strong> de la distribución muestral, que se conoce como el <strong>error estándar</strong>. El error estándar de un estadístico suele abreviarse como <em>SE</em>, y como habitualmente nos interesa el error estándar de la <strong>media</strong> muestral, usamos la sigla SEM (standard error of the mean). Como podés ver claramente en la animación, a medida que el tamaño de muestra <span class="math inline">\(N\)</span> aumenta, el SEM disminuye.</p>
<p>Bueno, eso es una parte de la historia. Sin embargo, hay algo que hemos estado dejando un poco de lado. Ya lo vimos antes, pero vale la pena volver a observarlo. Acá va el punto clave: <strong>no importa qué forma tenga tu distribución poblacional</strong>, a medida que <span class="math inline">\(N\)</span> aumenta, la distribución muestral de la media empieza a parecerse más y más a una distribución normal. Eso es el <strong>teorema central del límite</strong>.</p>
<p>Para ver el teorema central del límite en acción, vamos a mirar algunos histogramas de medias muestrales provenientes de diferentes tipos de distribuciones. Es muy importante recordar que lo que estás viendo son distribuciones de medias muestrales, no distribuciones de valores individuales.</p>
<p>Empecemos. La figura <span class="quarto-unresolved-ref">?fig-4sampledistmeannorm</span> muestra un muestreo a partir de una distribución normal. La línea roja es la distribución normal de la que se extraen las muestras. Para cada muestra se calcula la media, y la distribución de esas medias se muestra con las barras azules. Notá que la forma de la línea roja y de las barras azules es similar: ambas se ven como una distribución normal.</p>
<p>Hagámoslo de nuevo. Esta vez vamos a tomar muestras de una distribución uniforme plana, representada por la línea roja. Sin embargo, la <a href="#fig-4samplemeanunif">Figura&nbsp;<span>5.17</span></a> muestra que la distribución de las medias muestrales, representada por las barras azules, no es plana: se parece a una distribución normal.</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/fig-4samplemeanunif_45a70f769dbb39ccb9ccb868003b0e90">
<div class="cell-output cell-output-stderr">
<pre><code>Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.
ℹ Please use `after_stat(density)` instead.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Removed 4 rows containing missing values or values outside the scale range
(`geom_bar()`).</code></pre>
</div>
<div class="cell-output-display">
<div id="fig-4samplemeanunif" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="04-SamplesPopulations_files/figure-html/fig-4samplemeanunif-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figura&nbsp;5.17: Ilustración de que la forma de la distribución muestral de la media es normal, incluso cuando las muestras provienen de una distribución no normal (en este caso, uniforme)</figcaption>
</figure>
</div>
</div>
</div>
<p>Una vez más, ahora con una distribución exponencial (mostrada en rojo), donde es más probable que se muestren valores pequeños que grandes. Aunque muchos más números en cada muestra serán pequeños en comparación con los grandes, según la <a href="#fig-4samplemeanExp">Figura&nbsp;<span>5.18</span></a>, la distribución muestral de la media no se parece a la línea roja. En cambio, la distribución muestral de la media se parece a una curva en forma de campana: una distribución normal. Esto es el teorema central del límite en acción.</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/fig-4samplemeanExp_98bb4e0854cf455520e95b1a8a190e04">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Función para obtener medias muestrales a partir de una distribución exponencial</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>get_sampling_means <span class="ot">&lt;-</span> <span class="cf">function</span>(s_size, r, iter) {</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>  save_means <span class="ot">&lt;-</span> <span class="fu">length</span>(iter)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>iter) {</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    save_means[i] <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">rexp</span>(s_size, r))</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(save_means)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>all_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>()</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>sims <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Tamaños de muestra: 10 y 50</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (n <span class="cf">in</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">50</span>)) {</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>  sample <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, <span class="dv">1</span>)  <span class="co"># Nota: como antes, sample no se usa luego</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>  sample_means <span class="ot">&lt;-</span> <span class="fu">get_sampling_means</span>(n, <span class="dv">2</span>, <span class="dv">1000</span>)</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>  t_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">sims =</span> <span class="fu">rep</span>(sims, <span class="dv">1000</span>),</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>    sample,</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>    sample_means,</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">sample_size =</span> <span class="fu">rep</span>(n, <span class="dv">1000</span>),</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">sample_mean =</span> <span class="fu">rep</span>(<span class="fu">mean</span>(sample), <span class="dv">1000</span>),</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">sampling_mean =</span> <span class="fu">rep</span>(<span class="fu">mean</span>(sample_means), <span class="dv">1000</span>)</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>  all_df <span class="ot">&lt;-</span> <span class="fu">rbind</span>(all_df, t_df)</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(all_df, <span class="fu">aes</span>(<span class="at">x =</span> sample)) <span class="sc">+</span></span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(</span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">x =</span> sample_means, <span class="at">y =</span> (..density..) <span class="sc">/</span> <span class="fu">max</span>(..density..)),</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"blue"</span>, <span class="at">color =</span> <span class="st">"white"</span>, <span class="at">alpha =</span> .<span class="dv">5</span>, <span class="at">bins =</span> <span class="dv">75</span></span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dexp,</span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>                <span class="at">args =</span> <span class="fu">list</span>(<span class="at">rate =</span> <span class="dv">2</span>),</span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>                <span class="at">lwd =</span> .<span class="dv">75</span>,</span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>                <span class="at">col =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>sample_size) <span class="sc">+</span></span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="dv">0</span>, <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>() <span class="sc">+</span></span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Distribución muestral de la media</span><span class="sc">\n</span><span class="st"> para muestras tomadas de una distribución exponencial"</span>) <span class="sc">+</span></span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Verosimilitudes aproximadas"</span>) <span class="sc">+</span></span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"valor"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Removed 3 rows containing non-finite outside the scale range
(`stat_bin()`).</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Removed 4 rows containing missing values or values outside the scale range
(`geom_bar()`).</code></pre>
</div>
<div class="cell-output-display">
<div id="fig-4samplemeanExp" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="04-SamplesPopulations_files/figure-html/fig-4samplemeanExp-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figura&nbsp;5.18: Ilustración de que la forma de la distribución muestral de la media es normal, incluso cuando las muestras provienen de una distribución exponencial</figcaption>
</figure>
</div>
</div>
</div>
<p>A partir de estas figuras, parece que tenemos evidencia para las siguientes afirmaciones sobre la distribución muestral de la media:</p>
<ul>
<li><p>La media de la distribución muestral es igual a la media de la población</p></li>
<li><p>El desvío estándar de la distribución muestral (es decir, el error estándar) se reduce a medida que aumenta el tamaño de la muestra</p></li>
<li><p>La forma de la distribución muestral se vuelve normal a medida que aumenta el tamaño de la muestra</p></li>
</ul>
<p>Y resulta que no solo estas afirmaciones son verdaderas: hay un teorema muy famoso en estadística que las demuestra a las tres, conocido como el <strong>teorema central del límite</strong>. Entre otras cosas, este teorema nos dice que si la distribución poblacional tiene media <span class="math inline">\(\mu\)</span> y desvío estándar <span class="math inline">\(\sigma\)</span>, entonces la distribución muestral de la media también tiene media <span class="math inline">\(\mu\)</span>, y su error estándar es:</p>
<p><span class="math display">\[
\text{SEM} = \frac{\sigma}{\sqrt{N}}
\]</span></p>
<p>Como se divide el desvío estándar poblacional <span class="math inline">\(\sigma\)</span> por la raíz cuadrada del tamaño muestral <span class="math inline">\(N\)</span>, el SEM disminuye al aumentar el tamaño de la muestra. También nos dice que la forma de la distribución muestral <strong>tiende a ser normal</strong>.</p>
<p>Este resultado es útil para todo tipo de cosas. Nos explica por qué los experimentos grandes son más confiables que los pequeños, y como nos da una fórmula explícita para el error estándar, también nos dice <strong>cuánto</strong> más confiables son. También nos explica por qué la distribución normal es, bueno… <strong>normal</strong>. En los experimentos reales, muchas de las cosas que queremos medir son en realidad <strong>promedios</strong> de un montón de cantidades diferentes (por ejemplo, uno podría decir que la inteligencia “general” medida por el CI es un promedio de muchas habilidades y aptitudes “específicas”), y cuando eso pasa, el valor promedio tiende a seguir una distribución normal. Por esta ley matemática, la distribución normal aparece una y otra vez en los datos reales.</p>
</section>
</section>
<section id="puntajes-z" class="level2" data-number="5.11">
<h2 data-number="5.11" class="anchored" data-anchor-id="puntajes-z"><span class="header-section-number">5.11</span> Puntajes z</h2>
<p>Ahora estamos en condiciones de combinar algunas de las cosas que vimos en este capítulo, e introducirte a una nueva herramienta: los <strong>puntajes z</strong>. Realmente que no vamos a usar mucho los <strong>puntajes z</strong> en este libro. Sin embargo, no podés hacer un curso de estadística sin aprender sobre los <strong>puntajes z</strong>.</p>
<p>Vamos a observar una distribución normal en la <a href="#fig-4normalSDspercents">Figura&nbsp;<span>5.19</span></a>, y vamos a trazar líneas en la distribución en 0, ±1, ±2 y ±3 desviaciones estándar desde la media:</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/fig-4normalSDspercents_87098c52e8f89ef4a89268a329bbc7ce">
<div class="cell-output-display">
<div id="fig-4normalSDspercents" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="04-SamplesPopulations_files/figure-html/fig-4normalSDspercents-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figura&nbsp;5.19: Una distribución normal. Cada línea representa una desviación estándar desde la media. Las etiquetas muestran la proporción de puntajes que caen entre cada barra.</figcaption>
</figure>
</div>
</div>
</div>
<p>La figura muestra una distribución normal con media = 0 y desvío estándar = 1. Trazamos líneas en cada desviación estándar: -3, -2, -1, 0, 1, 2 y 3. También mostramos algunos números en las etiquetas entre cada línea. Esos números son proporciones. Por ejemplo, vemos que la proporción entre 0 y 1 es 0.341: es decir, los puntajes entre 0 y 1 ocurren el 34.1% del tiempo. Los puntajes entre -1 y 1 ocurren el 68.2% del tiempo, lo cual es más de la mitad. Los puntajes entre 1 y 2 ocurren aproximadamente el 13.6% del tiempo, y los que están entre 2 y 3 ocurren aún menos: solo el 2.1%.</p>
<p>Las distribuciones normales <strong>siempre</strong> tienen estas propiedades, incluso cuando tienen distintas medias y desviaciones estándar. Por ejemplo, mirá la distribución normal en la <a href="#fig-4normalSDspercentsB">Figura&nbsp;<span>5.20</span></a>, que tiene media = 100 y desvío estándar = 25.</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/fig-4normalSDspercentsB_dad8a8ee31f21fab8a61d89a96cf4142">
<div class="cell-output-display">
<div id="fig-4normalSDspercentsB" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="04-SamplesPopulations_files/figure-html/fig-4normalSDspercentsB-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figura&nbsp;5.20: Una distribución normal. Cada línea representa una desviación estándar desde la media. Las etiquetas muestran la proporción de puntajes que caen entre cada barra.</figcaption>
</figure>
</div>
</div>
</div>
<p>Ahora estamos viendo una distribución normal con media = 100 y desvío estándar = 25. Fijate que la región entre 100 y 125 contiene el 34.1% de los puntajes. Esta región está a 1 desviación estándar de la media (la desviación estándar es 25, la media es 100, así que 125 está a una desviación estándar completa de 100). Como podés ver, las mismas proporciones aparecen entre cada una de las desviaciones estándar, tal como ocurría cuando la desviación estándar era 1 y la media era 0.</p>
<section id="la-idea-detrás-de-los-puntajes-z" class="level3" data-number="5.11.1">
<h3 data-number="5.11.1" class="anchored" data-anchor-id="la-idea-detrás-de-los-puntajes-z"><span class="header-section-number">5.11.1</span> La idea detrás de los puntajes z</h3>
<p>A veces puede ser útil transformar tus puntajes originales a otros que sean más fáciles de manejar. Por ejemplo, si tenés un montón de proporciones como .3, .5, .6, .7, podrías querer convertirlas en porcentajes: 30%, 50%, 60%, 70%. Para eso, multiplicás las proporciones por una constante, 100. Si querés volver de porcentajes a proporciones, simplemente dividís por 100. Este tipo de transformación simplemente cambia la escala de los números (de 0–1 a 0–100), pero no cambia el patrón de los datos.</p>
<p>La idea detrás de los puntajes z es un tipo de transformación similar. La idea es expresar cada puntaje original (o bruto) en función de su desviación estándar. Por ejemplo, si te digo que saqué un 75% en una prueba, no sabrías qué tan bien me fue comparado con el resto de la clase. Pero si te digo que obtuve una puntuación 2 desviaciones estándar por encima de la media, sí sabrías que me fue bastante bien, porque sabés que la mayoría de los puntajes (si están distribuidos normalmente) quedan por debajo de 2 desviaciones estándar de la media.</p>
<p>Ahora también sabemos, gracias al teorema central del límite, que muchas de nuestras medidas —como las medias muestrales— se distribuyen normalmente. Por eso, muchas veces conviene expresar los puntajes brutos en términos de sus desviaciones estándar.</p>
<p>Veamos cómo se ve esto en una tabla, sin fórmulas. Vamos a considerar puntajes que provienen de una distribución normal con media = 100 y desviación estándar = 25. Vamos a listar algunos puntajes originales junto con sus correspondientes puntajes z:</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/unnamed-chunk-9_d550e02de73028ecb21d1eb7c24434fd">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>original <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="dv">50</span>, <span class="dv">75</span>, <span class="dv">100</span>, <span class="dv">125</span>, <span class="dv">150</span>, <span class="dv">175</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>z   <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(original, z)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(df)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: right;">original</th>
<th style="text-align: right;">z</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">25</td>
<td style="text-align: right;">-3</td>
</tr>
<tr class="even">
<td style="text-align: right;">50</td>
<td style="text-align: right;">-2</td>
</tr>
<tr class="odd">
<td style="text-align: right;">75</td>
<td style="text-align: right;">-1</td>
</tr>
<tr class="even">
<td style="text-align: right;">100</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: right;">125</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="even">
<td style="text-align: right;">150</td>
<td style="text-align: right;">2</td>
</tr>
<tr class="odd">
<td style="text-align: right;">175</td>
<td style="text-align: right;">3</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Recordá: la media es 100 y el desvío estándar es 25. ¿Cuántas desviaciones estándar está un puntaje de 100 por encima o por debajo de la media? Cero. Está justo en la media. Por eso, el puntaje z de 100 es 0. ¿Y el puntaje 125? Está exactamente 25 unidades por encima de 100, o sea, a una desviación estándar de distancia, por eso el puntaje z para 125 es es 1. El puntaje z para 150 es 2, 150 está “dos veces 25” por encima de 100. El puntaje z para 50 es -2, porque 50 está a “dos veces 25” de distancia de 100, pero en la dirección opuesta. Todo lo que estamos haciendo es reexpresar los puntajes brutos en función de cuántas desviaciones estándar están alejados de la media. Y como siempre, la media está justo en el centro: el centro de la distribución de puntajes z es siempre 0.</p>
</section>
<section id="cómo-calcular-puntajes-z" class="level3" data-number="5.11.2">
<h3 data-number="5.11.2" class="anchored" data-anchor-id="cómo-calcular-puntajes-z"><span class="header-section-number">5.11.2</span> Cómo calcular puntajes z</h3>
<p>Para calcular puntajes z, lo único que tenés que hacer es averiguar cuántas desviaciones estándar se encuentra cada número con respecto a la media. Supongamos que la media es 100 y la desviación estándar es 25. Tenés un puntaje de 97. ¿A cuántas desviaciones estándar está 97 de la media?</p>
<p>Primero, calculamos la diferencia entre el puntaje y la media:</p>
<p><span class="math display">\[
97 - 100 = -3
\]</span></p>
<p>Bien, tenemos una diferencia total de -3. ¿Cuántas desviaciones estándar representa ese -3, si una desviación estándar es 25? Claramente -3 es mucho menor que 25, así que va a ser mucho menos de 1 desviación estándar. Para saber cuánto, simplemente dividimos -3 por la desviación estándar:</p>
<p><span class="math display">\[
\frac{-3}{25} = -0.12
\]</span></p>
<p>Nuestro puntaje z para 97 es -0.12.</p>
<p>La fórmula general es:</p>
<p><span class="math display">\[
z = \frac{\text{puntaje bruto} - \text{media}}{\text{desvío estándar}}
\]</span></p>
<p>Por ejemplo, si tenemos estos 10 puntajes tomados de una distribución normal con media = 100 y desvío estándar = 25:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>scores <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">25</span>), <span class="at">digits =</span> <span class="dv">2</span>)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(scores)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Los puntajes z correspondientes serían:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>(scores <span class="sc">-</span> <span class="dv">100</span>) <span class="sc">/</span> <span class="dv">25</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Una vez que tenés los puntajes z, podés usarlos como una forma alternativa de describir tus datos. Por ejemplo, ahora con solo mirar un puntaje sabés si es más o menos probable que ocurra, porque ya conocés cómo funciona el área bajo la curva normal. Puntajes z entre -1 y 1 ocurren bastante seguido; mayores que ±1 todavía ocurren, pero con menos frecuencia; y los que superan ±2 son bastante poco comunes. Esta es una forma práctica de mirar tus números y tener una idea general de qué tan seguido ocurren.</p>
<p>En general, no conocés la media ni el desvío estándar de la población de la que provienen tus datos. Por eso, podés usar la <strong>media y el desvío estándar de tu muestra</strong> como estimaciones, y usarlos para calcular los puntajes z.</p>
<p>Finalmente, los puntajes z también se llaman <strong>puntajes estandarizados</strong>, porque cada puntaje bruto se expresa en términos de cuántas desviaciones estándar se encuentra respecto de la media. Es muy probable que esta sea la última vez que hablemos de puntajes z en este libro. Y podrías preguntarte por qué nos molestamos en explicarlos. Primero, porque vale la pena saber que existen. Segundo, porque se vuelven importantes a medida que tu conocimiento estadístico se vuelve más avanzado. Tercero, porque algunos conceptos estadísticos —como la correlación— pueden expresarse en términos de puntajes z, y eso ilumina aspectos de esos estadísticos. Y por último, porque los puntajes z son muy útiles cuando estás trabajando con una distribución normal cuya media y desviación estándar son conocidas.</p>
</section>
</section>
<section id="estimación-de-parámetros-poblacionales" class="level2" data-number="5.12">
<h2 data-number="5.12" class="anchored" data-anchor-id="estimación-de-parámetros-poblacionales"><span class="header-section-number">5.12</span> Estimación de parámetros poblacionales</h2>
<p>Paremos un momento para ubicarnos. Estamos por meternos en el tema de la <strong>estimación</strong>. ¿Qué es eso, y por qué debería importarte? Primero: los <strong>parámetros poblacionales</strong> son cosas que describen una distribución. Por ejemplo, las distribuciones tienen medias. La media es un parámetro de la distribución. La desviación estándar también es un parámetro. Cualquier cosa que describa una distribución es un posible parámetro.</p>
<p>OK, ¿y por qué importa? Buena pregunta. Hay razones concretas para que te importe. Y también hay muy buenas razones abstractas. Desafortunadamente, en investigación, casi siempre son las razones abstractas las que más importan —y también las más difíciles de entender al principio.</p>
<section id="parámetros-poblacionales-concretos" class="level3" data-number="5.12.1">
<h3 data-number="5.12.1" class="anchored" data-anchor-id="parámetros-poblacionales-concretos"><span class="header-section-number">5.12.1</span> Parámetros poblacionales concretos</h3>
<p>Primero, algunas razones concretas. Existen poblaciones reales ahí afuera, y a veces queremos conocer sus parámetros. Por ejemplo, si sos una empresa que fabrica calzado, te interesaría conocer los parámetros poblacionales del <strong>tamaño de los pies</strong>. Como primera aproximación, querrías saber la media y la desviación estándar de la población. Si tu empresa conoce esto, y otras no, probablemente te vaya mejor (asumiendo que todas fabrican zapatos de calidad similar). ¿Por qué te iría mejor y cómo podrías usar esos parámetros? Acá va una buena razón: como empresa, querés que la oferta coincida con la demanda. Si fabricás demasiados zapatos de talles muy chicos o muy grandes, y no hay suficientes personas que los compren, estás haciendo un montón de calzado que no se va a vender. Y si no fabricás suficientes zapatos de los talles más comunes, vas a estar dejando plata sobre la mesa. ¿Verdad? Sí. Entonces, ¿qué sería lo óptimo? Tal vez fabricarías diferentes cantidades de zapatos en cada talle, de acuerdo a la demanda de cada uno. Y sabrías algo sobre la demanda si conocieras la frecuencia de cada talle en la población. Para eso, necesitarías conocer los parámetros poblacionales.</p>
<p>Por suerte, no es tan difícil obtener los parámetros poblacionales sin medir a toda la población. ¿Quién tiene tiempo para medirle los pies a todo el mundo? Nadie. Lo que hacés, en cambio, es seleccionar al azar un grupo de personas, medirles los pies, y después calcular los parámetros de esa muestra. Si la muestra es suficientemente grande, ya aprendimos que la media muestral es una muy buena estimación de la media poblacional. Y pronto vamos a ver que también hay versiones del desvío estándar muestral que estiman bastante bien la desviación estándar poblacional. Quizás la distribución de talles de calzado no tenga una forma exactamente normal. Aun así, si recolectás una muestra lo bastante grande, la forma de la distribución muestral será una buena aproximación a la forma de la distribución poblacional. Todas estas son buenas razones para interesarse por la estimación de parámetros poblacionales. Pero… ¿acaso dirigís una empresa de calzado? Probablemente no.</p>
</section>
<section id="parámetros-poblacionales-abstractos" class="level3" data-number="5.12.2">
<h3 data-number="5.12.2" class="anchored" data-anchor-id="parámetros-poblacionales-abstractos"><span class="header-section-number">5.12.2</span> Parámetros poblacionales abstractos</h3>
<p>Incluso cuando pensamos que estamos hablando de algo concreto en psicología, a menudo enseguida se vuelve abstracto. En lugar de medir la población de talles de calzado, ¿qué tal si intentamos medir la población de la <strong>felicidad humana</strong>? Todos creemos saber lo que es la felicidad. Todos tienen más o menos cantidad de ella. Hay mucha gente, así que… debe haber una “población de felicidad”, ¿no? Tal vez. Pero no es algo muy concreto. El primer problema es cómo medir la felicidad. Supongamos que usamos un cuestionario. Considerá estas preguntas:</p>
<blockquote class="blockquote">
<p>¿Qué tan feliz te sentís ahora mismo en una escala del 1 al 7? ¿Qué tan feliz sos en general en una escala del 1 al 7? ¿Qué tan feliz te sentís a la mañana en una escala del 1 al 7? ¿Qué tan feliz te sentís a la tarde en una escala del 1 al 7?</p>
</blockquote>
<p>1 = muy infeliz 2 = infeliz 3 = algo infeliz 4 = en el medio 5 = algo feliz 6 = feliz 7 = muy feliz</p>
<p>Olvidémonos de preguntarle esto a todo el mundo. Supongamos que se lo preguntamos a mucha gente (nuestra muestra). ¿Qué creés que va a pasar? Bueno, obviamente, la gente va a dar todo tipo de respuestas, ¿no? Podemos contar cuántas veces se eligió cada opción y graficarlas en un histograma. Eso nos mostraría la distribución de puntajes de felicidad en nuestra muestra. “¡Genial, fantástico!”, decís. Sí, está todo muy bien.</p>
<p>Por un lado, podemos decir un montón de cosas sobre las personas en nuestra muestra. Podemos decir quién dijo que es feliz y quién no —¡al fin y al cabo, nos lo acaban de decir!</p>
<p>Pero… ¿qué podemos decir sobre la población más grande? ¿Podemos usar los parámetros de nuestra muestra (media, desvío, forma, etc.) para estimar algo sobre la población completa? ¿Podemos inferir qué tan feliz es “todo el mundo” a partir de lo que dijo nuestra muestra?</p>
<section id="complicaciones-de-la-inferencia" class="level4" data-number="5.12.2.1">
<h4 data-number="5.12.2.1" class="anchored" data-anchor-id="complicaciones-de-la-inferencia"><span class="header-section-number">5.12.2.1</span> Complicaciones de la inferencia</h4>
<p>Antes de listar un montón de complicaciones, dejame decirte qué creo que sí podemos hacer con nuestra muestra. Siempre que sea lo suficientemente grande, los parámetros de nuestra muestra serán una bastante buena estimación de cómo se vería otra muestra tomada de la misma población. Y por los motivos que vamos a discutir, muchas veces eso es todo lo que podemos decir. Pero está bien: como vas a ver a lo largo de este libro, podemos trabajar con eso.</p>
<p><strong>Problema 1: múltiples poblaciones</strong> Si observás una muestra grande de respuestas a un cuestionario, vas a encontrar evidencia de múltiples distribuciones dentro de tu muestra. Las personas responden de maneras distintas. Algunas personas son muy cautas y evitan los extremos. Sus respuestas tienden a concentrarse en el centro de la escala, con muchos 3, 4 y 5. Otras personas responden de manera muy bimodal: se sienten muy felices o muy infelices dependiendo del momento del día. Sus respuestas se agrupan mayormente en los extremos: 1, 2, 6 y 7. Esos números parecen provenir de una distribución completamente distinta. También hay personas que son completamente felices o completamente infelices. Una vez más, estos dos “grupos” de personas generan respuestas que parecen venir de dos distribuciones diferentes: una con casi todos 6 y 7, y otra con casi todos 1 y 2. Otras personas responden de forma bastante aleatoria, y sus respuestas se distribuyen de manera casi uniforme en toda la escala. Entonces, ¿existe una única población con parámetros que podamos estimar a partir de nuestra muestra? **Probablemente no. Podría tratarse de una mezcla de muchas poblaciones, cada una con su propia distribución.</p>
<p><strong>Problema 2: ¿Qué miden realmente estas preguntas?</strong> Si todo el propósito de hacer el cuestionario es estimar la felicidad de la población, entonces realmente tenemos que preguntarnos si nuestras mediciones nos dicen algo sobre la felicidad en primer lugar. Algunas preguntas que surgen: ¿Las personas son precisas al decir cuán felices son? ¿La medición de felicidad depende de la escala usada? Por ejemplo, ¿los resultados serían distintos si usáramos una escala de 0 a 100, o de -100 a +100, o si no usáramos números en absoluto? ¿La medición de felicidad depende de cómo está redactada la pregunta? ¿Una medida como esta nos dice <strong>todo</strong> lo que queremos saber sobre la felicidad? (probablemente no). ¿Qué cosas está dejando afuera? (¿quién sabe? probablemente muchas).</p>
<p>En resumen, nadie sabe con certeza si este tipo de preguntas miden lo que queremos que midan, solo esperamos que lo hagan. Lo que sí sabemos bastante bien es qué tipo de cosas miden realmente este tipo de preguntas. Es algo bastante evidente, que está justo frente a nosotros: las mediciones de cuestionarios miden cómo la gente responde cuestionarios. Dicho de otro modo: miden cómo se comportan las personas cuando se les da un cuestionario para responder. Esto puede también reflejar algo sobre la felicidad, si la pregunta trata sobre felicidad. Pero, resulta que las personas son notablemente consistentes en cómo responden, incluso cuando las preguntas son totalmente absurdas, o cuando ni siquiera hay preguntas (¡solo números para elegir!) <span class="citation" data-cites="maul">(<a href="references.html#ref-maul" role="doc-biblioref"><strong>maul?</strong></a>_rethinking_2017)</span>.</p>
<p>La enseñanza que nos dejan estas complicaciones es que, en psicología, podemos recolectar muestras… pero muchas veces no tenemos una idea clara de qué población está asociada a esas muestras. Puede haber muchas poblaciones distintas. O la población puede variar dependiendo de a quién le preguntes. Y finalmente, la “población” quizás no sea la que vos querés que sea.</p>
</section>
</section>
<section id="experimentos-y-parámetros-poblacionales" class="level3" data-number="5.12.3">
<h3 data-number="5.12.3" class="anchored" data-anchor-id="experimentos-y-parámetros-poblacionales"><span class="header-section-number">5.12.3</span> Experimentos y parámetros poblacionales</h3>
<p>OK, entonces no tenemos una empresa de calzado, y tampoco podemos identificar con claridad la población que nos interesa en psicología… ¿podemos saltearnos esta sección sobre estimación? Después de todo, eso de “la población” parece demasiado raro, abstracto, inútil y polémico. ¡ESPERÁ!</p>
<p>Resulta que sí podemos aplicar todo lo que venimos aprendiendo para resolver un montón de problemas importantes en investigación. Estas herramientas nos permiten responder preguntas a partir de los datos que recolectamos. La estimación de parámetros es una de esas herramientas. Solo necesitamos ser un poco más creativos y un poco más abstractos para poder usarlas.</p>
<p>Ya sabemos algunas cosas. Los números que medimos vienen de algún lado. A eso le llamamos “distribuciones”. Las distribuciones controlan cómo aparecen los números. Algunos valores ocurren más que otros, según la distribución. Asumimos —incluso si no sabemos cuál es la distribución, ni qué significa— que los números provienen de una. Segundo: cuando tenemos algunos números, a eso le llamamos una muestra. Y todo este capítulo te enseñó una cosa fundamental: Cuando tu muestra es grande, se parece a la distribución de la que proviene. Y cuando tu muestra es grande, también se va a parecer mucho a otra muestra grande de la misma población. ¡Podemos usar este conocimiento!</p>
<p>Muy a menudo, como psicólogos, lo que queremos saber es qué causa qué. Queremos saber si X causa un cambio en Y. ¿Comer chocolate te hace más feliz? ¿Estudiar mejora tus notas? Hay millones de preguntas como estas. Y queremos respuestas.</p>
<p>Hasta ahora traté de mantenerme en ejemplos concretos en este libro —por eso hablamos de chocolate y felicidad, al menos son cosas tangibles. Pero ahora intentemos ponernos abstractos. Podemos hacerlo.</p>
<p>Queremos saber si X causa un cambio en Y. ¿Qué es X? ¿Qué es Y? X es algo que cambiás, es decir, la variable independiente. Y es algo que medís. Entonces, vamos a tomar muestras de Y. “¡Ah, ya entendí! Tomamos muestras de Y, y luego podemos usar los parámetros muestrales para estimar los parámetros poblacionales de Y.” NO, bueno, más o menos. Vamos a tomar muestras de Y, eso sí. De hecho, eso es todo lo que hacemos siempre, por eso hablar de “la población de Y” es un poco sin sentido. Lo que nos interesa de verdad son nuestras muestras de Y, y cómo se comportan.</p>
<p>Entonces, ¿qué pasaría si elimináramos completamente X del universo, y luego tomáramos una gran muestra de Y? Vamos a suponer que Y mide algo en un experimento de psicología. Así que sabemos, desde ya, que Y es una variable. Cuando tomamos una muestra grande, va a tener una distribución (porque Y varía). Entonces podemos hacer cosas como calcular la media de Y, medir su desviación estándar, y cualquier otra cosa que nos interese saber sobre Y. Perfecto. ¿Y si repitiésemos esa medición? Es decir, tomamos otra muestra aleatoria de Y, del mismo tamaño que la anterior. ¿Qué debería pasar? Nuestra primera muestra debería parecerse mucho a la segunda. Después de todo, no hicimos nada a Y, simplemente tomamos dos muestras grandes, en dos momentos diferentes. Ambas muestras serán un poco distintas (por el error muestral), pero se parecerán bastante. Cuanto más grandes sean nuestras muestras, más similares serán entre sí, especialmente si no hicimos nada para que sean diferentes. En otras palabras: podemos usar los parámetros de una muestra para estimar los de otra, porque tienden a ser iguales, sobre todo cuando las muestras son grandes.</p>
<p>Ahora estamos listos para el segundo paso. Vos querés saber si X cambia Y. ¿Qué hacés? Hacés que X suba y tomás una muestra grande de Y, y después la mirás. Después hacés que X baje, tomás otra muestra grande de Y y la mirás también. Lo que sigue es comparar las dos muestras de Y. Si X no cambia nada, ¿qué tendrías que encontrar? Eso ya lo hablamos en el párrafo anterior. Si X no hace nada, entonces las dos muestras grandes de Y tendrían que ser bastante parecidas. Sin embargo, si X realmente tiene un efecto sobre Y, entonces una de tus muestras grandes de Y va a ser distinta de la otra. Habrás cambiado algo en Y. Tal vez X hace que cambie la media de Y. O tal vez X cambia la variabilidad de Y. O incluso, puede que X cambie toda la forma de la distribución. Si encontramos algún cambio importante que no pueda explicarse por error muestral, entonces podemos concluir que algo en X causó un cambio en Y. ¡Podemos usar este enfoque para aprender qué causa qué!</p>
<p>La idea muy importante sigue siendo la de estimación, solo que no se trata exactamente de estimar un parámetro poblacional. Sabemos que cuando tomamos muestras, hay variación natural. Entonces, cuando estimamos un parámetro de una muestra —como la media— sabemos que esa estimación va a estar equivocada en alguna medida. Cuando encontramos que dos muestras son distintas, lo que necesitamos averiguar es si la magnitud de esa diferencia es compatible con lo que esperaría del error muestral, o si la diferencia es más grande que eso. Si la diferencia es más grande, entonces podemos tener confianza en que no fue el error muestral lo que la produjo. Entonces, podemos inferir con confianza que otra cosa (como X) causó la diferencia. Este tipo de pensamiento más abstracto es el que ocupa la mayor parte del resto del libro. Se trata de determinar si hubo una diferencia causada por tu manipulación experimental. Hay mucho más para contar, siempre lo hay. Podemos ir más allá de simplemente preguntar si hay una diferencia, pero para fines introductorios, nos vamos a enfocar en encontrar diferencias como concepto fundamental.</p>
</section>
<section id="resumen-intermedio" class="level3" data-number="5.12.4">
<h3 data-number="5.12.4" class="anchored" data-anchor-id="resumen-intermedio"><span class="header-section-number">5.12.4</span> Resumen intermedio</h3>
<p>Hemos hablado bastante sobre estimación, aunque hasta ahora no hemos hecho muchas estimaciones concretas. Así que en la próxima sección vamos a empezar a estimar la media y la desviación estándar. Formalmente, esto se conoce como el uso de una muestra para estimar un parámetro poblacional. Pero sentite libre de pensar en “la población” de distintas maneras. Podría ser una población concreta, como la distribución de tamaños de calzado. O podría ser algo más abstracto, como una estimación del parámetro que típicamente producen las muestras, si las repitieras muchas veces. Por ejemplo, si realizás muchas muestras grandes bajo condiciones similares, ¿qué promedio suelen darte? Eso es un parámetro. La mayoría de las veces, no podemos ver directamente ese parámetro. Lo que podemos ver es una muestra. Y lo que podemos hacer es usar esa muestra para estimar el parámetro que no podemos observar.</p>
</section>
<section id="estimación-de-la-media-poblacional" class="level3" data-number="5.12.5">
<h3 data-number="5.12.5" class="anchored" data-anchor-id="estimación-de-la-media-poblacional"><span class="header-section-number">5.12.5</span> Estimación de la media poblacional</h3>
<p>Supongamos que vamos a Brooklyn y 100 personas locales tienen la amabilidad de hacer una prueba de CI. El puntaje promedio de CI entre esas personas resulta ser <span class="math inline">\(\bar{X} = 98.5\)</span>. Entonces, ¿cuál es la verdadera media del CI en toda la población de Brooklyn? Obviamente, no lo sabemos. Podría ser 97.2, o también podría ser 103.5. Como nuestra muestra no es exhaustiva, no podemos dar una respuesta definitiva. Sin embargo, si nos obligaran a dar nuestra “mejor aproximación”, tendría que decir 98.5. Esa es la esencia de la estimación estadística. Estamos usando la media muestral como nuestra mejor aproximación a la media poblacional.</p>
<p>En este ejemplo, estimar el parámetro poblacional desconocido es bastante directo. Calculamos la media muestral y la usamos como nuestra <strong>estimación de la media poblacional</strong>. Es bastante simple, y en la próxima sección vamos a ver la justificación estadística de por qué esta respuesta intuitiva tiene sentido. Pero por ahora, asegurémonos de distinguir bien que el estadístico muestral y la estimación del parámetro poblacional son conceptualmente distintos. El estadístico muestral describe tus datos; en cambio, una estimación es una conjetura sobre la población.</p>
<p>Con eso en mente, los profesionales de la estadística suelen usar notaciones distintas para diferenciarlas. Por ejemplo, si la media poblacional verdadera se denota <span class="math inline">\(\mu\)</span>, entonces usamos <span class="math inline">\(\hat{\mu}\)</span> para referirnos a nuestra estimación de esa media poblacional. En contraste, la media muestral se denota <span class="math inline">\(\bar{X}\)</span>, o a veces <span class="math inline">\(m\)</span>. Sin embargo, en muestras aleatorias simples, la estimación de la media poblacional es idéntica a la media muestral: si observo una media muestral de <span class="math inline">\(\bar{X} = 98.5\)</span>, entonces mi estimación de la media poblacional es también <span class="math inline">\(\hat{\mu} = 98.5\)</span>.</p>
<p>Para dejar clara la notación, acá va una tabla útil:</p>
<table class="table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Símbolo</th>
<th>Qué representa</th>
<th>¿Conocido a partir de la muestra?</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\bar{X}\)</span></td>
<td>Media muestral</td>
<td>Sí, se calcula a partir de los datos crudos</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\mu\)</span></td>
<td>Verdadera media poblacional</td>
<td>Casi nunca se conoce con certeza</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\hat{\mu}\)</span></td>
<td>Estimación de la media poblacional</td>
<td>Sí, es idéntica a la media muestral</td>
</tr>
</tbody>
</table>
</section>
<section id="estimación-del-desvío-estándar-poblacional" class="level3" data-number="5.12.6">
<h3 data-number="5.12.6" class="anchored" data-anchor-id="estimación-del-desvío-estándar-poblacional"><span class="header-section-number">5.12.6</span> Estimación del desvío estándar poblacional</h3>
<p>Hasta ahora, la estimación parece bastante sencilla, y tal vez te estés preguntando por qué te hice leer todo ese material sobre teoría del muestreo. En el caso de la media, nuestra estimación del parámetro poblacional (<span class="math inline">\(\hat{\mu}\)</span>) resultó ser idéntica a la estadística muestral correspondiente (<span class="math inline">\(\bar{X}\)</span>). Sin embargo, eso no siempre es así. Para verlo, pensemos cómo construir una <strong>estimación del desvío estándar poblacional</strong>, que vamos a denotar como <span class="math inline">\(\hat{\sigma}\)</span>. ¿Qué deberíamos usar como estimación en este caso? Tu primera reacción podría ser hacer lo mismo que con la media, y simplemente usar el estadístico muestral como estimación. Eso está casi bien, pero no del todo.</p>
<p>Veamos por qué. Supongamos que tengo una muestra que contiene una sola observación. Para este ejemplo, ayuda pensar en una situación donde no tengas ninguna intuición previa sobre cuál podría ser el valor real en la población. Así que usemos algo completamente ficticio: supongamos que la observación mide la <strong>cromulencia</strong> de mis zapatos. Resulta que mis zapatos tienen una cromulencia de 20. Así que mi muestra es:</p>
<p><code>20</code></p>
<p>Esta es una muestra perfectamente legítima, aunque tenga un tamaño muestral de <span class="math inline">\(N = 1\)</span>. Tiene una media muestral de 20, y como cada observación en esta muestra es igual a la media muestral (¡obviamente!), el desvío estándar muestral es 0. Como descripción de la <strong>muestra</strong>, esto está bien: la muestra contiene una sola observación, así que no hay variabilidad observada en la muestra. Un desvío estándar muestral de <span class="math inline">\(s = 0\)</span> es la respuesta correcta acá. Pero como estimación del desvío estándar <strong>poblacional</strong>, eso suena completamente absurdo, ¿no? Seamos sinceros: vos y yo no tenemos ni idea de qué es la “cromulencia”, pero sabemos algo sobre datos. La única razón por la que no vemos ninguna variabilidad en la <strong>muestra</strong> es que la muestra es demasiado chica como para mostrar alguna variación. Entonces, si tenés un tamaño muestral de <span class="math inline">\(N=1\)</span>, lo que se <strong>siente</strong> como la respuesta correcta es simplemente decir: “ni idea, la verdad”.</p>
<p>Fijate que <strong>no</strong> tenemos la misma intuición cuando se trata de la media muestral y la media poblacional. Si alguien nos obliga a hacer una mejor aproximación sobre la media de la población, no suena completamente descabellado decir que la media poblacional es 20. Obvio, probablemente no te sientas muy seguro de esa aproximación, porque solo tenés una observación, pero sigue siendo la mejor aproximación que podés hacer.</p>
<p>Extendamos un poco este ejemplo. Supongamos que ahora hago una segunda observación. Mi conjunto de datos ahora tiene <span class="math inline">\(N=2\)</span> observaciones de la cromulencia de los zapatos, y la muestra completa se ve así:</p>
<p><code>20, 22</code></p>
<p>Esta vez, nuestra muestra es <strong>justo</strong> lo suficientemente grande como para que podamos ver algo de variabilidad: dos observaciones es el número mínimo necesario para que pueda observarse alguna variación. Para este nuevo conjunto de datos, el promedio muestral es <span class="math inline">\(\bar{X}=21\)</span> y la desviación estándar muestral es <span class="math inline">\(s=1\)</span>.</p>
<p>¿Qué intuiciones tenemos ahora sobre la población? De nuevo, en lo que respecta a la media poblacional, la mejor aproximación que podemos hacer es la media muestral: si nos obligaran a adivinar, probablemente diríamos que la media de cromulencia poblacional es 21. ¿Y la desviación estándar? Acá la cosa se pone un poco más complicada. La desviación estándar muestral está basada solamente en dos observaciones, y si sos como yo, seguramente tenés la intuición de que, con solo dos datos, no le estamos dando a la población “suficiente oportunidad” de mostrarnos su verdadera variabilidad. No es solo que sospechamos que la estimación está <strong>equivocada</strong> —porque con solo dos observaciones ya esperamos que haya algún error—. La preocupación más grande es que el error sea <strong>sistemático</strong>.</p>
<p>Si el error es sistemático, entonces está <strong>sesgado</strong>. Por ejemplo, imaginate que el promedio muestral siempre fuera menor que el promedio poblacional. Si eso fuera cierto (no lo es), entonces no podríamos usar el promedio muestral como estimador. Estaría sesgado, estaríamos usando el número equivocado.</p>
<p>Bueno, resulta que el desvío estándar muestral es un <strong>estimador sesgado</strong> del desvío estándar poblacional. Ya veníamos intuyéndolo con lo que estuvimos discutiendo. Cuando el tamaño muestral es 1, el desvío estándar es 0, lo cual claramente es demasiado bajo. Cuando el tamaño muestral es 2, el desvío estándar empieza a ser mayor que 0, pero como solo tenemos dos datos, sospechamos que sigue siendo demasiado bajo. Y resulta que esta intuición es correcta.</p>
<p>Estaría bueno poder demostrar esto de alguna forma. Hay pruebas matemáticas que confirman esta intuición, pero salvo que tengas una formación matemática bastante sólida, no van a ayudarte mucho. Así que en vez de eso, lo que voy a hacer es usar R para simular los resultados de algunos experimentos. Con esto en mente, volvamos a nuestros estudios sobre CI. Supongamos que la verdadera media poblacional de CI es 100, y la desviación estándar poblacional es 15. Podemos usar la función <strong>rnorm()</strong> para generar los resultados de un experimento en el que medimos <span class="math inline">\(N = 2\)</span> puntuaciones de CI, y luego calculamos el desvío estándar muestral. Si repetimos este procedimiento una y otra vez, y graficamos un histograma de esos desvíos estándar muestrales, obtenemos la <strong>distribución muestral del desvío estándar</strong>. Esa distribución está graficada en la <span class="quarto-unresolved-ref">?fig-sampdistsd</span>.</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/unnamed-chunk-10_79ff8d14370814d4735391996cee3d66">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"imgs/navarro_img/estimation/sampdistsd_es.png"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="imgs/navarro_img/estimation/sampdistsd_es.png" class="img-fluid" width="2025"></p>
</div>
</div>
<p>Aunque la verdadera desviación estándar poblacional es 15, el promedio de los desvíos estándar <strong>muestrales</strong> es solo 8.5. Notá que esto es muy distinto de lo que pasaba cuando graficábamos distribuciones muestrales de la media: esas siempre estaban centradas en la media poblacional.</p>
<p>Ahora ampliemos la simulación. En lugar de restringirnos a un tamaño muestral de <span class="math inline">\(N=2\)</span>, repitamos el experimento para tamaños muestrales del 1 al 10. Si graficamos el promedio de la media muestral y el promedio del desvío estándar muestral como función del tamaño de la muestra, obtenemos los siguientes resultados.</p>
<p>La <a href="#fig-estimatorbiasA">Figura&nbsp;<span>5.21</span></a> muestra cómo cambia la media muestral según el tamaño de la muestra. Notá que la línea es plana: la media muestral no sobrestima ni subestima la media poblacional. Es un estimador insesgado.</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/fig-estimatorbiasA_3ac23e2b2cfcdb1634ba404778e7a94c">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"imgs/navarro_img/estimation/biasMean_es.png"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-estimatorbiasA" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="imgs/navarro_img/estimation/biasMean_es.png" class="img-fluid figure-img" width="1800"></p>
<figcaption class="figure-caption">Figura&nbsp;5.21: Una ilustración del hecho de que la media muestral es un estimador insesgado de la media poblacional.</figcaption>
</figure>
</div>
</div>
</div>
<p>La <a href="#fig-estimatorbiasB">Figura&nbsp;<span>5.22</span></a> muestra cómo cambia el <strong>desvío estándar muestral</strong> con el tamaño de muestra. Notá que <strong>no</strong> es una línea plana: el desvío estándar muestral <strong>subestima sistemáticamente</strong> la desviación estándar poblacional.</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/fig-estimatorbiasB_e3e593e2743303cf8682c889e0caf0bc">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"imgs/navarro_img/estimation/biasSD_es.png"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-estimatorbiasB" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="imgs/navarro_img/estimation/biasSD_es.png" class="img-fluid figure-img" width="1800"></p>
<figcaption class="figure-caption">Figura&nbsp;5.22: Una ilustración del hecho de que el desvío estándar muestral es un estimador sesgado de la desviación estándar poblacional.</figcaption>
</figure>
</div>
</div>
</div>
<p>En otras palabras, si queremos hacer una “mejor aproximación” (<span class="math inline">\(\hat\sigma\)</span>, nuestra estimación de la desviación estándar poblacional) sobre el valor real de la desviación estándar de la población <span class="math inline">\(\sigma\)</span>, deberíamos asegurarnos de que nuestra aproximación sea un poquito más grande que la desviación estándar muestral <span class="math inline">\(s\)</span>.</p>
<p>La solución a este sesgo sistemático resulta ser bastante simple. Así es como funciona. Antes de meternos con la desviación estándar, vamos a mirar la varianza. Si recordás el segundo capítulo, la varianza muestral se define como el promedio de los cuadrados de las desviaciones respecto de la media muestral. Es decir:</p>
<p><span class="math display">\[
s^2 = \frac{1}{N} \sum_{i=1}^N (X_i - \bar{X})^2
\]</span></p>
<p>La varianza muestral <span class="math inline">\(s^2\)</span> es un estimador sesgado de la varianza poblacional <span class="math inline">\(\sigma^2\)</span>. Pero resulta que solo necesitamos hacer un pequeño ajuste para transformarla en un estimador insesgado. Todo lo que hay que hacer es dividir por <span class="math inline">\(N-1\)</span> en lugar de por <span class="math inline">\(N\)</span>. Si hacemos eso, obtenemos la siguiente fórmula:</p>
<p><span class="math display">\[
\hat\sigma^2 = \frac{1}{N-1} \sum_{i=1}^N (X_i - \bar{X})^2
\]</span></p>
<p>Esto sí es un estimador insesgado de la varianza poblacional <span class="math inline">\(\sigma^2\)</span>.</p>
<p>Una historia similar se aplica al desvío estándar. Si dividimos por <span class="math inline">\(N-1\)</span> en lugar de por <span class="math inline">\(N\)</span>, nuestra estimación del desvío estándar poblacional se convierte en:</p>
<p><span class="math display">\[
\hat\sigma = \sqrt{\frac{1}{N-1} \sum_{i=1}^N (X_i - \bar{X})^2}
\]</span></p>
<p>Vale la pena señalar que los programas de software toman decisiones <strong>por vos</strong> sobre qué tipo de varianza y desvío estándar estás calculando. Algunos programas dividen automáticamente por <span class="math inline">\(N-1\)</span>, otros no. Necesitás verificar qué están haciendo. No dejes que el software decida por <strong>vos</strong>. El software está para que vos le digas qué hacer.</p>
<p>Un último punto: en la práctica, muchas personas se refieren a <span class="math inline">\(\hat{\sigma}\)</span> (la fórmula con <span class="math inline">\(N-1\)</span>) como el desvío estándar <strong>muestral</strong>. Técnicamente, esto es incorrecto: el desvío estándar muestral, como propiedad de la muestra, debería ser igual a <span class="math inline">\(s\)</span> (la fórmula con <span class="math inline">\(N\)</span>). No son la misma cosa, ni conceptualmente ni numéricamente. Una es una propiedad de la muestra; la otra, una estimación del parámetro poblacional. Sin embargo, en casi todas las aplicaciones reales, lo que realmente nos importa es la estimación del parámetro poblacional. Por eso, la gente casi siempre reporta <span class="math inline">\(\hat{\sigma}\)</span> en lugar de <span class="math inline">\(s\)</span>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>Ojo, si hay que dividir por 𝑁 o por 𝑁−1 también depende de cómo pensás lo que estás haciendo. Por ejemplo, si no creés que lo que estás haciendo es estimar un parámetro poblacional, entonces, ¿por qué dividirías por N−1? Además, cuando 𝑁 es grande, no importa tanto. La diferencia entre un 𝑁 grande y un 𝑁−1 grande es… simplemente 1.</p>
</div>
</div>
<p>Este es el número correcto que hay que reportar, claro. Pero la gente tiende a ser un poco imprecisa con la terminología cuando lo escribe, porque “desvío estándar muestral” es más corto que “estimación del desvío estándar poblacional”. No es gran cosa, y en la práctica yo hago lo mismo que todos los demás. Sin embargo, creo que es importante mantener los dos <strong>conceptos</strong> separados: nunca es buena idea confundir “propiedades conocidas de tu muestra” con “conjeturas sobre la población de la que proviene”. En el momento en que empezás a pensar que <span class="math inline">\(s\)</span> y <span class="math inline">\(\hat{\sigma}\)</span> son lo mismo, empezás a hacer justamente eso.</p>
<p>Para cerrar esta sección, acá tenés un par de tablas más para ayudarte a mantener todo claro:</p>
<table class="table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Símbolo</th>
<th>¿Qué es?</th>
<th>¿Lo conocemos?</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(s^2\)</span></td>
<td>Varianza muestral</td>
<td>Sí, se calcula a partir de los datos crudos</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\sigma^2\)</span></td>
<td>Varianza poblacional</td>
<td>Casi nunca se conoce con certeza</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\hat{\sigma}^2\)</span></td>
<td>Estimación de la varianza poblacional</td>
<td>Sí, pero no es lo mismo que la varianza muestral</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="estimación-de-un-intervalo-de-confianza" class="level2" data-number="5.13">
<h2 data-number="5.13" class="anchored" data-anchor-id="estimación-de-un-intervalo-de-confianza"><span class="header-section-number">5.13</span> Estimación de un intervalo de confianza</h2>
<blockquote class="blockquote">
<p>La estadística es no tener que decir nunca que estás seguro — Autor desconocido</p>
</blockquote>
<p>Hasta este punto del capítulo, describimos los fundamentos de la teoría del muestreo en los que se apoyan los estadísticos para hacer conjeturas sobre los parámetros poblacionales a partir de una muestra de datos. Como muestra esta discusión, una de las razones por las que necesitamos toda esta teoría es que todo conjunto de datos deja un cierto grado de incertidumbre, así que nuestras estimaciones nunca van a ser perfectamente precisas. Lo que falta en esta discusión hasta ahora es un intento de <strong>cuantificar</strong> cuánto es esa incertidumbre. No alcanza con poder decir que el CI promedio de estudiantes de psicología es 115 (sí, me acabo de inventar ese número). También queremos poder decir qué tan seguros estamos de esa estimación. Por ejemplo, estaría bueno poder decir que hay un 95% de probabilidad de que el valor real esté entre 109 y 121. A eso se le llama un <strong>intervalo de confianza</strong> para la media.</p>
<p>Armados con lo que ya sabemos sobre distribuciones muestrales, construir un intervalo de confianza para la media es bastante fácil. Así es como funciona: Supongamos que la verdadera media poblacional es <span class="math inline">\(\mu\)</span> y la desviación estándar poblacional es <span class="math inline">\(\sigma\)</span>. Acabo de terminar mi estudio con <span class="math inline">\(N\)</span> participantes, y la media muestral de CI fue <span class="math inline">\(\bar{X}\)</span>. Sabemos, gracias al teorema central del límite, que la distribución muestral de la media es aproximadamente normal. También sabemos, por lo que aprendimos sobre la distribución normal, que hay un 95% de probabilidad de que un valor normalmente distribuido caiga dentro de dos desviaciones estándar de la media verdadera. Para ser más precisos, podemos usar la función <code>qnorm()</code> para calcular los percentiles 2.5 y 97.5 de la distribución normal:</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/unnamed-chunk-11_8329ccb849d74cc522b101c30471a571">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>( <span class="at">p =</span> <span class="fu">c</span>(.<span class="dv">025</span>, .<span class="dv">975</span>) )</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -1.959964  1.959964</code></pre>
</div>
</div>
<p>Ok, así que te mentí un poco antes: lo más correcto es decir que hay un 95% de probabilidad de que una cantidad normalmente distribuida caiga dentro de 1.96 desviaciones estándar de la media verdadera.</p>
<p>Ahora recordá que la desviación estándar de la distribución muestral se llama error estándar, y que el error estándar de la media se denota como SEM. Cuando juntamos todas estas piezas, aprendemos que hay un 95% de probabilidad de que la media muestral <span class="math inline">\(\bar{X}\)</span> que observamos esté a no más de 1.96 errores estándar de la media poblacional. Uf, eso fue mucha matemática junta. Tranquilo, ahora lo aclaramos.</p>
<p>En notación matemática, esto se escribe así:</p>
<p><span class="math display">\[
\mu - \left(1.96 \times \text{SEM} \right) \ \leq\ \bar{X} \ \leq\ \mu + \left(1.96 \times \text{SEM} \right)
\]</span> donde el SEM es igual a <span class="math inline">\(\sigma / \sqrt{N}\)</span>, y podemos estar un 95% seguros de que esto es cierto.</p>
<p>Sin embargo, esto no responde la pregunta que realmente nos interesa. La ecuación anterior nos dice qué deberíamos esperar sobre la media muestral, dado que conocemos los parámetros poblacionales. Pero lo que queremos es que funcione al revés: queremos saber qué deberíamos creer sobre los parámetros poblacionales, dado que observamos una muestra particular. Sin embargo, no es muy difícil lograrlo. Con un poco de álgebra de secundaria, podemos reescribir nuestra ecuación así:</p>
<p><span class="math display">\[
\bar{X} - \left( 1.96 \times \text{SEM} \right) \leq \mu \leq \bar{X} + \left( 1.96 \times \text{SEM} \right)
\]</span></p>
<p>Esto nos dice que el rango de valores tiene una probabilidad del 95% de contener la media poblacional <span class="math inline">\(\mu\)</span>. A este rango lo llamamos <strong>intervalo de confianza del 95%</strong>, denotado como <span class="math inline">\(\text{CI}\_{95}\)</span>.</p>
<p>En resumen, siempre que <span class="math inline">\(N\)</span> sea lo suficientemente grande —lo suficientemente grande como para que la distribución muestral de la media se parezca a una normal— podemos usar la siguiente fórmula para el intervalo de confianza del 95%:</p>
<p><span class="math display">\[
\text{CI}_{95} = \bar{X} \pm \left( 1.96 \times \frac{\sigma}{\sqrt{N}} \right)
\]</span></p>
<p>Por supuesto, no hay nada especial en el número 1.96: simplemente es el multiplicador que necesitás usar si querés un intervalo de confianza del 95%. Si quisiera un intervalo de confianza del 70%, podría usar la función <strong>qnorm()</strong> para calcular los cuantiles 15 y 85:</p>
<div class="cell" data-hash="04-SamplesPopulations_cache/html/unnamed-chunk-12_6ee0fca744d42d4ca582c9ecbbd9b8be">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>( <span class="at">p =</span> <span class="fu">c</span>(.<span class="dv">15</span>, .<span class="dv">85</span>) )</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -1.036433  1.036433</code></pre>
</div>
</div>
<p>Así que la fórmula para el <span class="math inline">\(\text{CI}*{70}\)</span> sería igual a la del <span class="math inline">\(\text{CI}*{95}\)</span>, excepto que usaríamos 1.04 como nuestro número mágico, en lugar de 1.96.</p>
<section id="un-pequeño-error-en-la-fórmula" class="level3" data-number="5.13.1">
<h3 data-number="5.13.1" class="anchored" data-anchor-id="un-pequeño-error-en-la-fórmula"><span class="header-section-number">5.13.1</span> Un pequeño error en la fórmula</h3>
<p>Como de costumbre, te mentí un poco. La fórmula que te di más arriba para el intervalo de confianza del 95% es aproximadamente correcta, pero me salté un detalle importante en la explicación. Fijate que mi fórmula requiere que uses el error estándar de la media (SEM), que a su vez necesita que conozcas la desviación estándar real de la población, <span class="math inline">\(\sigma\)</span>.</p>
<p>Sin embargo, ya dijimos antes que en general <strong>no conocemos</strong> los parámetros poblacionales verdaderos. Y como no conocemos el valor real de <span class="math inline">\(\sigma\)</span>, tenemos que usar una <strong>estimación</strong> del desvío estándar poblacional <span class="math inline">\(\hat{\sigma}\)</span>. Eso no es difícil de hacer, pero tiene una consecuencia: tenemos que usar los cuantiles de la distribución <span class="math inline">\(t\)</span> en lugar de la distribución normal para calcular nuestro número mágico; y ese número depende del tamaño muestral. Además, todavía no hablamos de la distribución <span class="math inline">\(t\)</span> en este capítulo.</p>
<p>Cuando usamos la distribución <span class="math inline">\(t\)</span> en lugar de la distribución normal, obtenemos números más grandes, lo que indica que tenemos más incertidumbre. ¿Y por qué tenemos esa incertidumbre extra? Bueno, porque nuestra estimación de la desviación estándar poblacional, <span class="math inline">\(\hat\sigma\)</span>, puede estar equivocada. Y si está equivocada, eso significa que estamos menos seguros de cómo es realmente la distribución muestral de la media… y esa incertidumbre termina reflejándose en un intervalo de confianza más amplio.</p>
</section>
</section>
<section id="resumen" class="level2" data-number="5.14">
<h2 data-number="5.14" class="anchored" data-anchor-id="resumen"><span class="header-section-number">5.14</span> Resumen</h2>
<p>En este capítulo cubrimos dos grandes temas. La primera mitad trató sobre la teoría del muestreo, y la segunda mitad sobre cómo podemos usar esa teoría para construir <strong>estimaciones de parámetros poblacionales</strong>. La estructura fue más o menos así:</p>
<ul>
<li><p>Ideas básicas sobre muestras, muestreo y poblaciones</p></li>
<li><p>Teoría estadística del muestreo: ley de los grandes números, distribuciones muestrales y el teorema central del límite</p></li>
<li><p>Estimación de medias y desviaciones estándar</p></li>
<li><p>Intervalos de confianza</p></li>
</ul>
<p>Como siempre, hay un montón de temas relacionados con el muestreo y la estimación que no se cubren en este capítulo, pero para una materia introductoria de psicología, creo que esto es bastante completo. Para la mayoría de quienes hacen investigación aplicada, no vas a necesitar mucha más teoría que esta. Una gran pregunta que no toqué en este capítulo es: ¿qué hacés cuando no tenés una muestra aleatoria simple? Hay muchísima teoría estadística que se puede usar para manejar esa situación, pero queda muy por fuera del alcance de este libro.</p>
</section>
<section id="videos" class="level2" data-number="5.15">
<h2 data-number="5.15" class="anchored" data-anchor-id="videos"><span class="header-section-number">5.15</span> Videos</h2>
<section id="introducción-a-la-probabilidad" class="level3" data-number="5.15.1">
<h3 data-number="5.15.1" class="anchored" data-anchor-id="introducción-a-la-probabilidad"><span class="header-section-number">5.15.1</span> Introducción a la probabilidad</h3>
<p>Jeff tiene varios videos más sobre probabilidad que podés ver en su <a href="https://www.youtube.com/playlist?list=PLKXdxQAT3tCvuex_E1ZnQYaw897ELUSaI">lista de reproducción de estadística</a>.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/RoalMn9VHZg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
</section>
<section id="teorema-de-chebychev" class="level3" data-number="5.15.2">
<h3 data-number="5.15.2" class="anchored" data-anchor-id="teorema-de-chebychev"><span class="header-section-number">5.15.2</span> Teorema de Chebychev</h3>
<iframe width="560" height="315" src="https://www.youtube.com/embed/4RtwqCFt1IU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
</section>
<section id="puntajes-z-1" class="level3" data-number="5.15.3">
<h3 data-number="5.15.3" class="anchored" data-anchor-id="puntajes-z-1"><span class="header-section-number">5.15.3</span> Puntajes Z</h3>
<iframe width="560" height="315" src="https://www.youtube.com/embed/dQVO0KAxFaU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
</section>
<section id="distribución-normal-i" class="level3" data-number="5.15.4">
<h3 data-number="5.15.4" class="anchored" data-anchor-id="distribución-normal-i"><span class="header-section-number">5.15.4</span> Distribución normal I</h3>
<iframe width="560" height="315" src="https://www.youtube.com/embed/FPJDF9fGwwE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
</section>
<section id="distribución-normal-ii" class="level3" data-number="5.15.5">
<h3 data-number="5.15.5" class="anchored" data-anchor-id="distribución-normal-ii"><span class="header-section-number">5.15.5</span> Distribución normal II</h3>
<iframe width="560" height="315" src="https://www.youtube.com/embed/mPdnF-GVuCo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-Fisher1922b" class="csl-entry" role="listitem">
Fisher, R. A. 1922. <span>«On the Mathematical Foundation of Theoretical Statistics»</span>. <em>Philosophical Transactions of the Royal Society A</em> 222: 309-68.
</div>
<div id="ref-Keynes1923" class="csl-entry" role="listitem">
Keynes, John Maynard. 1923. <em>A Tract on Monetary Reform</em>. <span>London</span>: <span>Macmillan and Company</span>.
</div>
<div id="ref-Meehl1967" class="csl-entry" role="listitem">
Meehl, P. H. 1967. <span>«Theory Testing in Psychology and Physics: <span>A</span> Methodological Paradox»</span>. <em>Philosophy of Science</em> 34: 103-15. <a href="https://doi.org/10.1086/288135">https://doi.org/10.1086/288135</a>.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./03-Correlation.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Correlación</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./05-Foundation_Inference.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Fundamentos de la inferencia</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>